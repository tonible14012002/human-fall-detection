<!DOCTYPE html>
<!-- saved from url=(0053)https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><link rel="stylesheet" type="text/css" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/jig.min.css">
    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Mobile properties -->
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
    <!-- Stylesheets -->
    <link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.aa42804411e1.css" type="text/css">
  
  <link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.6c8346f5860b.css" type="text/css"><link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.3b12438b8d66.css" type="text/css"><link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.3766d7ad0d2d.css" type="text/css"><link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.e3c3c2c84eb3.css" type="text/css">

  
    <link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/font-awesome.min.css">
  
<link type="text/css" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/base.6539a0a78536cfdc1fa6.css" rel="stylesheet">


    <link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/stixfonts.css" type="text/css"><link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/pmcrefs1.min.css" type="text/css"><link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/ncbi_web.min.css" type="text/css"><style type="text/css">.pmc-wm {background:transparent repeat-y top left;background-image:url(/corehtml/pmc/pmcgifs/wm-jhir.gif);background-size: auto, contain}</style><style type="text/css">.print-view{display:block}</style>

    <link type="text/css" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/article.e622fd8870cb011febf1.css" rel="stylesheet">
    <link type="text/css" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/cite-box.css" rel="stylesheet">


    <title>DeepFall: Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC</title>

  
  <!-- Favicons -->
  <link rel="shortcut icon" type="image/ico" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.ico">
  <link rel="icon" type="image/png" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon.png">

  <!-- 192x192, as recommended for Android
  http://updates.html5rocks.com/2014/11/Support-for-theme-color-in-Chrome-39-for-Android
  -->
  <link rel="icon" type="image/png" sizes="192x192" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-192.png">

  <!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
  <link rel="apple-touch-icon-precomposed" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-57.png">
  <!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-72.png">
  <!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-114.png">
  <!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://www.ncbi.nlm.nih.gov/coreutils/nwds/img/favicons/favicon-144.png">



    
        <!-- Logging params: Pinger defaults -->

<meta name="ncbi_app" content="pmc-frontend">

<meta name="ncbi_db" content="pmc">

<meta name="ncbi_phid" content="939B32A63687BA55000044848D963331.1.m_2">


        <!-- Logging params: Pinger custom -->

<meta name="ncbi_pdid" content="article">

<meta name="ncbi_op" content="retrieved">

<meta name="ncbi_app_version" content="1.5.0.post1+55721b3">

<meta name="ncbi_domain" content="jhir">

<meta name="ncbi_type" content="fulltext">

<meta name="ncbi_pcid" content="/articles/PMC8982799/">


    


        <script type="text/javascript" async="" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/js"></script><script async="" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/gtm.js.download" id="pingerInjectedGTM"></script><script>
            
            var useOfficialGovtHeader = true;
        </script>


    <meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE"><link rel="canonical" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/"><link rel="schema.DC" href="http://purl.org/DC/elements/1.0/"><meta name="citation_journal_title" content="Journal of Healthcare Informatics Research"><meta name="citation_title" content="DeepFall: Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders"><meta name="citation_author" content="Jacob Nogas"><meta name="citation_author_institution" content="University of Toronto, Toronto, Canada"><meta name="citation_author" content="Shehroz S. Khan"><meta name="citation_author_institution" content="University of Toronto, Toronto, Canada"><meta name="citation_author" content="Alex Mihailidis"><meta name="citation_author_institution" content="Toronto Rehabilitation Institute, University Health Network, Toronto, Canada"><meta name="citation_publication_date" content="2020/03"><meta name="citation_issue" content="1"><meta name="citation_volume" content="4"><meta name="citation_firstpage" content="50"><meta name="citation_doi" content="10.1007/s41666-019-00061-4"><meta name="citation_abstract_html_url" content="/pmc/articles/PMC8982799/?report=abstract"><meta name="citation_fulltext_html_url" content="/pmc/articles/PMC8982799/"><meta name="citation_pmid" content="35415435"><meta name="DC.Title" content="DeepFall: Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders"><meta name="DC.Type" content="Text"><meta name="DC.Publisher" content="Springer"><meta name="DC.Contributor" content="Jacob Nogas"><meta name="DC.Contributor" content="Shehroz S. Khan"><meta name="DC.Contributor" content="Alex Mihailidis"><meta name="DC.Date" content="2020 Mar"><meta name="DC.Identifier" content="10.1007/s41666-019-00061-4"><meta name="DC.Language" content="en"><meta property="og:title" content="DeepFall: Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders"><meta property="og:type" content="article"><meta property="og:description" content="Human falls rarely occur; however, detecting falls is very important from the health and safety perspective. Due to the rarity of falls, it is difficult to employ supervised classification techniques to detect them. Moreover, in these highly skewed situations, ..."><meta property="og:url" content="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/"><meta property="og:site_name" content="PubMed Central (PMC)"><meta property="og:image" content="https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-card-share.jpg?_=0"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@ncbi">


<meta name="ncbi_nwds_ver" content="1.1.9-2"><meta name="ncbi_nwds" content="yes"><script async="1" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/analytics.js.download"></script><style type="text/css">.MathJax_Preview {color: #888; display: contents}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><script charset="utf-8" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/12.c374cce172555dcce9b4.chunk.js.download"></script><style type="text/css">.MathJax_Display {text-align: center; margin: 1em 0em; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax:focus, body :focus .MathJax {display: inline-table}
.MathJax.MathJax_FullWidth {text-align: center; display: table-cell!important; width: 10000em!important}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none; box-sizing: content-box}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_test {font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow: hidden; height: 1px}
.MathJax_test.mjx-test-display {display: table!important}
.MathJax_test.mjx-test-inline {display: inline!important; margin-right: -1px}
.MathJax_test.mjx-test-default {display: block!important; clear: both}
.MathJax_ex_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.MathJax_em_box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60em}
.mjx-test-inline .MathJax_left_box {display: inline-block; width: 0; float: left}
.mjx-test-inline .MathJax_right_box {display: inline-block; width: 0; float: right}
.mjx-test-display .MathJax_right_box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Main; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Main-bold; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Main-italic; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Math-italic; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Caligraphic; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size1; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size2; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size3; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf?V=2.7.9') format('opentype')}
@font-face {font-family: MathJax_Size4; src: url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff?V=2.7.9') format('woff'), url('https://www.ncbi.nlm.nih.gov/core/mathjax/2.7.9/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf?V=2.7.9') format('opentype')}
</style><script charset="utf-8" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/7.5ccfa63c1a40bc213c6e.chunk.js.download"></script><script charset="utf-8" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/1.53cfb5f19d9d4b3a8cae.chunk.js.download"></script></head>
<body id="ui-ncbiexternallink-3"><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div><section class="pmc-alerts">

</section><section data-section="Alerts">
	<div class="ncbi-alerts-placeholder"></div>
</section>

   
    
    


    
        
    

    
        <button class="back-to-top back-to-top--bottom" data-ga-category="pagination" data-ga-action="back_to_top">
          Back to Top
        </button>
    

    <a class="usa-skipnav" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#main-content">Skip to main content</a>
    <!-- ========== BEGIN HEADER ========== -->
<section class="usa-banner" style="">
  <div class="usa-accordion">
    <header class="usa-banner-header">
      <div class="usa-grid usa-banner-inner">
        <img src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/favicon-57.png" alt="U.S. flag">
        <p>An official website of the United States government</p>
        <button class="usa-accordion-button usa-banner-button" aria-expanded="false" aria-controls="gov-banner-top">
          <span class="usa-banner-button-text">Here's how you know</span>
        </button>
      </div>
    </header>
    <div class="usa-banner-content usa-grid usa-accordion-content" id="gov-banner-top" aria-hidden="true">
      <div class="usa-banner-guidance-gov usa-width-one-half">
        <img class="usa-banner-icon usa-media_block-img" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/icon-dot-gov.svg" alt="Dot gov">
        <div class="usa-media_block-body">
          <p>
            <strong>The .gov means it’s official.</strong>
            <br>
            Federal government websites often end in .gov or .mil. Before
            sharing sensitive information, make sure you’re on a federal
            government site.
          </p>
        </div>
      </div>
      <div class="usa-banner-guidance-ssl usa-width-one-half">
        <img class="usa-banner-icon usa-media_block-img" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/icon-https.svg" alt="Https">
        <div class="usa-media_block-body">
          <p>
            <strong>The site is secure.</strong>
            <br>
            The <strong>https://</strong> ensures that you are connecting to the
            official website and that any information you provide is encrypted
            and transmitted securely.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<div class="usa-overlay"></div>
<header class="ncbi-header" role="banner" data-section="Header">

	<div class="usa-grid">
		<div class="usa-width-one-whole">

            <div class="ncbi-header__logo">
                <a href="https://www.ncbi.nlm.nih.gov/" class="logo" aria-label="NCBI Logo" data-ga-action="click_image" data-ga-label="NIH NLM Logo">
                  <img src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/AgencyLogo.svg" alt="NIH NLM Logo">
                </a>
            </div>

			<div class="ncbi-header__account">
				<a id="account_login" href="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F" class="usa-button header-button" style="" data-ga-action="open_menu" data-ga-label="account_menu">Log in</a>
				<button id="account_info" class="header-button" style="display:none" aria-controls="account_popup" aria-haspopup="true" aria-expanded="false">
					<span class="fa fa-user" aria-hidden="true"></span>
					<span class="username desktop-only" aria-hidden="true" id="uname_short"></span>
					<span class="sr-only">Show account info</span>
				</button>
			</div>

			<div class="ncbi-popup-anchor">
				<div class="ncbi-popup account-popup" id="account_popup" aria-hidden="true" tabindex="-1" aria-modal="true" style="display: none;">
					<div class="ncbi-popup-head">
						<button class="ncbi-close-button" data-ga-action="close_menu" data-ga-label="account_menu"><span class="fa fa-times"></span><span class="usa-sr-only">Close</span></button>
						<h4>Account</h4>
					</div>
					<div class="account-user-info">
						Logged in as:<br>
						<b><span class="username" id="uname_long">username</span></b>
					</div>
					<div class="account-links">
						<ul class="usa-unstyled-list">
							<li><a id="account_myncbi" href="https://www.ncbi.nlm.nih.gov/myncbi/" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_myncbi">Dashboard</a></li>
							<li><a id="account_pubs" href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_pubs">Publications</a></li>
							<li><a id="account_settings" href="https://www.ncbi.nlm.nih.gov/account/settings/" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_settings">Account settings</a></li>
							<li><a id="account_logout" href="https://www.ncbi.nlm.nih.gov/account/signout/?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F" class="set-base-url" data-ga-action="click_menu_item" data-ga-label="account_logout">Log out</a></li>
						</ul>
					</div>
				</div>
			</div>

		</div>
	</div>
</header>
<div role="navigation" aria-label="access keys">
<a id="nws_header_accesskey_0" href="https://www.ncbi.nlm.nih.gov/guide/browsers/#ncbi_accesskeys" class="usa-sr-only" accesskey="0" tabindex="-1">Access keys</a>
<a id="nws_header_accesskey_1" href="https://www.ncbi.nlm.nih.gov/" class="usa-sr-only" accesskey="1" tabindex="-1">NCBI Homepage</a>
<a id="nws_header_accesskey_2" href="https://www.ncbi.nlm.nih.gov/myncbi/" class="set-base-url usa-sr-only" accesskey="2" tabindex="-1">MyNCBI Homepage</a>
<a id="nws_header_accesskey_3" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#maincontent" class="usa-sr-only" accesskey="3" tabindex="-1">Main Content</a>
<a id="nws_header_accesskey_4" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" class="usa-sr-only" accesskey="4" tabindex="-1">Main Navigation</a>
</div>

<!-- ========== END HEADER ========== -->

    
    
        
        <header class="pmc-header usa-header-extended" role="banner">
    <div class="pmc-header__bar">
        <div class="pmc-header__control usa-accordion">
            
                <button class="usa-menu-btn pmc-header--button pmc-header--left">
                    <i class="fa fa-ellipsis-v" aria-hidden="true"></i>
                </button>
            

            <div class="usa-logo pmc-header__logo pmc-header--stretch
                
               " id="extended-mega-logo">
                <div class="usa-logo-text">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/" title="Home" aria-label="Home"></a>
                </div>
            </div>
            <button class="usa-accordion-button pmc-header--right pmc-header--button pmc-header__search--control pmc-header--right" aria-expanded="false" aria-controls="a1">
                <i class="fa fa-search" aria-hidden="true"></i>
                <i class="fa fa-times" aria-hidden="true"></i>
            </button>
        </div>
        <div class="pmc-header__search usa-accordion-content" id="a1" aria-hidden="true">
            <div role="search" class="pmc-header--stretch">
    <form class="usa-search " autocomplete="off">
        <div>
              <label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
              <span class="clearable">
                <span class="twitter-typeahead ncbi-autocomplete"><input required="required" autocomplete-url="/pmc/autocomplete/pmc/" placeholder="Search PMC Full-Text Archive" id="pmc-search" type="search" name="term" class="tt-input" spellcheck="false" dir="auto" aria-owns="pmc-search_listbox" role="combobox" aria-autocomplete="list" aria-expanded="false" style="position: relative; vertical-align: top;"><span role="status" aria-live="polite" style="position: absolute; padding: 0px; border: 0px; height: 1px; width: 1px; margin-bottom: -1px; margin-right: -1px; overflow: hidden; clip: rect(0px, 0px, 0px, 0px); white-space: nowrap;"></span><pre aria-hidden="true" style="position: absolute; visibility: hidden; white-space: pre; font-family: Roboto, &quot;Helvetica Neue&quot;, Arial, Tahoma; font-size: 16px; font-style: normal; font-variant: normal; font-weight: 400; word-spacing: 0px; letter-spacing: 0px; text-indent: 0px; text-rendering: auto; text-transform: none;"></pre><div role="listbox" class="tt-menu" id="pmc-search_listbox" style="position: absolute; top: 100%; left: 0px; z-index: 100; display: none;"><div role="presentation" class="tt-dataset tt-dataset-0"></div></div></span>
                  <i class="clear-btn"></i>
              </span>
              <button type="submit" formaction="/pmc/">
                <span class="usa-search-submit-text">Search in PMC</span>
              </button>
        </div>
    </form>
</div>


            <ul class="usa-unstyled-list usa-nav-secondary-links pmc-header--offset-two">
                    <li>
                        <a href="https://www.ncbi.nlm.nih.gov/pmc/advanced" data-ga-action="featured_link" data-ga-label="advanced_search">
                            Advanced Search
                        </a>
                    </li>
                    <li>
                        <a href="https://www.ncbi.nlm.nih.gov/pmc/about/userguide/" data-ga-action="featured_link" data-ga-label="user guide">
                            User Guide
                        </a>
                    </li>
            </ul>
        </div>
    </div>
     <nav role="navigation" class="usa-nav ">
        <button class="usa-nav-close">
            <i class="fa fa-times" aria-hidden="true"></i>
        </button>
        <div class="usa-breadcrumb usa-breadcrumb--wrap usa-breadcrumb--hack">
             
    <ul class="usa-breadcrumb__list">
            
                <li class="usa-breadcrumb__list-item">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/" class="navlink">Journal List</a>
                </li>
            
                <li class="usa-breadcrumb__list-item">
                    <a class="navlink" href="https://www.ncbi.nlm.nih.gov/pmc/journals/4174/">J Healthc Inform Res</a>
                </li>
            
                <li class="usa-breadcrumb__list-item">
                    <a class="navlink" href="https://www.ncbi.nlm.nih.gov/pmc/issues/404748/">v.4(1); 2020 Mar</a>
                </li>
            
                <li class="usa-breadcrumb__list-item" aria-current="page">
                    PMC8982799
                </li>
            
    </ul>
 

        </div>
        
        
            <div class="pmc-sidebar pmc-sidebar-hack">
                

<div class="scroller">

    
        <section>
                <h6>Other Formats</h6>
                <ul class="pmc-sidebar__formats">
                  <li class="pubreader-link other_item"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/?report=reader" class="sidefm-pmclink">PubReader</a></li>
<li class="pdf-link other_item"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/pdf/41666_2019_Article_61.pdf" class="int-view">PDF (1.5M)</a></li>
                </ul>
        </section>
    
    <section>
        <h6>Actions</h6>
        <ul class="pmc-sidebar__actions">
            <li>
                <button role="button" class="citation-button citation-dialog-trigger ctxp" aria-label="Open dialog with citation text in different styles" data-ga-category="save_share" data-ga-action="cite" data-ga-label="open" data-all-citations-url="/pmc/resources/citations/8982799/" data-citation-style="nlm" data-download-format-link="/pmc/resources/citations/8982799/export/">
                    <span class="button-label">Cite</span>
                </button>
            </li>
            <li>
                
                    

<div class="collections-button-container" data-article-id="8982799" data-article-db="pmc">
  <button class="collections-button collections-dialog-trigger collections-button-empty" aria-label="Save article in MyNCBI collections." data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_button" data-collections-open-dialog-enabled="false" data-collections-open-dialog-url="https://www.ncbi.nlm.nih.gov/account?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F%23open-collections-dialog" data-in-collections="false">
      <span class="button-label">Collections</span>
  </button>
  <div class="overlay collections-dialog-overlay" role="dialog">
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true" role="document">
    <div class="title">Add to Collections</div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form" class="collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors" data-existing-collections-url="/pmc/list-existing-collections/" data-add-to-existing-collection-url="/pmc/add-to-existing-collection/" data-create-and-add-to-new-collection-url="/pmc/create-and-add-to-new-collection/" data-myncbi-max-collection-name-length="100" data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

  <input type="hidden" name="csrfmiddlewaretoken" value="Z1wlUS2IdMoRH6er7wVEUXiJxGaWCn1Q6W71YasyERnavgTnHGolLdY3kfv1MEhC">

  

  <div class="choice-group" role="radiogroup">
    <ul class="radio-group-items">
      <li>
        <input type="radio" id="collections-action-dialog-new-header " class="collections-new" name="collections" value="new" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_new">
        <label for="collections-action-dialog-new-header ">Create a new collection</label>
      </li>
      <li>
        <input type="radio" id="collections-action-dialog-existing-header " class="collections-existing" name="collections" value="existing" checked="true" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_existing">
        <label for="collections-action-dialog-existing-header ">Add to an existing collection</label>
      </li>
    </ul>
  </div>

  <div class="controls-wrapper">
    <div class="action-panel-control-wrap new-collections-controls">
      <label for="collections-action-dialog-add-to-new" class="action-panel-label required-field-asterisk">
        Name your collection:
      </label>
      <input type="text" name="add-to-new-collection" id="collections-action-dialog-add-to-new" class="collections-action-add-to-new" pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/" maxlength="" data-ga-category="collections_button" data-ga-action="create_collection" data-ga-label="non_favorties_collection">
      <div class="collections-new-name-too-long usa-input-error-message selection-validation-message">
        Name must be less than  characters
      </div>
    </div>
    <div class="action-panel-control-wrap existing-collections-controls">
      <label for="collections-action-dialog-add-to-existing" class="action-panel-label">
        Choose a collection:
      </label>
      <select id="collections-action-dialog-add-to-existing" class="action-panel-selector collections-action-add-to-existing" data-ga-category="collections_button" data-ga-action="select_collection" data-ga-label="($(&#39;.collections-action-add-to-existing&#39;).val() === &#39;Favorites&#39;) ? &#39;Favorites&#39; : &#39;non_favorites_collection&#39;">
      </select>
      <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
        Unable to load your collection due to an error<br>
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#">Please try again</a>
      </div>
    </div>
  </div>

  <div class="action-panel-actions">
    <button class="action-panel-submit" type="submit" data-loading-label="Adding..." data-pinger-ignore="" data-ga-category="collections_button" data-ga-action="click" data-ga-label="add">
      Add
    </button>
    <button class="action-panel-cancel" aria-label="Close &#39;Add to Collections&#39; panel" ref="linksrc=close_collections_panel" aria-controls="collections-action-panel" aria-expanded="false" data-ga-category="collections_button" data-ga-action="click" data-ga-label="cancel">
      Cancel
    </button>
  </div>
</form>
    </div>
  </div>
</div>
</div>
                
            </li>

        </ul>
    </section>
    
        <section class="social-sharing">
            <h6>Share</h6>
            <ul class="pmc-sidebar__share">
                <li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F&amp;text=DeepFall%3A%20Non-Invasive%20Fall%20Detection%20with%20Deep%20Spatio-Temporal%20Convolutional%20Autoencoders" alt="Share on Twitter" aria-expanded="false" aria-haspopup="true"><i class="fa fa-twitter fa-stack-1x">&nbsp;</i></a></li> 
<li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F" alt="Share on Facebook" aria-expanded="false" aria-haspopup="true"><i class="fa fa-facebook fa-stack-1x">&nbsp;</i></a></li>
                <li>
                    <div class="share-permalink dropdown-block">
                        <button class="trigger" alt="Show article permalink" aria-expanded="false" aria-haspopup="true">
                            <i class="fa-stack fa-lg">
                                <i class="fa fa-link fa-stack-1x">&nbsp;</i>
                            </i>
                        </button>
                        <div class="dropdown dropdown-container" aria-hidden="true">
                              <div class="title">
                                Permalink
                              </div>
                              <div class="content">
                                  <input type="text" class="permalink-text" value="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/" aria-label="Article permalink"><button class="permalink-copy-button usa-button-primary" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                                      <span class="button-title">Copy</span>
                                  </button>
                              </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
    
    <section>
        <h6>RESOURCES</h6>
        <ul class="pmc-sidebar__resources">
        
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_similar_articles" data-ga-label="/pmc/articles/PMC8982799/" class="usa-accordion-button" aria-controls="similar-articles-accordion-header" aria-expanded="false" data-action-open="open_similar_articles" data-action-close="close_similar_articles">
                        Similar articles
                    </button>
                    <div data-source-url="/pmc/resources/similar-article-links/35415435/" class="usa-accordion-content pmc-sidebar__resources--citations" id="similar-articles-accordion-header" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_cited_by" data-ga-label="/pmc/articles/PMC8982799/" class="usa-accordion-button" aria-controls="cited-by-accordion-header" aria-expanded="false" data-action-open="open_cited_by" data-action-close="close_cited_by">
                        Cited by other articles
                    </button>
                    <div data-source-url="/pmc/resources/cited-by-links/35415435/" class="usa-accordion-content pmc-sidebar__resources--citations" id="cited-by-accordion-header" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_NCBI_links" data-ga-label="/pmc/articles/PMC8982799/" class="usa-accordion-button" aria-controls="links-accordion-header" aria-expanded="false" data-action-open="open_NCBI_links" data-action-close="close_NCBI_link">
                        Links to NCBI Databases
                    </button>
                    <div data-source-url="/pmc/resources/db-links/8982799/" class="usa-accordion-content" id="links-accordion-header" aria-hidden="true"></div>
                </div>
            </li>

            
        
        </ul>
    </section>

 </div>
            </div>
        

    </nav>

</header>

    
    

    <div class="usa-overlay"></div>
    
<main id="main-content" class="usa-grid usa-layout-docs pmc-main">
    <article class="usa-width-three-fourths usa-layout-docs-main_content pmc-article">
        <section class="usa-breadcrumb usa-breadcrumb--wrap">
         
    <ul class="usa-breadcrumb__list">
            
                <li class="usa-breadcrumb__list-item">
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/" class="navlink">Journal List</a>
                </li>
            
                <li class="usa-breadcrumb__list-item">
                    <a class="navlink" href="https://www.ncbi.nlm.nih.gov/pmc/journals/4174/">J Healthc Inform Res</a>
                </li>
            
                <li class="usa-breadcrumb__list-item">
                    <a class="navlink" href="https://www.ncbi.nlm.nih.gov/pmc/issues/404748/">v.4(1); 2020 Mar</a>
                </li>
            
                <li class="usa-breadcrumb__list-item" aria-current="page">
                    PMC8982799
                </li>
            
    </ul>
 

        </section>
        
  <div class="pmc-article__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br>
    Learn more:
    <a data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="https://www.ncbi.nlm.nih.gov/pmc/about/disclaimer/">PMC Disclaimer</a>
    |
    <a data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="https://www.ncbi.nlm.nih.gov/pmc/about/copyright/">
        PMC Copyright Notice
    </a>
</div>

        <section class="pmc-page-banner" role="banner">
            
                
                    <div><img src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/logo-jhir.png" alt="Logo of jhir" usemap="#logo-imagemap"><map id="logo-imagemap" name="logo-imagemap"><area alt="Link to Publisher&#39;s site" title="Link to Publisher&#39;s site" shape="default" coords="0,0,499,74" href="https://www.springer.com/journal/41666" target="_blank" rel="noopener noreferrer" ref="reftype=publisher&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CBanner&amp;TO=Publisher%7COther%7CN/A"></map></div> 
                
            
        </section>
        <section role="document">
            
                <div id="mc" class=" article lit-style content pmc-wm slang-all page-box"><!--main-content--><div class="jig-ncbiinpagenav" data-jigconfig="smoothScroll: false, allHeadingLevels: [&#39;h2&#39;], headingExclude: &#39;:hidden,.nomenu&#39;" id="ui-ncbiinpagenav-1"><div class="fm-sec half_rhythm no_top_margin"><div class="fm-flexbox"><div class="fm-citation"><div class="citation-default"><div class="part1"><span role="menubar"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" role="menuitem" aria-expanded="false" aria-haspopup="true">J Healthc Inform Res.</a></span> 2020 Mar; 4(1): 50–70. </div><div class="part2"><span class="fm-vol-iss-date">Published online 2019 Dec 18. </span>  <span class="doi"><span>doi:&nbsp;</span><a href="https://doi.org/10.1007%2Fs41666-019-00061-4" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CFront%20Matter&amp;TO=Content%20Provider%7CCrosslink%7CDOI">10.1007/s41666-019-00061-4</a></span></div></div></div><div class="fm-ids"><div class="fm-citation-pmcid"><span class="fm-citation-ids-label">PMCID: </span><span>PMC8982799</span></div><div class="fm-citation-pmid">PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/35415435">35415435</a></div></div></div><h1 class="content-title">DeepFall: Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders</h1><div class="half_rhythm"><div class="contrib-group fm-author"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Nogas%20J%5BAuthor%5D" class="affpopup" co-rid="_co_idm140326275578160" co-class="co-affbox">Jacob Nogas</a>,<sup><img src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/corrauth.gif" alt="corresponding author"></sup><sup>1</sup> <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Khan%20SS%5BAuthor%5D" class="affpopup" co-rid="_co_idm140326265170752" co-class="co-affbox">Shehroz S. Khan</a>,<sup>1</sup> and  <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Mihailidis%20A%5BAuthor%5D" class="affpopup" co-rid="_co_idm140326272845872" co-class="co-affbox">Alex Mihailidis</a><sup>2</sup></div><div style="display:none" class="contrib-group aff-tip"><div id="_co_idm140326275578160"><h3 class="no_margin">Jacob Nogas</h3><p><sup>1</sup>University of Toronto, Toronto, Canada </p><div>Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Nogas%20J%5BAuthor%5D">Jacob Nogas</a></div></div><div id="_co_idm140326265170752"><h3 class="no_margin">Shehroz S. Khan</h3><p><sup>1</sup>University of Toronto, Toronto, Canada </p><div>Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Khan%20SS%5BAuthor%5D">Shehroz S. Khan</a></div></div><div id="_co_idm140326272845872"><h3 class="no_margin">Alex Mihailidis</h3><p><sup>2</sup>Toronto Rehabilitation Institute, University Health Network, Toronto, Canada </p><div>Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Mihailidis%20A%5BAuthor%5D">Alex Mihailidis</a></div></div></div></div><div class="half_rhythm"><div class="togglers fm-copyright-license"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" class="pmctoggle" rid="idm140326267101696_ai">Author information</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" class="pmctoggle" rid="idm140326267101696_an">Article notes</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" class="pmctoggle" rid="idm140326267101696_cpl">Copyright and License information</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/about/disclaimer/" style="margin-left: 1em">PMC Disclaimer</a></div><div class="fm-authors-info hide half_rhythm" id="idm140326267101696_ai" style="display:none"><div class="fm-affl" id="Aff1"><sup>1</sup>University of Toronto, Toronto, Canada </div><div class="fm-affl" id="Aff2"><sup>2</sup>Toronto Rehabilitation Institute, University Health Network, Toronto, Canada </div><div><span class="fm-affl">Jacob Nogas, </span><span class="fm-affl"><span class="email-label">Email: </span><a href="mailto:dev@null" data-email="ac.otnorotu.liam@sagon.bocaj" class="oemail">ac.otnorotu.liam@sagon.bocaj</a></span>.</div><div><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#article-aaff-info">Contributor Information</a>.</div><div><sup><img src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/corrauth.gif" alt="corresponding author"></sup>Corresponding author.</div></div><div class="fm-article-notes hide half_rhythm" id="idm140326267101696_an" style="display:none"><div class="fm-pubdate half_rhythm">Received 2018 Oct 4; Revised 2019 Jul 12; Accepted 2019 Oct 25.</div></div><div class="permissions half_rhythm hide" id="idm140326267101696_cpl" style="display:none"><div class="fm-copyright half_rhythm"><a href="https://www.ncbi.nlm.nih.gov/pmc/about/copyright/">Copyright</a> © Springer Nature Switzerland AG 2019</div></div></div><div id="pmclinksbox" class="links-box whole_rhythm hidden" role="complementary" aria-label="Related or updated information about this article."></div></div><div class="sec"></div><div id="Abs1" lang="en" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><span role="menubar"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="menuitem" aria-expanded="false" aria-haspopup="true">Go to:</a></span></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Abs1title">Abstract</h2><!--article-meta--><div><p id="Par1" class="p p-first-last">Human falls rarely occur; however, detecting falls is very important from the health and safety perspective. Due to the rarity of falls, it is difficult to employ supervised classification techniques to detect them. Moreover, in these highly skewed situations, it is also difficult to extract domain-specific features to identify falls. In this paper, we present a novel framework, <em>DeepFall</em>, which formulates the fall detection problem as an anomaly detection problem. The <em>DeepFall</em> framework presents the novel use of deep spatio-temporal convolutional autoencoders to learn spatial and temporal features from normal activities using non-invasive sensing modalities. We also present a new anomaly scoring method that combines the reconstruction score of frames across a temporal window to detect unseen falls. We tested the <em>DeepFall</em> framework on three publicly available datasets collected through non-invasive sensing modalities, thermal camera and depth cameras, and show superior results in comparison with traditional autoencoder methods to identify unseen falls.</p></div><div class="sec"><strong class="kwd-title">Keywords: </strong><span class="kwd-text">Fall detection, Convolutional autoencoders, Spatio-temporal, Anomaly detection</span></div></div><div id="Sec1" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Sec1title">Introduction</h2><p id="Par2" class="p p-first">Each year, one out of five falls that older adults incur causes a serious injury to them such as broken bones or a head injury [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR4" rid="CR4" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">4</a>]. Among nursing home residents, on an average, 2.6 falls per person per year occur [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR28" rid="CR28" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">28</a>]. Detecting falls is important from the perspective of health and safety; however, due to the infrequent occurrence of falls, it is difficult to collect sufficient training data for them [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR17" rid="CR17" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">17</a>]. Given this lack of training data, there may be no or little training data for falls, and it will be hard to employ supervised classification techniques. There are also concerns that the sensing devices for the task of fall detection may be invasive and breach the privacy of a person [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR22" rid="CR22" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">22</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR36" rid="CR36" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">36</a>]. Some non-invasive sensing devices, such as a thermal or depth camera, may not fully reveal the identity of a person, but it is difficult to extract discriminative features to identify unseen falls, especially in a highly skewed data scenario [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR31" rid="CR31" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">31</a>].</p><p id="Par3">The research work discussed in this paper deals with identifying falls in video sequences captured from non-invasive sensing modalities, such as thermal and depth cameras, which may fully or partially protect the privacy of a person. We propose to address the problem of fall detection as an anomaly detection problem by considering the lack of fall data and the abundance of normal activities of daily living (ADL). The general idea explored in the paper is to train an autoencoder on normal activities and use their reconstruction error to identify unseen falls during testing. A deep autoencoder (DAE) can be used to learn features from normal ADL; however, it ignores the 2D structure of images and may force each feature to be global to span the entire visual field [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR21" rid="CR21" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">21</a>]. In visual recognition tasks, convolutional autoencoders (CAE) perform better because they can discover localized spatial features that repeat themselves over the input [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR21" rid="CR21" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">21</a>]. A video sequence embeds information in both space and time; therefore, spatio-temporal convolutional autoencoders are more relevant as they can learn a representation of local spatio-temporal patterns of frames in a video [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR1" rid="CR1" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">1</a>].</p><p id="Par4" class="p p-last">In this paper, we present a novel fall detection framework, <em>DeepFall</em>, which comprises (i) formulating fall detection as an anomaly detection problem, (ii) designing a deep spatio-temporal convolutional autoencoder (DSTCAE) and training it on only the normal ADL, and (iii) proposing a new anomaly score to detect unseen falls. The DSTCAE first encodes stacks of contiguous frames in a time window by performing 3D convolution/3D pooling. During the decoding phase, the DSTCAE uses 3D UpSampling, or 3D deconvolution to reconstruct the input window of frames. Reconstruction error for each frame within a window is then calculated. We then present a new method to compute anomaly score, termed as within-context score, which considers the reconstruction error of frames within a window and gives an anomaly score of a given window. The anomaly score can be used to identify an unseen fall during the testing phase of DSTCAE. To the best of our knowledge, this is the first time a DSTCAE has been used for fall detection problem. The present paper is an extension of our previous work [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR25" rid="CR25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>] and differs from it in the following manner:
</p><ul class="unordered" style="list-style-type:disc"><li><div id="Par5">In the previous work, we employed convolutional LSTM–based autoencoder (CLSTMAE). By contrast, in this paper, we use a different 3D convolutional autoencoder, DSTCAE, for learning spatio-temporal features from the normal ADL. Our results show that DSTCAE gives better results than CLSTMAE for all the datasets.</div></li><li><div id="Par6">The previous paper only tested CLSTMAE on thermal dataset, whereas in this paper we extend our experiments on two more depth camera–based fall detection datasets.</div></li><li><div id="Par7">The previous paper presented a frame-based anomaly score. However, in this paper, we present a new anomaly scoring method that takes the decision at the level of a window (comprising contiguous frames) and not individual frames, which resulted in similar or higher area under the curve (AUC) across all the datasets.</div></li><li><div id="Par8">In this paper, we did an additional experiment to understand the impact on AUC of designating an entire window as a fall by increasing the number of fall frames in it from 1 to the maximum size of the window. This experiment provided insights on choosing appropriate fall frames in a window before identifying it as a fall window using a given anomaly score.</div></li><li><div id="Par9">In the present paper, we compare CLSTMAE with three variants of DSTCAE for all the three datasets and also added new results from one-class nearest neighbors on the features learned through the DAE.</div></li></ul><p></p></div><div id="Sec2" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Sec2title">Related Work</h2><p id="Par10" class="p p-first">To the best of our knowledge, fall detection has not been addressed as an anomaly detection problem using unsupervised deep learning methods. Therefore, in this section, we present a review of literature on video anomaly detection, which is closer in concept to the work presented in this paper.</p><p id="Par11">Ribeiro et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR27" rid="CR27" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">27</a>] propose to use CAE for detecting anomalies in videos. They extract appearance and motion features from video frames and combine them to present different scenarios to the CAE. They train the CAE on only normal frames and use a regularized reconstruction error as a score to identify normal and anomalous frames. They extend their work by using reconstruction error from the CAE trained on normal video frames as an input to a one-class SVM and showed similar results [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR12" rid="CR12" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">12</a>]. Tran and Hogg [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR32" rid="CR32" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">32</a>] use CAE and one-class SVM for video anomaly detection. They first extract foreground optical flow patches using an empirical threshold, then train a convolutional autoencoder on these patches, which learn hierarchical sparse representations in an unsupervised manner. After training the model, sparse features are extracted and fed to a one-class SVM to learn the concept of normality. Their method shows competitive performance on two datasets in comparison with existing state-of-the-art methods. Chalapathy et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR5" rid="CR5" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">5</a>] present a robust CAE that considers anomalies in the data and modify the objective function for training the model. They use the reconstruction error as a score and comment that their method is not over-sensitive to anomalies, can discover subtle anomalies, and can be potentially deployed in live settings. They show their results on a video activity detection dataset and other image datasets. Hasan et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR13" rid="CR13" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>] use both hand-crafted spatio-temporal features and fully convolutional feed-forward autoencoder to learn regular motion patterns in videos. They introduce a regularity score that scales the reconstruction error of a frame between 0 and 1. They show a competitive performance of their method to other state-of-the-art anomaly detection methods. Munawar et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR23" rid="CR23" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">23</a>] present a method to generate unbiased features by unsupervised learning for finding anomalies in industrial robot surveillance task. They cluster the input image data based on different image cues (such as color and gradient) to generate pseudo-class labels. Then, they simultaneously train the network on different pseudo-class labels to learn neutral feature representation using convolution neural networks. Finally, they use a deep long short term memory based recurrent neural network to predict the next video frame in the learned feature space. If it deviates significantly from the observed frame, it is identified as an anomaly in time and space. A fusion of appearance as well as motion features is used by Xu et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR35" rid="CR35" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">35</a>] to detect anomalies in video. More precisely, stacked denoising DAE networks are applied separately to optical flow and raw image patches. Anomalies in video are then detected in a one-class SVM framework.</p><p id="Par12">Zhao et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR37" rid="CR37" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">37</a>] present a spatio-temporal autoencoder that uses 3D convolutions to extract spatio-temporal features from videos. They further introduce a weight-decreasing prediction loss for generating future frames to improve the learning of motion features in videos. They tested their method on a dataset comprising a set of real-world traffic surveillance videos along with other standard anomaly detection datasets and show superior performance on state-of-the-art approaches. Penttilä [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR26" rid="CR26" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">26</a>] proposes to use 3D CAE to learn spatial and temporal features to find anomalies in hyperspectral data. After training the network, they extract feature maps from the data and feed to standard anomaly detection algorithms. A two-stage cascade of autoencoders is used by Sabokrou et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR29" rid="CR29" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">29</a>] to detect anomalies in video. In particular, spatio-temporal patches are fed to a 3D autoencoder, where regions of interest are detected. The proposed regions are then fed to a 3D convolutional neural network. The layers of the cascaded deep networks are designed as single-class Gaussian classifiers, which are used to detect anomalies in the video.</p><p id="Par13">Chong and Tay [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR8" rid="CR8" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">8</a>] present a method to detect anomalies in videos that consists of a spatial feature extractor and a temporal encoder-decoder framework. The spatial feature extractor comprises convolutional and deconvolutional layers, whereas the temporal encoder-decoder is a three-layer convolutional long short term memory model. This model will be referred to as CLSTMAE. Their model is trained only on the videos with normal scenes. They use a regularity score [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR13" rid="CR13" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>] to identify anomalies. They show comparable performance in comparison with other standard methods; however, it may produce more false alarms.</p><p id="Par14">The literature review suggests that spatio-temporal CAE are a good candidate to learn spatial and temporal features from normal activities and identify anomalies in videos. We expand on the previous works in the following ways:
</p><ul class="unordered" style="list-style-type:disc"><li><div id="Par15">None of the reviewed methods is used for fall detection problem. In <em>DeepFall</em>, we train a DSTCAE only on normal ADL and use a new anomaly scoring methods to identify a fall as an anomaly from non-invasive sensors with superior performance.</div></li><li><div id="Par16">In the above-related works which use reconstruction error in videos (and thus regularity score), an anomaly score is given strictly on a per-frame basis. That is, a video sequence is reconstructed, and each reconstructed frame used as an anomaly score for that frame. It is not obvious that using this score is ideal for the fall detection problem. We thus explore alternatives through our novel anomaly scoring scheme, which allows aggregating anomaly scores across overlapping sliding windows. In this scheme, we can find an anomaly score per frame, and that incorporates information from adjacent windows. Further, in this scheme, we also find an anomaly score on a per-window basis.</div></li><li><div id="Par17">The above authors use a regularity scoring system [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR13" rid="CR13" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>] as an anomaly score. The regularity score is a normalized reconstruction error. This normalization requires knowledge of the maximum and minimum reconstruction error for a video. Obtaining these maximum and minimum reconstruction error values requires reconstruction error for an entire video. This means that to give an anomaly score for a frame, we require reconstruction error values for all future frames of the video which this frame belongs to. Finding these future reconstruction error values is not practically feasible. We thus use the un-normalized reconstruction error in our anomaly scoring scheme.</div></li></ul><p>The reader may consult other papers on general anomaly detection that may involve methods besides neural networks [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR6" rid="CR6" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">6</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR10" rid="CR10" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">10</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR18" rid="CR18" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">18</a>].</p><p id="Par18" class="p p-last">In the next section, we introduce the different components of the <em>DeepFall</em> framework, which consists of a DSTCAE and anomaly scoring methods (after formulating fall detection in an anomaly detection setting).</p></div><div id="Sec3" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Sec3title">Deep Spatio-Temporal Convolutional Autoencoders</h2><p id="Par19" class="p p-first">Traditional autoencoders consist of fully connected layers [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR19" rid="CR19" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">19</a>]. When passing an image to such a network, it is flattened into a 1D vector of pixels, and each pixel is connected to the units of the next layer. This results in a large number of network parameters and learns spatially global features [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR21" rid="CR21" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">21</a>]. A CAE exploits the 2D spatial structure of an image, by sharing a set of weights across the image, resulting in far fewer parameters than a traditional autoencoder, and allowing the extraction of local features from neighboring pixels [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR21" rid="CR21" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">21</a>]. A CAE may be a good choice to find spatial structures in images, but it cannot capture temporal information present in the contiguous frames of a video [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR37" rid="CR37" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">37</a>]. 3D convolutions can be used to extract both temporal and spatial features by convolving a 3D kernel with the cube formed by stacking temporally contiguous frames of a video (we refer it as a window). This allows information across these contiguous frames to be connected to form feature maps, thereby capturing spatio-temporal information encoded in these adjacent frames [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR15" rid="CR15" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">15</a>]. This idea can be used to construct a DSTCAE, where the encoding phase consists of dimensionality reduction both in space and time of a window of images that are joined contiguously. In the decoding phase, the network attempts to reconstruct the window.</p><div id="Sec4" class="sec"><h3 id="Sec4title">Sliding Window Reconstruction</h3><p id="Par20" class="p p-first">The inputs to DSTCAE are windows of contiguous video frames. These windows are generated by applying a temporal sliding window to video frames, with window length <em>T</em>, padding (or not), and stride <em>B</em> (which represents the amount of frames shifted from one window to the next). If a video contains <em>V</em> frames, and padding is not used, then the number of windows (<em>D</em>) generated is
</p><div class="disp-formula" id="Equ1"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-1-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="M2" style="width: 10.617em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.156em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.81em, 1008.08em, 4.463em, -999.998em); top: -3.383em; left: 0em;"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3" style="font-family: MathJax_Math-italic;">D</span><span class="mo" id="MathJax-Span-4" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mo" id="MathJax-Span-5" style="vertical-align: 0em; padding-left: 0.271em;"><span style="font-family: MathJax_Size3;">⌊</span></span><span class="mfrac" id="MathJax-Span-6"><span style="display: inline-block; position: relative; width: 2.848em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.194em, 1002.73em, 4.194em, -999.998em); top: -4.69em; left: 50%; margin-left: -1.344em;"><span class="mrow" id="MathJax-Span-7"><span class="mi" id="MathJax-Span-8" style="font-family: MathJax_Math-italic;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.194em;"></span></span><span class="mo" id="MathJax-Span-9" style="font-family: MathJax_Main; padding-left: 0.233em;">−</span><span class="mi" id="MathJax-Span-10" style="font-family: MathJax_Math-italic; padding-left: 0.233em;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.117em, -999.998em); top: -3.306em; left: 50%; margin-left: -0.383em;"><span class="mrow" id="MathJax-Span-11"><span class="mi" id="MathJax-Span-12" style="font-family: MathJax_Math-italic;">B</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1002.85em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 2.848em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="mo" id="MathJax-Span-13" style="vertical-align: 0em;"><span style="font-family: MathJax_Size3;">⌋</span></span><span class="mo" id="MathJax-Span-14" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="mn" id="MathJax-Span-15" style="font-family: MathJax_Main; padding-left: 0.233em;">1</span></span><span style="display: inline-block; width: 0px; height: 3.387em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.297em; border-left: 0px solid; width: 0px; height: 3.202em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-1"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M2"><mi>D</mi><mo>=</mo><mo>⌊</mo><mfrac><mrow><mi>V</mi><mo>−</mo><mi>T</mi></mrow><mrow><mi>B</mi></mrow></mfrac><mo>⌋</mo><mo>+</mo><mn>1</mn></math></script></div><div class="l">1</div></div><p></p><p id="Par21" class="p p-last">In our implementation of DSTCAE, we chose <em>T</em> = 8 (this choice is explained in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec15" rid="Sec15" class=" sec">5.2</a>), no padding, and <em>B</em> = 1, which ensure that all the frames of the video are selected in forming windows. We re-size all the input frames to 64 × 64. The resulting network input (<em>I</em>) thus has dimensions of 8 × 64 × 64. DSTCAE encodes <em>I</em> into spatio-temporal features and then attempts to reconstruct it from the encoded representation. For training DSTCAE, we use mean squared error loss between <em>I</em> and reconstructed output window <em>O</em> (same dimensions as <em>I</em>), optimized on a per batch basis, giving the following cost function:
</p><div class="disp-formula" id="Equ2"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-2-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="M4" style="width: 14.925em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.463em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.54em, 1011.46em, 4.579em, -999.998em); top: -3.383em; left: 0em;"><span class="mrow" id="MathJax-Span-17"><span class="mi" id="MathJax-Span-18" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span><span class="mo" id="MathJax-Span-19" style="vertical-align: 0em;"><span style="font-family: MathJax_Size3;">(</span></span><span class="mi" id="MathJax-Span-20" style="font-family: MathJax_Math-italic;">θ</span><span class="mo" id="MathJax-Span-21" style="vertical-align: 0em;"><span style="font-family: MathJax_Size3;">)</span></span><span class="mo" id="MathJax-Span-22" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mfrac" id="MathJax-Span-23" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 1.002em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.233em, 1000.42em, 4.117em, -999.998em); top: -4.69em; left: 50%; margin-left: -0.229em;"><span class="mrow" id="MathJax-Span-24"><span class="mn" id="MathJax-Span-25" style="font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1000.89em, 4.117em, -999.998em); top: -3.306em; left: 50%; margin-left: -0.46em;"><span class="mrow" id="MathJax-Span-26"><span class="mi" id="MathJax-Span-27" style="font-family: MathJax_Math-italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1001em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 1.002em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="munderover" id="MathJax-Span-28"><span style="display: inline-block; position: relative; width: 1.156em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0.04em;"><span class="mrow" id="MathJax-Span-29"><span class="mi" id="MathJax-Span-30" style="font-family: MathJax_Size1;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.08em, 4.233em, -999.998em); top: -3.113em; left: 0em;"><span class="mrow" id="MathJax-Span-31"><span class="mi" id="MathJax-Span-32" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-33" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-34" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.31em, 1000.62em, 4.117em, -999.998em); top: -4.96em; left: 0.271em;"><span class="mrow" id="MathJax-Span-35"><span class="mi" id="MathJax-Span-36" style="font-size: 70.7%; font-family: MathJax_Math-italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-37" style="font-family: MathJax_Main; padding-left: 0.271em;">∥</span><span class="msub" id="MathJax-Span-38" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 0.771em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.5em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-39"><span class="mi" id="MathJax-Span-40" style="font-family: MathJax_Math-italic;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.425em;"><span class="mrow" id="MathJax-Span-41"><span class="mi" id="MathJax-Span-42" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-43" style="font-family: MathJax_Main; padding-left: 0.233em;">−</span><span class="msub" id="MathJax-Span-44" style="padding-left: 0.233em;"><span style="display: inline-block; position: relative; width: 1.079em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.73em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-45"><span class="mi" id="MathJax-Span-46" style="font-family: MathJax_Math-italic;">O</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-47"><span class="mi" id="MathJax-Span-48" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-49" style=""><span style="display: inline-block; position: relative; width: 0.925em; height: 0px;"><span style="position: absolute; clip: rect(2.348em, 1000.39em, 5.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-50"><span class="mo" id="MathJax-Span-51" style="vertical-align: 1.54em;"><span style="display: inline-block; position: relative; width: 0.502em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -3.229em; left: 0em;">∥<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -1.69em; left: 0em;">∥<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -2.46em; left: 0em;">∥<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.42em, 4.117em, -999.998em); top: -5.267em; left: 0.502em;"><span class="mrow" id="MathJax-Span-52"><span class="mn" id="MathJax-Span-53" style="font-size: 70.7%; font-family: MathJax_Main;">2</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.42em, 4.117em, -999.998em); top: -2.921em; left: 0.502em;"><span class="mrow" id="MathJax-Span-54"><span class="mn" id="MathJax-Span-55" style="font-size: 70.7%; font-family: MathJax_Main;">2</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.387em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.448em; border-left: 0px solid; width: 0px; height: 3.752em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-2"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M4"><mi>C</mi><mo>(</mo><mi>𝜃</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>N</mi></mrow></mfrac><munderover accent="false" accentunder="false"><mrow><mi>∑</mi></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi></mrow></munderover><mo>∥</mo><msub><mrow><mi>I</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mi>O</mi></mrow><mrow><mi>i</mi></mrow></msub><msubsup><mrow><mo>∥</mo></mrow><mrow><mn>2</mn></mrow><mrow><mn>2</mn></mrow></msubsup></math></script></div><div class="l">2</div></div><p>where <em>N</em> is the number of training samples in a batch, <em>𝜃</em> denotes the network parameters, and ∥⋅∥<sub>2</sub> denotes the Euclidean norm.</p></div><div id="Sec5" class="sec"><h3 id="Sec5title">3D Convolutions</h3><p id="Par22" class="p p-first-last">The main component of a DSTCAE is the 3D convolutional layer, which is defined as follows: the value <em>v</em> at position (<em>x</em>,<em>y</em>,<em>z</em>) of the <em>j</em> th feature map in the <em>i</em> th 3D convolution layer, with bias <em>b</em><sub><em>i</em><em>j</em></sub>, is given by the equation [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR15" rid="CR15" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">15</a>]
</p><div class="disp-formula" id="Equ3"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-3-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="M6" style="width: 27.617em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.233em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(2.156em, 1021em, 5.348em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-57"><span class="msubsup" id="MathJax-Span-58"><span style="display: inline-block; position: relative; width: 1.656em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.46em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-59"><span class="mi" id="MathJax-Span-60" style="font-family: MathJax_Math-italic;">v</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1001.16em, 4.271em, -999.998em); top: -4.498em; left: 0.502em;"><span class="mrow" id="MathJax-Span-61"><span class="mi" id="MathJax-Span-62" style="font-size: 70.7%; font-family: MathJax_Math-italic;">x</span><span class="mi" id="MathJax-Span-63" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-64" style="font-size: 70.7%; font-family: MathJax_Math-italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.62em, 4.271em, -999.998em); top: -3.69em; left: 0.502em;"><span class="mrow" id="MathJax-Span-65"><span class="mi" id="MathJax-Span-66" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-67" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-68" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mi" id="MathJax-Span-69" style="font-family: MathJax_Math-italic; padding-left: 0.271em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span><span class="mfenced" id="MathJax-Span-70"><span class="mo" id="MathJax-Span-168" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">(</span></span><span class="mrow" id="MathJax-Span-72"><span class="munder" id="MathJax-Span-73"><span style="display: inline-block; position: relative; width: 1.04em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-74"><span class="mi" id="MathJax-Span-75" style="font-family: MathJax_Size1;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.62em, 4.233em, -999.998em); top: -3.152em; left: 0.233em;"><span class="mrow" id="MathJax-Span-76"><span class="mi" id="MathJax-Span-77" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="munderover" id="MathJax-Span-78"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0.271em;"><span class="mrow" id="MathJax-Span-79"><span class="mi" id="MathJax-Span-80" style="font-family: MathJax_Size1;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.23em, 4.348em, -999.998em); top: -3.113em; left: 0.156em;"><span class="mrow" id="MathJax-Span-81"><span class="mi" id="MathJax-Span-82" style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span class="mo" id="MathJax-Span-83" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-84" style="font-size: 70.7%; font-family: MathJax_Main;">0</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.31em, 1001.54em, 4.233em, -999.998em); top: -4.96em; left: 0em;"><span class="mrow" id="MathJax-Span-85"><span class="msub" id="MathJax-Span-86"><span style="display: inline-block; position: relative; width: 0.694em; height: 0px;"><span style="position: absolute; clip: rect(3.387em, 1000.54em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-87"><span class="mi" id="MathJax-Span-88" style="font-size: 70.7%; font-family: MathJax_Math-italic;">P<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.883em; left: 0.463em;"><span class="mrow" id="MathJax-Span-89"><span class="mi" id="MathJax-Span-90" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-91" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-92" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="munderover" id="MathJax-Span-93"><span style="display: inline-block; position: relative; width: 1.694em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0.31em;"><span class="mrow" id="MathJax-Span-94"><span class="mi" id="MathJax-Span-95" style="font-family: MathJax_Size1;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.19em, 4.348em, -999.998em); top: -3.113em; left: 0.233em;"><span class="mrow" id="MathJax-Span-96"><span class="mi" id="MathJax-Span-97" style="font-size: 70.7%; font-family: MathJax_Math-italic;">q<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-98" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-99" style="font-size: 70.7%; font-family: MathJax_Main;">0</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.271em, 1001.66em, 4.271em, -999.998em); top: -5.037em; left: 0em;"><span class="mrow" id="MathJax-Span-100"><span class="msub" id="MathJax-Span-101"><span style="display: inline-block; position: relative; width: 0.771em; height: 0px;"><span style="position: absolute; clip: rect(3.387em, 1000.54em, 4.271em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-102"><span class="mi" id="MathJax-Span-103" style="font-size: 70.7%; font-family: MathJax_Math-italic;">Q</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.579em;"><span class="mrow" id="MathJax-Span-104"><span class="mi" id="MathJax-Span-105" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-106" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-107" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="munderover" id="MathJax-Span-108"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0.271em;"><span class="mrow" id="MathJax-Span-109"><span class="mi" id="MathJax-Span-110" style="font-family: MathJax_Size1;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.19em, 4.233em, -999.998em); top: -3.113em; left: 0.156em;"><span class="mrow" id="MathJax-Span-111"><span class="mi" id="MathJax-Span-112" style="font-size: 70.7%; font-family: MathJax_Math-italic;">s</span><span class="mo" id="MathJax-Span-113" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-114" style="font-size: 70.7%; font-family: MathJax_Main;">0</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.271em, 1001.5em, 4.233em, -999.998em); top: -4.96em; left: 0em;"><span class="mrow" id="MathJax-Span-115"><span class="msub" id="MathJax-Span-116"><span style="display: inline-block; position: relative; width: 0.656em; height: 0px;"><span style="position: absolute; clip: rect(3.387em, 1000.46em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-117"><span class="mi" id="MathJax-Span-118" style="font-size: 70.7%; font-family: MathJax_Math-italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.883em; left: 0.425em;"><span class="mrow" id="MathJax-Span-119"><span class="mi" id="MathJax-Span-120" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-121" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-122" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-123"><span style="display: inline-block; position: relative; width: 1.963em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.69em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-124"><span class="mi" id="MathJax-Span-125" style="font-family: MathJax_Math-italic;">w</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1001.08em, 4.271em, -999.998em); top: -4.498em; left: 0.733em;"><span class="mrow" id="MathJax-Span-126"><span class="mi" id="MathJax-Span-127" style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span class="mi" id="MathJax-Span-128" style="font-size: 70.7%; font-family: MathJax_Math-italic;">q<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-129" style="font-size: 70.7%; font-family: MathJax_Math-italic;">s</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.23em, 4.271em, -999.998em); top: -3.69em; left: 0.733em;"><span class="mrow" id="MathJax-Span-130"><span class="mi" id="MathJax-Span-131" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-132" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mi" id="MathJax-Span-133" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-134"><span style="display: inline-block; position: relative; width: 5.963em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.46em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-135"><span class="mi" id="MathJax-Span-136" style="font-family: MathJax_Math-italic;">v</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.348em, 1005.46em, 4.31em, -999.998em); top: -4.537em; left: 0.502em;"><span class="mrow" id="MathJax-Span-137"><span class="mo" id="MathJax-Span-138" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-139" style="font-size: 70.7%; font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-140" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mi" id="MathJax-Span-141" style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span class="mo" id="MathJax-Span-142" style="font-size: 70.7%; font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-143" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-144" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-145" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mi" id="MathJax-Span-146" style="font-size: 70.7%; font-family: MathJax_Math-italic;">q<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-147" style="font-size: 70.7%; font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-148" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-149" style="font-size: 70.7%; font-family: MathJax_Math-italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mo" id="MathJax-Span-150" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mi" id="MathJax-Span-151" style="font-size: 70.7%; font-family: MathJax_Math-italic;">s</span><span class="mo" id="MathJax-Span-152" style="font-size: 70.7%; font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.348em, 1002.39em, 4.31em, -999.998em); top: -3.613em; left: 0.502em;"><span class="mrow" id="MathJax-Span-153"><span class="mo" id="MathJax-Span-154" style="font-size: 70.7%; font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-155" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-156" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-157" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-158" style="font-size: 70.7%; font-family: MathJax_Main;">)</span><span class="mi" id="MathJax-Span-159" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-160" style="font-family: MathJax_Main; padding-left: 0.233em;">+</span><span class="msub" id="MathJax-Span-161" style="padding-left: 0.233em;"><span style="display: inline-block; position: relative; width: 1.04em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.42em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-162"><span class="mi" id="MathJax-Span-163" style="font-family: MathJax_Math-italic;">b</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.425em;"><span class="mrow" id="MathJax-Span-164"><span class="mi" id="MathJax-Span-165" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-166" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-169" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -1.648em; border-left: 0px solid; width: 0px; height: 4.002em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-3"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M6"><msubsup><mrow><mi>v</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>x</mi><mi>y</mi><mi>z</mi></mrow></msubsup><mo>=</mo><mi>f</mi><mfenced close=")" open="("><mrow><munder><mrow><mi>∑</mi></mrow><mrow><mi>m</mi></mrow></munder><munderover accent="false" accentunder="false"><mrow><mi>∑</mi></mrow><mrow><mi>p</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><mn>1</mn></mrow></munderover><munderover accent="false" accentunder="false"><mrow><mi>∑</mi></mrow><mrow><mi>q</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mrow><mi>Q</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><mn>1</mn></mrow></munderover><munderover accent="false" accentunder="false"><mrow><mi>∑</mi></mrow><mrow><mi>s</mi><mo>=</mo><mn>0</mn></mrow><mrow><msub><mrow><mi>S</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><mn>1</mn></mrow></munderover><msubsup><mrow><mi>w</mi></mrow><mrow><mi>i</mi><mi>j</mi><mi>m</mi></mrow><mrow><mi>p</mi><mi>q</mi><mi>s</mi></mrow></msubsup><msubsup><mrow><mi>v</mi></mrow><mrow><mo>(</mo><mi>i</mi><mo>−</mo><mn>1</mn><mo>)</mo><mi>m</mi></mrow><mrow><mo>(</mo><mi>x</mi><mo>+</mo><mi>p</mi><mo>)</mo><mo>(</mo><mi>y</mi><mo>+</mo><mi>q</mi><mo>)</mo><mo>(</mo><mi>z</mi><mo>+</mo><mi>s</mi><mo>)</mo></mrow></msubsup><mo>+</mo><msub><mrow><mi>b</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow></mfenced></math></script></div><div class="l">3</div></div><p>where <em>P</em><sub><em>i</em></sub>, <em>Q</em><sub><em>i</em></sub>, and <em>S</em><sub><em>i</em></sub> are the vertical (spatial), horizontal (spatial), and temporal extent of the filter cube <em>w</em><sub><em>i</em></sub> in the <em>i</em> th layer. The set of feature maps from the (<em>i</em> − 1)th layer are indexed by <em>m</em>, and <span id="IEq1"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M8" style="width: 2.579em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.963em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.233em, 1001.96em, 2.733em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-171"><span class="msubsup" id="MathJax-Span-172"><span style="display: inline-block; position: relative; width: 1.963em; height: 0px;"><span style="position: absolute; clip: rect(3.425em, 1000.69em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-173"><span class="mi" id="MathJax-Span-174" style="font-family: MathJax_Math-italic;">w</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1001.08em, 4.271em, -999.998em); top: -4.498em; left: 0.733em;"><span class="mrow" id="MathJax-Span-175"><span class="mi" id="MathJax-Span-176" style="font-size: 70.7%; font-family: MathJax_Math-italic;">p</span><span class="mi" id="MathJax-Span-177" style="font-size: 70.7%; font-family: MathJax_Math-italic;">q<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span class="mi" id="MathJax-Span-178" style="font-size: 70.7%; font-family: MathJax_Math-italic;">s</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.23em, 4.271em, -999.998em); top: -3.69em; left: 0.733em;"><span class="mrow" id="MathJax-Span-179"><span class="mi" id="MathJax-Span-180" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-181" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mi" id="MathJax-Span-182" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.647em; border-left: 0px solid; width: 0px; height: 1.702em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-4"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8"><msubsup><mrow><mi>w</mi></mrow><mrow><mi>i</mi><mi>j</mi><mi>m</mi></mrow><mrow><mi>p</mi><mi>q</mi><mi>s</mi></mrow></msubsup></math></script></span> is the value of the filter cube at position <em>pqs</em> connected to the <em>m</em> th feature map in the previous layer. Multiple filter cubes will output multiple feature maps.</p></div><div id="Sec6" class="sec sec-last"><h3 id="Sec6title">3D Encoding and Decoding</h3><div id="FPar1" class="sec sec-first"><p></p><h4 id="FPar1title" class="inline">Encoding </h4><p id="Par23" class="p p-first-last">The input <em>I</em> introduced in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec3" rid="Sec3" class=" sec">3</a> in a DSTCAE is encoded by a sequence of 3D convolution and 3D-max-pooling layers. 3D convolutions operate as described in (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Equ3" rid="Equ3" class=" ">3</a>), with stride of 1 × 1 × 1 and padding. The max-pooling layers use padding, with stride and kernel dimensions of 2 × 2 × 2. This means that each dimension (temporal depth, height, and width) is reduced by a factor of 2 with every max-pooling layer. This process is repeated for 2 level of depth. For hidden layers (in both encoding and decoding), the activation function <em>f</em> in (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Equ3" rid="Equ3" class=" ">3</a>) is set to <strong>R</strong><strong>e</strong><strong>L</strong><strong>U</strong>. We use <em>P</em><sub><em>i</em></sub> = <em>Q</em><sub><em>i</em></sub> = 3 and <em>S</em><sub><em>i</em></sub> = 5 for all convolutional and deconvolutional layers, as these values were found to produce the best results across all data sets. The specification of the encoding and decoding process is shown in Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab1/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab1" rid-ob="ob-Tab1" co-legend-rid=""><span>1</span></a> and described in detail below.
</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="Tab1"><h3>Table 1</h3><!--caption a7--><div class="caption"><p>Configuration of the encoding and decoding of DSTCAE-UpSampling, DSTCAE-Deconv, and DSTCAE-C3D</p></div><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326265494752"><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=8982799_41666_2019_61_Figa_HTML.jpg" target="tileshopwindow" rel="noopener"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Figa_HTML.jpg" title="Click on image to zoom" class="tileshop" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Figa_HTML.jpg"></a></div><div class="largeobj-link align_right" id="largeobj_idm140326265494752" style="display: none;"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab1/?report=objectonly">Open in a separate window</a></div><div class="tblwrap-foot"><p>Encoding is in blue and decoding in yellow</p></div></div></div><div id="FPar2" class="sec sec-last"><p></p><h4 id="FPar2title" class="inline">Decoding </h4><p id="Par24" class="p p-first">For the decoding of DSTCAE, we explore two variants. The first method (DSTCAE-UpSampling) uses padded 3D convolutions with stride of 2 × 2 × 2, followed by a fixed UpSampling operation for increasing dimensions (as seen in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig1/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig1" rid-ob="ob-Fig1" co-legend-rid="lgnd_Fig1"><span>1</span></a>). In particular, we use 3D UpSampling layers as defined in Keras [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR7" rid="CR7" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">7</a>], with UpSampling factors 2 × 2 × 2. That is, matrix elements are repeated across each dimension, such that the extent of all dimensions is doubled. The second method (DSTCAE-Deconv) uses 3D deconvolutions [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR7" rid="CR7" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">7</a>], with stride of 2 × 2 × 2 and padding [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR37" rid="CR37" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">37</a>] instead of UpSampling. This results in an increase in each dimension by a factor of 2, thus undoing a max-pooling operation. For both the decoding methods, the output layer activation function <em>f</em> is set to <strong>t</strong><strong>a</strong><strong>n</strong><strong>h</strong>, computed element-wise in both cases. We use <strong>t</strong><strong>a</strong><strong>n</strong><strong>h</strong> for the output layer to limit the reconstructed pixel values in the range [− 1,1], so that they are comparable to the input (see Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec15" rid="Sec15" class=" sec">5.2</a>). In both decoding methods, outputs of the network (<em>O</em>) have the same dimensions as <em>I</em> and are generated by convolving a single filter cube with a final layer of feature maps. By proposing two methods for the decoding procedure in DSTCAE, we created two variants of the spatio-temporal autoencoder, whose performance are compared for detecting unseen falls in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec17" rid="Sec17" class=" sec">5.4</a>.
</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig1" co-legend-rid="lgnd_Fig1"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig1/" target="figure" rid-figpopup="Fig1" rid-ob="ob-Fig1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326261957376"><img loading="lazy" class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig1_HTML.jpg" title="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig1_HTML.jpg" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig1_HTML.jpg"></div></a><div class="largeobj-link align_right" id="largeobj_idm140326261957376" style="display: none;"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig1/" target="figure" rid-figpopup="Fig1" rid-ob="ob-Fig1"></a><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig1/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig1"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig1/" target="figure" rid-figpopup="Fig1" rid-ob="ob-Fig1">Fig. 1</a></div><!--caption a7--><div class="caption"><p>Out line of DSTCAE layers using fixed UpSampling (DSTCAE-UpSampling). Each layer has dimensions of temporal depth × height × width × number of feature maps</p></div></div></div><p id="Par25">A diagram illustrating the DSTCAE-UpSampling structure is shown in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig1/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig1" rid-ob="ob-Fig1" co-legend-rid="lgnd_Fig1"><span>1</span></a>. The first layer generates 16 feature maps (depicted in figure by vertical stacks), by convolving 16 different filter cubes with the input window of frames. This layer is followed by a 3D max-pooling layer. Convolution and pooling layers are repeated in this manner once more, resulting in an encoded dimension of 2 × 16 × 16 × 8. We choose to stop encoding at this point, in order to avoid collapsing the temporal dimension completely; a larger value of <em>T</em> would allow for a deeper network. Decoding then involves two UpSampling/3D convolution steps, bringing the hidden representation dimensions to 8 × 64 × 64 × 16. A final 3D convolution layer combines these 16 feature maps into the decoded reconstruction <em>O</em>.</p><p id="Par26">We also test a third 3D convolutional autoencoder variant, based on Tran et al. [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR9" rid="CR9" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">9</a>], which we refer to as DSTCAE-C3D. The DSTCAE-C3D network has the same encoding and decoding as DSTCAE-UpSampling, but with an extra 3D Convolution/3D max-pooling layer in encoding (see Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab1/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab1" rid-ob="ob-Tab1" co-legend-rid=""><span>1</span></a>) and extra 3D UpSampling/3D convolution in decoding. The extra 3D max-pooling has padding, with stride and kernel dimensions of 1 × 2 × 2. This results in spatial dimension reduction, but not temporal, allowing for greater network depth without collapsing the temporal dimension.</p><p id="Par27">To summarize, we compare three variants of DSTCAE: (1) DSTCAE-UpSampling: uses UpSampling for decoding, (2) DSTCAE-Deconv: uses deconvolution for decoding (similar to [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR37" rid="CR37" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">37</a>]), and (3) DSTCAE-C3D: uses UpSampling for decoding, but contains additional spatial pooling/unpooling layer. These architectures are summarized in Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab1/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab1" rid-ob="ob-Tab1" co-legend-rid=""><span>1</span></a>. In this table, encoding is highlighted in blue and decoding in yellow.</p><p id="Par28" class="p p-last">We compare these DSTCAE variants to 2D frame–based models CAE and DAE. Their specifications are shown in Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab2/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab2" rid-ob="ob-Tab2" co-legend-rid=""><span>2</span></a>. This table only shows the configuration of the encoding phase of the autoencoder. The decoding configuration is the same, but using UpSampling, or deconvolution for CAE (referred to as CAE-UpSampling and CAE-Decconv respectively), and more fully connected layers for DAE. Also, dropout is applied to layer 1 for DAE. We also use dropout for layer 2 for all DSTCAE variants. In all cases, the dropout probability is set to 0.25. Dropout was not found to be beneficial for CAE models and so was not used.
</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="Tab2"><h3>Table 2</h3><!--caption a7--><div class="caption"><p>Configuration of the encoding phase of CAE and DAE</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="left" rowspan="1" colspan="1">CAE</th><th align="left" rowspan="1" colspan="1">DAE</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Input - (64, 64, 1)</td><td align="left" rowspan="1" colspan="1">Input - (64,64,1)</td></tr><tr><td align="left" rowspan="1" colspan="1">2D Convolution - (64, 64, 16)</td><td align="left" rowspan="1" colspan="1">Fully Connected - (4096)</td></tr><tr><td align="left" rowspan="1" colspan="1">2D Max-pooling - (32, 32, 16)</td><td align="left" rowspan="1" colspan="1">Fully Connected - (150)</td></tr><tr><td align="left" rowspan="1" colspan="1">2D Convolution - (32, 32, 8)</td><td align="left" rowspan="1" colspan="1">Fully Connected - (100)</td></tr><tr><td align="left" rowspan="1" colspan="1">2D Max-pooling - (16, 16, 8)</td><td align="left" rowspan="1" colspan="1">Fully Connected - (50)</td></tr><tr><td align="left" rowspan="1" colspan="1">2D Convolution - (16, 16, 8)</td><td align="left" rowspan="1" colspan="1">–</td></tr><tr><td align="left" rowspan="1" colspan="1">2D Max-pooling - (8, 8, 8)</td><td align="left" rowspan="1" colspan="1">–</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140326273405488"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab2/?report=objectonly">Open in a separate window</a></div></div></div></div></div><div id="Sec7" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Sec7title">Anomaly Scores to Detect Unseen Falls</h2><p id="Par29" class="p p-first">In this paper, we formulated fall detection in a one-class classification framework [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR19" rid="CR19" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">19</a>], where normal ADL are available in abundance and no fall data is present during training. However, during testing, both normal ADL and falls may be present. Therefore, we detect falls as an anomaly. In the <em>DeepFall</em> framework, the general process for detecting unseen falls is
</p><ul class="unordered" style="list-style-type:disc"><li><div id="Par30">Train a given type of autoencoder by minimizing reconstruction error on ADL</div></li><li><div id="Par31">During testing, get reconstitution error of a frame (or a window comprising different frames); if the reconstruction error is “high,” then a fall is detected.</div></li></ul><p></p><p id="Par32">Previous anomaly scoring schemes involve using a regularity score [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR13" rid="CR13" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>], which is a normalized reconstruction error requiring future values from test frames, which is a major drawback in real-world deployment. We thus strictly use un-normalized reconstruction error.</p><p id="Par33">Further, previous anomaly scoring schemes [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR8" rid="CR8" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">8</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR13" rid="CR13" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">13</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR37" rid="CR37" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">37</a>] etc. compute an anomaly score on a per-frame basis, using the reconstruction error of that frame. Such a scoring scheme may not be ideal for the fall detection problem, and so we propose to explore a new anomaly scoring scheme, presented in this section. In our novel anomaly scoring scheme, we compute an anomaly score per frame, while also incorporating information about reconstruction error in adjacent overlapping sliding windows. We also explore computing an anomaly score on a per-window basis. The details of this anomaly scoring scheme are as follows:</p><p id="Par34">For CAE and DAE, the input to the network is a single frame; therefore, the reconstruction error is computed per frame. For all the variants of DSTCAE, the input to the network is a temporal window of <em>T</em> video frames. That is, given a test video sequence, we apply a sliding window as described in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec3" rid="Sec3" class=" sec">3</a>. For the <em>i</em> th window <em>I</em><sub><em>i</em></sub>, the network outputs a reconstruction of this window, <em>O</em><sub><em>i</em></sub>. The reconstruction error (<em>R</em><sub><em>i</em>,<em>j</em></sub>) between the <em>j</em> th frame of <em>I</em><sub><em>i</em></sub> and <em>O</em><sub><em>i</em></sub> can be calculated as
</p><div class="disp-formula" id="Equ4"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-5-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="M10" style="width: 10.925em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.387em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1008.39em, 2.656em, -999.998em); top: -2.229em; left: 0em;"><span class="mrow" id="MathJax-Span-184"><span class="msub" id="MathJax-Span-185"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-186"><span class="mi" id="MathJax-Span-187" style="font-family: MathJax_Math-italic;">R</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-188"><span class="mi" id="MathJax-Span-189" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-190" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-191" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-192" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mo" id="MathJax-Span-193" style="font-family: MathJax_Main;">∥</span><span class="msub" id="MathJax-Span-194" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.5em, 4.117em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-195"><span class="mi" id="MathJax-Span-196" style="font-family: MathJax_Math-italic;">I<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.425em;"><span class="mrow" id="MathJax-Span-197"><span class="mi" id="MathJax-Span-198" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-199" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-200" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-201" style="font-family: MathJax_Main; padding-left: 0.233em;">−</span><span class="msub" id="MathJax-Span-202" style="padding-left: 0.233em;"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.73em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-203"><span class="mi" id="MathJax-Span-204" style="font-family: MathJax_Math-italic;">O</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-205"><span class="mi" id="MathJax-Span-206" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-207" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-208" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-209" style=""><span style="display: inline-block; position: relative; width: 0.925em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1000.39em, 4.348em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-210"><span class="mo" id="MathJax-Span-211" style=""><span style="font-family: MathJax_Main;">∥</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.42em, 4.117em, -999.998em); top: -4.46em; left: 0.502em;"><span class="mrow" id="MathJax-Span-212"><span class="mn" id="MathJax-Span-213" style="font-size: 70.7%; font-family: MathJax_Main;">2</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.42em, 4.117em, -999.998em); top: -3.729em; left: 0.502em;"><span class="mrow" id="MathJax-Span-214"><span class="mn" id="MathJax-Span-215" style="font-size: 70.7%; font-family: MathJax_Main;">2</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.233em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.447em; border-left: 0px solid; width: 0px; height: 1.702em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-5"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M10"><msub><mrow><mi>R</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><mo>∥</mo><msub><mrow><mi>I</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>−</mo><msub><mrow><mi>O</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><msubsup><mrow><mo>∥</mo></mrow><mrow><mn>2</mn></mrow><mrow><mn>2</mn></mrow></msubsup></math></script></div><div class="l">4</div></div><p></p><p id="Par35" class="p">Figure&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig2/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig2" rid-ob="ob-Fig2" co-legend-rid="lgnd_Fig2"><span>2</span></a> shows the sliding window approach for <em>T</em> = 8. The first window of <em>T</em> = 8 frames, <em>I</em><sub>1</sub> (<em>F</em><em>r</em><sub>1</sub> to <em>F</em><em>r</em><sub>8</sub>) are reconstructed, and their corresponding reconstruction error is stored (<em>R</em><sub>1,1:8</sub>). For the next window of frames, the input window is shifted forward in time by one frame. This process continues until all frames are used.
</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig2" co-legend-rid="lgnd_Fig2"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig2/" target="figure" rid-figpopup="Fig2" rid-ob="ob-Fig2"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326272637936"><img loading="lazy" class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig2_HTML.jpg" title="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig2_HTML.jpg" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig2_HTML.jpg"></div></a><div class="largeobj-link align_right" id="largeobj_idm140326272637936" style="display: none;"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig2/" target="figure" rid-figpopup="Fig2" rid-ob="ob-Fig2"></a><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig2/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig2"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig2/" target="figure" rid-figpopup="Fig2" rid-ob="ob-Fig2">Fig. 2</a></div><!--caption a7--><div class="caption"><p>Temporal sliding window showing reconstruction error (<em>R</em><sub><em>i</em>,<em>j</em></sub>) per frame (<em>F</em><em>r</em><sub><em>j</em></sub>) with <em>T</em> = 8</p></div></div></div><div id="Sec8" class="sec"><h3 id="Sec8title">Cross-Context Anomaly Score</h3><p id="Par36" class="p p-first">To compare DSTCAE models with CAE and DAE, we must get a score per frame. A frame can appear in multiple windows. For instance, frame <em>F</em><em>r</em><sub>2</sub> (see Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig2/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig2" rid-ob="ob-Fig2" co-legend-rid="lgnd_Fig2"><span>2</span></a>) appears in two windows and thus gives two reconstruction errors: <em>R</em><sub>1,2</sub> and <em>R</em><sub>2,2</sub>. The former is attained when frame <em>F</em><em>r</em><sub>2</sub> was the second frame in the window, and the latter case when frame <em>F</em><em>r</em><sub>2</sub> was the first frame of the input window. Each window that a frame appears in provides a different temporal <em>context</em> within which this frame can be viewed. The cross-context anomaly score gives scores on a per-frame basis, by considering all of the reconstruction errors obtained for a frame across different windows (temporal contexts) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR25" rid="CR25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>]. For a frame <em>j</em>, an anomaly score can be calculated based on the mean (<span id="IEq2"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M12" style="width: 1.617em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.23em, 2.656em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-217"><span class="msubsup" id="MathJax-Span-218"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-219"><span class="mi" id="MathJax-Span-220" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-221"><span class="mi" id="MathJax-Span-222" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-223"><span class="mi" id="MathJax-Span-224" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.547em; border-left: 0px solid; width: 0px; height: 1.802em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-6"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></math></script></span>) or standard deviation (<span id="IEq3"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M14" style="width: 1.579em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.194em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.19em, 2.54em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-226"><span class="msubsup" id="MathJax-Span-227"><span style="display: inline-block; position: relative; width: 1.194em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-228"><span class="mi" id="MathJax-Span-229" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-230"><span class="mi" id="MathJax-Span-231" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.46em, 4.117em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-232"><span class="mi" id="MathJax-Span-233" style="font-size: 70.7%; font-family: MathJax_Math-italic;">σ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.398em; border-left: 0px solid; width: 0px; height: 1.602em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-7"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M14"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>σ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></math></script></span>) of the reconstruction errors (<em>R</em><sub><em>i</em>,<em>j</em></sub>) across different windows (or contexts):
</p><div class="disp-formula" id="Equ5"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-8-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="M16" style="width: 24.348em; display: inline-block;"><span style="display: inline-block; position: relative; width: 18.733em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(-2.652em, 1018.42em, 6.463em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-235"><span class="mtable eqnarray" id="MathJax-Span-236"><span style="display: inline-block; position: relative; width: 18.425em; height: 0px; margin-right: 0.156em; margin-left: 0.156em;"><span style="position: absolute; clip: rect(2.963em, 1001.23em, 9.002em, -999.998em); top: -6.806em; left: 0em;"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.002em, 1001.23em, 4.502em, -999.998em); top: -6.844em; right: 0em;"><span class="mtd eqnarray-1" id="MathJax-Span-237"><span class="mrow" id="MathJax-Span-238"><span class="msubsup" id="MathJax-Span-239"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-240"><span class="mi" id="MathJax-Span-241" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-242"><span class="mi" id="MathJax-Span-243" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-244"><span class="mi" id="MathJax-Span-245" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.002em, 1001.19em, 4.387em, -999.998em); top: -2.19em; right: 0em;"><span class="mtd eqnarray-1" id="MathJax-Span-312"><span class="mrow" id="MathJax-Span-313"><span class="msubsup" id="MathJax-Span-314"><span style="display: inline-block; position: relative; width: 1.194em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-315"><span class="mi" id="MathJax-Span-316" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-317"><span class="mi" id="MathJax-Span-318" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.46em, 4.117em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-319"><span class="mi" id="MathJax-Span-320" style="font-size: 70.7%; font-family: MathJax_Math-italic;">σ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 6.81em;"></span></span><span style="position: absolute; clip: rect(2.579em, 1000.73em, 7.694em, -999.998em); top: -5.883em; left: 2.002em;"><span style="display: inline-block; position: relative; width: 0.771em; height: 0px;"><span style="position: absolute; clip: rect(3.502em, 1000.73em, 4.002em, -999.998em); top: -6.844em; left: 50%; margin-left: -0.383em;"><span class="mtd eqnarray-2" id="MathJax-Span-246"><span class="mrow" id="MathJax-Span-247"><span class="mo" id="MathJax-Span-248" style="font-family: MathJax_Main;">=</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.502em, 1000.73em, 4.002em, -999.998em); top: -2.19em; left: 50%; margin-left: -0.383em;"><span class="mtd eqnarray-2" id="MathJax-Span-321"><span class="mrow" id="MathJax-Span-322"><span class="mo" id="MathJax-Span-323" style="font-family: MathJax_Main;">=</span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 5.887em;"></span></span><span style="position: absolute; clip: rect(5.04em, 1014.54em, 14.156em, -999.998em); top: -9.844em; left: 3.579em;"><span style="display: inline-block; position: relative; width: 14.848em; height: 0px;"><span style="position: absolute; clip: rect(2.233em, 1009.96em, 5.656em, -999.998em); top: -7.037em; left: 0em;"><span class="mtd eqnarray-3" id="MathJax-Span-249"><span class="mrow" id="MathJax-Span-250"><span class="mfenced" id="MathJax-Span-251"><span class="mo" id="MathJax-Span-366" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">{</span></span><span class="mrow" id="MathJax-Span-253"><span class="mtable array" id="MathJax-Span-254"><span style="display: inline-block; position: relative; width: 8.271em; height: 0px; margin-right: 0.156em; margin-left: 0.156em;"><span style="position: absolute; clip: rect(2.233em, 1005em, 5.656em, -999.998em); top: -4.19em; left: 0em;"><span style="display: inline-block; position: relative; width: 5.002em; height: 0px;"><span style="position: absolute; clip: rect(2.925em, 1004.89em, 4.617em, -999.998em); top: -4.883em; left: 50%; margin-left: -2.421em;"><span class="mtd array" id="MathJax-Span-255"><span class="mrow" id="MathJax-Span-256"><span class="mfrac" id="MathJax-Span-257"><span style="display: inline-block; position: relative; width: 0.463em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.383em; left: 50%; margin-left: -0.19em;"><span class="mrow" id="MathJax-Span-258"><span class="mn" id="MathJax-Span-259" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.27em, 4.271em, -999.998em); top: -3.652em; left: 50%; margin-left: -0.152em;"><span class="mrow" id="MathJax-Span-260"><span class="mi" id="MathJax-Span-261" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1000.46em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 0.463em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-262" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 2.271em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-263"><span class="mo" id="MathJax-Span-264" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.498em; left: 1.04em;"><span class="mrow" id="MathJax-Span-265"><span class="mi" id="MathJax-Span-266" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.23em, 4.117em, -999.998em); top: -3.69em; left: 1.04em;"><span class="mrow" id="MathJax-Span-267"><span class="mi" id="MathJax-Span-268" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-269" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-270" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="msub" id="MathJax-Span-271" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-272"><span class="mi" id="MathJax-Span-273" style="font-family: MathJax_Math-italic;">R</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-274"><span class="mi" id="MathJax-Span-275" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-276" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-277" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(2.925em, 1005em, 4.463em, -999.998em); top: -2.998em; left: 50%; margin-left: -2.498em;"><span class="mtd array" id="MathJax-Span-283"><span class="mrow" id="MathJax-Span-284"><span class="mfrac" id="MathJax-Span-285"><span style="display: inline-block; position: relative; width: 0.617em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.383em; left: 50%; margin-left: -0.19em;"><span class="mrow" id="MathJax-Span-286"><span class="mn" id="MathJax-Span-287" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.5em, 4.117em, -999.998em); top: -3.652em; left: 50%; margin-left: -0.229em;"><span class="mrow" id="MathJax-Span-288"><span class="mi" id="MathJax-Span-289" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1000.62em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 0.617em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-290" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 2.271em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-291"><span class="mo" id="MathJax-Span-292" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.58em, 4.117em, -999.998em); top: -4.46em; left: 1.04em;"><span class="mrow" id="MathJax-Span-293"><span class="mi" id="MathJax-Span-294" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.23em, 4.117em, -999.998em); top: -3.729em; left: 1.04em;"><span class="mrow" id="MathJax-Span-295"><span class="mi" id="MathJax-Span-296" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-297" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-298" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="msub" id="MathJax-Span-299" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-300"><span class="mi" id="MathJax-Span-301" style="font-family: MathJax_Math-italic;">R</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-302"><span class="mi" id="MathJax-Span-303" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-304" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-305" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.194em;"></span></span><span style="position: absolute; clip: rect(2.31em, 1002.42em, 5.31em, -999.998em); top: -3.998em; left: 5.81em;"><span style="display: inline-block; position: relative; width: 2.425em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1002.42em, 4.31em, -999.998em); top: -4.883em; left: 50%; margin-left: -1.229em;"><span class="mtd array" id="MathJax-Span-278"><span class="mrow" id="MathJax-Span-279"><span class="mi" id="MathJax-Span-280" style="font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-281" style="font-family: MathJax_Main; padding-left: 0.271em;">&lt;</span><span class="mi" id="MathJax-Span-282" style="font-family: MathJax_Math-italic; padding-left: 0.271em;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1002.42em, 4.31em, -999.998em); top: -2.998em; left: 50%; margin-left: -1.229em;"><span class="mtd array" id="MathJax-Span-306"><span class="mrow" id="MathJax-Span-307"><span class="mi" id="MathJax-Span-308" style="font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-309" style="font-family: MathJax_Main; padding-left: 0.271em;">≥</span><span class="mi" id="MathJax-Span-310" style="font-family: MathJax_Math-italic; padding-left: 0.271em;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-367" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">)</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.194em;"></span></span><span style="position: absolute; clip: rect(3.271em, 1014.54em, 8.694em, -999.998em); top: -4.421em; left: 0em;"><span class="mtd eqnarray-3" id="MathJax-Span-324"><span class="mrow" id="MathJax-Span-325"><span class="mfenced" id="MathJax-Span-326"><span class="mo" id="MathJax-Span-368" style="vertical-align: 2.848em;"><span style="display: inline-block; position: relative; width: 0.887em; height: 0px;"><span style="position: absolute; font-family: MathJax_Size4; top: -3.113em; left: 0em;">⎧<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: 0.348em; left: 0em;">⎩<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -1.152em; left: 0em;">⎨<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -2.806em; left: 0em;">⎪<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -2.537em; left: 0em;">⎪<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -2.267em; left: 0em;">⎪<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -0.19em; left: 0em;">⎪<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: 0.079em; left: 0em;">⎪<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: 0.348em; left: 0em;">⎪<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mrow" id="MathJax-Span-328"><span class="mtable array" id="MathJax-Span-329"><span style="display: inline-block; position: relative; width: 12.733em; height: 0px; margin-right: 0.156em; margin-left: 0.156em;"><span style="position: absolute; clip: rect(3.271em, 1009.46em, 8.694em, -999.998em); top: -6.229em; left: 0em;"><span style="display: inline-block; position: relative; width: 9.502em; height: 0px;"><span style="position: absolute; clip: rect(2.425em, 1009.31em, 5.04em, -999.998em); top: -5.383em; left: 50%; margin-left: -4.69em;"><span class="mtd array" id="MathJax-Span-330"><span class="mrow" id="MathJax-Span-331"><span class="msqrt" id="MathJax-Span-332"><span style="display: inline-block; position: relative; width: 9.387em; height: 0px;"><span style="position: absolute; clip: rect(2.733em, 1008.19em, 4.771em, -999.998em); top: -3.998em; left: 1.002em;"><span class="mrow" id="MathJax-Span-333"><span class="mrow" id="MathJax-Span-334"><span class="mfrac" id="MathJax-Span-335"><span style="display: inline-block; position: relative; width: 0.463em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.383em; left: 50%; margin-left: -0.19em;"><span class="mrow" id="MathJax-Span-336"><span class="mn" id="MathJax-Span-337" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.27em, 4.271em, -999.998em); top: -3.652em; left: 50%; margin-left: -0.152em;"><span class="mrow" id="MathJax-Span-338"><span class="mi" id="MathJax-Span-339" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1000.46em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 0.463em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-340" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 2.271em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-341"><span class="mo" id="MathJax-Span-342" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.498em; left: 1.04em;"><span class="mrow" id="MathJax-Span-343"><span class="mi" id="MathJax-Span-344" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.23em, 4.117em, -999.998em); top: -3.69em; left: 1.04em;"><span class="mrow" id="MathJax-Span-345"><span class="mi" id="MathJax-Span-346" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-347" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-348" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-349" style="vertical-align: 0em;"><span style="font-family: MathJax_Size2;">(</span></span><span class="msub" id="MathJax-Span-350"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-351"><span class="mi" id="MathJax-Span-352" style="font-family: MathJax_Math-italic;">R</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-353"><span class="mi" id="MathJax-Span-354" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-355" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-356" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-357" style="font-family: MathJax_Main; padding-left: 0.233em;">−</span><span class="msubsup" id="MathJax-Span-358" style="padding-left: 0.233em;"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-359"><span class="mi" id="MathJax-Span-360" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-361"><span class="mi" id="MathJax-Span-362" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-363"><span class="mi" id="MathJax-Span-364" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-365" style="vertical-align: 0em;"><span style="font-family: MathJax_Size2;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.617em, 1008.31em, 3.887em, -999.998em); top: -5.152em; left: 1.002em;"><span style="display: inline-block; position: relative; width: 8.31em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -3.998em; left: -0.075em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -3.998em; left: 7.617em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 0.463em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 1.002em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 1.579em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 2.117em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 2.694em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 3.233em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 3.81em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 4.348em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 4.925em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 5.463em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 6.04em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 6.579em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 7.156em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(2.425em, 1001.04em, 5.079em, -999.998em); top: -4.037em; left: 0em;"><span style="font-family: MathJax_Size3;">√</span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(2.425em, 1009.46em, 5.04em, -999.998em); top: -2.575em; left: 50%; margin-left: -4.767em;"><span class="mtd array" id="MathJax-Span-374"><span class="mrow" id="MathJax-Span-375"><span class="msqrt" id="MathJax-Span-376"><span style="display: inline-block; position: relative; width: 9.502em; height: 0px;"><span style="position: absolute; clip: rect(2.733em, 1008.35em, 4.771em, -999.998em); top: -3.998em; left: 1.002em;"><span class="mrow" id="MathJax-Span-377"><span class="mrow" id="MathJax-Span-378"><span class="mfrac" id="MathJax-Span-379"><span style="display: inline-block; position: relative; width: 0.617em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.383em; left: 50%; margin-left: -0.19em;"><span class="mrow" id="MathJax-Span-380"><span class="mn" id="MathJax-Span-381" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.5em, 4.117em, -999.998em); top: -3.652em; left: 50%; margin-left: -0.229em;"><span class="mrow" id="MathJax-Span-382"><span class="mi" id="MathJax-Span-383" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1000.62em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 0.617em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-384" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 2.271em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-385"><span class="mo" id="MathJax-Span-386" style="font-family: MathJax_Size1; vertical-align: 0em;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.58em, 4.117em, -999.998em); top: -4.46em; left: 1.04em;"><span class="mrow" id="MathJax-Span-387"><span class="mi" id="MathJax-Span-388" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.23em, 4.117em, -999.998em); top: -3.729em; left: 1.04em;"><span class="mrow" id="MathJax-Span-389"><span class="mi" id="MathJax-Span-390" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-391" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mn" id="MathJax-Span-392" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-393" style="vertical-align: 0em;"><span style="font-family: MathJax_Size2;">(</span></span><span class="msub" id="MathJax-Span-394"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-395"><span class="mi" id="MathJax-Span-396" style="font-family: MathJax_Math-italic;">R</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-397"><span class="mi" id="MathJax-Span-398" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-399" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-400" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-401" style="font-family: MathJax_Main; padding-left: 0.233em;">−</span><span class="msubsup" id="MathJax-Span-402" style="padding-left: 0.233em;"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-403"><span class="mi" id="MathJax-Span-404" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-405"><span class="mi" id="MathJax-Span-406" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-407"><span class="mi" id="MathJax-Span-408" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-409" style="vertical-align: 0em;"><span style="font-family: MathJax_Size2;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.617em, 1008.46em, 3.887em, -999.998em); top: -5.152em; left: 1.002em;"><span style="display: inline-block; position: relative; width: 8.463em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -3.998em; left: -0.075em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -3.998em; left: 7.771em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 0.425em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 0.963em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 1.502em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 2.002em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 2.54em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 3.079em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 3.617em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 4.117em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 4.656em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 5.194em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 5.733em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 6.271em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 6.771em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 7.31em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(2.425em, 1001.04em, 5.079em, -999.998em); top: -4.037em; left: 0em;"><span style="font-family: MathJax_Size3;">√</span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 6.233em;"></span></span><span style="position: absolute; clip: rect(2.54em, 1002.42em, 6.502em, -999.998em); top: -4.729em; left: 10.31em;"><span style="display: inline-block; position: relative; width: 2.425em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1002.42em, 4.31em, -999.998em); top: -5.383em; left: 50%; margin-left: -1.229em;"><span class="mtd array" id="MathJax-Span-369"><span class="mrow" id="MathJax-Span-370"><span class="mi" id="MathJax-Span-371" style="font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-372" style="font-family: MathJax_Main; padding-left: 0.271em;">&lt;</span><span class="mi" id="MathJax-Span-373" style="font-family: MathJax_Math-italic; padding-left: 0.271em;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1002.42em, 4.31em, -999.998em); top: -2.575em; left: 50%; margin-left: -1.229em;"><span class="mtd array" id="MathJax-Span-410"><span class="mrow" id="MathJax-Span-411"><span class="mi" id="MathJax-Span-412" style="font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-413" style="font-family: MathJax_Main; padding-left: 0.271em;">≥</span><span class="mi" id="MathJax-Span-414" style="font-family: MathJax_Math-italic; padding-left: 0.271em;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.733em;"></span></span></span></span></span><span class="mo" id="MathJax-Span-415" style="vertical-align: 2.848em;"><span style="display: inline-block; position: relative; width: 0.887em; height: 0px;"><span style="position: absolute; font-family: MathJax_Size4; top: -2.844em; left: 0em;">⎞<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: 0.579em; left: 0em;">⎠<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -1.652em; left: 0em;">⎟<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -1.075em; left: 0em;">⎟<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -0.537em; left: 0em;">⎟<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 6.233em;"></span></span></span><span style="display: inline-block; width: 0px; height: 9.848em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -5.498em; border-left: 0px solid; width: 0px; height: 11.603em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-8"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M16"><mtable class="eqnarray" columnalign="right center left"><mtr><mtd class="eqnarray-1"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></mtd><mtd class="eqnarray-2"><mo>=</mo></mtd><mtd class="eqnarray-3"><mfenced open="{"><mrow><mtable class="array"><mtr><mtd class="array"><mfrac><mrow><mn>1</mn></mrow><mrow><mi>j</mi></mrow></mfrac><msubsup><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>j</mi></mrow></msubsup><msub><mrow><mi>R</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mtd><mtd class="array"><mi>j</mi><mo>&lt;</mo><mi>T</mi></mtd></mtr><mtr><mtd class="array"><mfrac><mrow><mn>1</mn></mrow><mrow><mi>T</mi></mrow></mfrac><msubsup><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>T</mi></mrow></msubsup><msub><mrow><mi>R</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mtd><mtd class="array"><mi>j</mi><mo>≥</mo><mi>T</mi></mtd></mtr></mtable></mrow></mfenced></mtd></mtr><mtr><mtd class="eqnarray-1"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>σ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></mtd><mtd class="eqnarray-2"><mo>=</mo></mtd><mtd class="eqnarray-3"><mfenced open="{"><mrow><mtable class="array"><mtr><mtd class="array"><msqrt><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>j</mi></mrow></mfrac><msubsup><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>j</mi></mrow></msubsup><mo>(</mo><msub><mrow><mi>R</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>−</mo><msubsup><mrow><mi>C</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>j</mi></mrow></msubsup><mo>)</mo></mrow></msqrt></mtd><mtd class="array"><mi>j</mi><mo>&lt;</mo><mi>T</mi></mtd></mtr><mtr><mtd class="array"><msqrt><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>T</mi></mrow></mfrac><msubsup><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>T</mi></mrow></msubsup><mo>(</mo><msub><mrow><mi>R</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>−</mo><msubsup><mrow><mi>C</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>j</mi></mrow></msubsup><mo>)</mo></mrow></msqrt></mtd><mtd class="array"><mi>j</mi><mo>≥</mo><mi>T</mi></mtd></mtr></mtable></mrow></mfenced></mtd></mtr></mtable></math></script></div><div class="l">5</div></div><p></p><p id="Par37" class="p p-last"><span id="IEq4"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M18" style="width: 1.617em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.23em, 2.656em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-417"><span class="msubsup" id="MathJax-Span-418"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-419"><span class="mi" id="MathJax-Span-420" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-421"><span class="mi" id="MathJax-Span-422" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-423"><span class="mi" id="MathJax-Span-424" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.547em; border-left: 0px solid; width: 0px; height: 1.802em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-9"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M18"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></math></script></span> and <span id="IEq5"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M20" style="width: 1.579em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.194em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.19em, 2.54em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-426"><span class="msubsup" id="MathJax-Span-427"><span style="display: inline-block; position: relative; width: 1.194em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-428"><span class="mi" id="MathJax-Span-429" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-430"><span class="mi" id="MathJax-Span-431" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.46em, 4.117em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-432"><span class="mi" id="MathJax-Span-433" style="font-size: 70.7%; font-family: MathJax_Math-italic;">σ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.398em; border-left: 0px solid; width: 0px; height: 1.602em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-10"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M20"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>σ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></math></script></span> give an anomaly score per frame, while incorporating information from the past and future. A large value of <span id="IEq6"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M22" style="width: 1.617em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.23em, 2.656em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-435"><span class="msubsup" id="MathJax-Span-436"><span style="display: inline-block; position: relative; width: 1.233em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-437"><span class="mi" id="MathJax-Span-438" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-439"><span class="mi" id="MathJax-Span-440" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-441"><span class="mi" id="MathJax-Span-442" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.547em; border-left: 0px solid; width: 0px; height: 1.802em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-11"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M22"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></math></script></span> or <span id="IEq7"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M24" style="width: 1.579em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.194em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.19em, 2.54em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-444"><span class="msubsup" id="MathJax-Span-445"><span style="display: inline-block; position: relative; width: 1.194em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-446"><span class="mi" id="MathJax-Span-447" style="font-family: MathJax_Math-italic;">C<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.04em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.39em, 4.271em, -999.998em); top: -4.421em; left: 0.81em;"><span class="mrow" id="MathJax-Span-448"><span class="mi" id="MathJax-Span-449" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.46em, 4.117em, -999.998em); top: -3.767em; left: 0.733em;"><span class="mrow" id="MathJax-Span-450"><span class="mi" id="MathJax-Span-451" style="font-size: 70.7%; font-family: MathJax_Math-italic;">σ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.398em; border-left: 0px solid; width: 0px; height: 1.602em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-12"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M24"><msubsup><mrow><mi>C</mi></mrow><mrow><mi>σ</mi></mrow><mrow><mi>j</mi></mrow></msubsup></math></script></span> means that the <em>j</em> th frame, when appearing at different positions in subsequent windows, is reconstructed with a high average error or highly variable error. In a normal ADL case, the reconstruction error of a frame should not vary a lot with its position in subsequent windows; however, if it does, then this may indicate anomalous behavior, such as a fall.</p></div><div id="Sec9" class="sec sec-last"><h3 id="Sec9title">Within-Context Anomaly Score</h3><p id="Par38" class="p p-first">In a case when videos are considered as sequences of contiguous frames, we may want to designate the class of the whole window as fall or normal ADL, instead of deciding the class of every frame across different windows (or contexts). This way, all the frames present in a window will be used for predicting its class and they will have no influence on subsequent windows. Therefore, we call this method as within-context anomaly score. This method considers the reconstruction of frames within a context (or windows shown vertically in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig2/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig2" rid-ob="ob-Fig2" co-legend-rid="lgnd_Fig2"><span>2</span></a>) and gives a single score. In particular, the mean (<span id="IEq8"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M26" style="width: 1.925em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.46em, 2.656em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-453"><span class="msubsup" id="MathJax-Span-454"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1001.04em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-455"><span class="mi" id="MathJax-Span-456" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.421em; left: 1.117em;"><span class="mrow" id="MathJax-Span-457"><span class="mi" id="MathJax-Span-458" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.963em;"><span class="mrow" id="MathJax-Span-459"><span class="mi" id="MathJax-Span-460" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.547em; border-left: 0px solid; width: 0px; height: 1.752em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-13"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M26"><msubsup><mrow><mi>W</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>i</mi></mrow></msubsup></math></script></span>) and standard deviation (<span id="IEq9"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M28" style="width: 1.925em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.46em, 2.54em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-462"><span class="msubsup" id="MathJax-Span-463"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1001.04em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-464"><span class="mi" id="MathJax-Span-465" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.421em; left: 1.117em;"><span class="mrow" id="MathJax-Span-466"><span class="mi" id="MathJax-Span-467" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.46em, 4.117em, -999.998em); top: -3.767em; left: 0.963em;"><span class="mrow" id="MathJax-Span-468"><span class="mi" id="MathJax-Span-469" style="font-size: 70.7%; font-family: MathJax_Math-italic;">σ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.398em; border-left: 0px solid; width: 0px; height: 1.552em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-14"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M28"><msubsup><mrow><mi>W</mi></mrow><mrow><mi>σ</mi></mrow><mrow><mi>i</mi></mrow></msubsup></math></script></span>) of the reconstruction error of all the frames within a window <em>I</em><sub><em>i</em></sub> can be computed as an anomaly score to identify a fall,
</p><div class="disp-formula" id="Equ6"><div class="f"><span class="MathJax_Preview" style=""></span><div class="MathJax_Display" style="text-align: center;"><span class="MathJax" id="MathJax-Element-15-Frame" tabindex="0" style="text-align: center;"><nobr><span class="math" id="M30" style="width: 28.502em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.925em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(0.079em, 1021.85em, 3.925em, -999.998em); top: -2.229em; left: 0em;"><span class="mrow" id="MathJax-Span-471"><span class="msubsup" id="MathJax-Span-472"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1001.04em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-473"><span class="mi" id="MathJax-Span-474" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.421em; left: 1.117em;"><span class="mrow" id="MathJax-Span-475"><span class="mi" id="MathJax-Span-476" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.963em;"><span class="mrow" id="MathJax-Span-477"><span class="mi" id="MathJax-Span-478" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-479" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="mfrac" id="MathJax-Span-480" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.233em, 1000.42em, 4.117em, -999.998em); top: -4.69em; left: 50%; margin-left: -0.229em;"><span class="mrow" id="MathJax-Span-481"><span class="mn" id="MathJax-Span-482" style="font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1000.69em, 4.117em, -999.998em); top: -3.306em; left: 50%; margin-left: -0.344em;"><span class="mrow" id="MathJax-Span-483"><span class="mi" id="MathJax-Span-484" style="font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1000.81em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 0.81em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="munderover" id="MathJax-Span-485"><span style="display: inline-block; position: relative; width: 2.194em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0.579em;"><span class="mrow" id="MathJax-Span-486"><span class="mi" id="MathJax-Span-487" style="font-family: MathJax_Size1;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.04em, 4.348em, -999.998em); top: -3.113em; left: 0.54em;"><span class="mrow" id="MathJax-Span-488"><span class="mi" id="MathJax-Span-489" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-490" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mi" id="MathJax-Span-491" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.31em, 1002.16em, 4.194em, -999.998em); top: -4.96em; left: 0em;"><span class="mrow" id="MathJax-Span-492"><span class="mi" id="MathJax-Span-493" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span><span class="mo" id="MathJax-Span-494" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mi" id="MathJax-Span-495" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-496" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-497" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="msub" id="MathJax-Span-498"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-499"><span class="mi" id="MathJax-Span-500" style="font-family: MathJax_Math-italic;">R</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-501"><span class="mi" id="MathJax-Span-502" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-503" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-504" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-505" style="font-family: MathJax_Main;">,</span><span class="mspace" id="MathJax-Span-506" style="height: 0em; vertical-align: 0em; width: 1.002em; display: inline-block; overflow: hidden;"></span><span class="msubsup" id="MathJax-Span-507" style="padding-left: 0.156em;"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1001.04em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-508"><span class="mi" id="MathJax-Span-509" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.421em; left: 1.117em;"><span class="mrow" id="MathJax-Span-510"><span class="mi" id="MathJax-Span-511" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.46em, 4.117em, -999.998em); top: -3.767em; left: 0.963em;"><span class="mrow" id="MathJax-Span-512"><span class="mi" id="MathJax-Span-513" style="font-size: 70.7%; font-family: MathJax_Math-italic;">σ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-514" style="font-family: MathJax_Main; padding-left: 0.271em;">=</span><span class="msqrt" id="MathJax-Span-515" style="padding-left: 0.271em;"><span style="display: inline-block; position: relative; width: 10.117em; height: 0px;"><span style="position: absolute; clip: rect(2.156em, 1008.85em, 5.348em, -999.998em); top: -3.998em; left: 1.002em;"><span class="mrow" id="MathJax-Span-516"><span class="mrow" id="MathJax-Span-517"><span class="mfrac" id="MathJax-Span-518"><span style="display: inline-block; position: relative; width: 0.81em; height: 0px; margin-right: 0.117em; margin-left: 0.117em;"><span style="position: absolute; clip: rect(3.233em, 1000.42em, 4.117em, -999.998em); top: -4.69em; left: 50%; margin-left: -0.229em;"><span class="mrow" id="MathJax-Span-519"><span class="mn" id="MathJax-Span-520" style="font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.194em, 1000.69em, 4.117em, -999.998em); top: -3.306em; left: 50%; margin-left: -0.344em;"><span class="mrow" id="MathJax-Span-521"><span class="mi" id="MathJax-Span-522" style="font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(0.887em, 1000.81em, 1.194em, -999.998em); top: -1.306em; left: 0em;"><span style="display: inline-block; overflow: hidden; vertical-align: 0em; border-top: 1.6px solid; width: 0.81em; height: 0px;"></span><span style="display: inline-block; width: 0px; height: 1.079em;"></span></span></span></span><span class="munderover" id="MathJax-Span-523"><span style="display: inline-block; position: relative; width: 2.194em; height: 0px;"><span style="position: absolute; clip: rect(3.156em, 1001em, 4.348em, -999.998em); top: -3.998em; left: 0.579em;"><span class="mrow" id="MathJax-Span-524"><span class="mi" id="MathJax-Span-525" style="font-family: MathJax_Size1;">∑</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1001.04em, 4.348em, -999.998em); top: -3.113em; left: 0.54em;"><span class="mrow" id="MathJax-Span-526"><span class="mi" id="MathJax-Span-527" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-528" style="font-size: 70.7%; font-family: MathJax_Main;">=</span><span class="mi" id="MathJax-Span-529" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.31em, 1002.16em, 4.194em, -999.998em); top: -4.96em; left: 0em;"><span class="mrow" id="MathJax-Span-530"><span class="mi" id="MathJax-Span-531" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.079em;"></span></span><span class="mo" id="MathJax-Span-532" style="font-size: 70.7%; font-family: MathJax_Main;">+</span><span class="mi" id="MathJax-Span-533" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-534" style="font-size: 70.7%; font-family: MathJax_Main;">−</span><span class="mn" id="MathJax-Span-535" style="font-size: 70.7%; font-family: MathJax_Main;">1</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-536" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">(</span></span><span class="msub" id="MathJax-Span-537"><span style="display: inline-block; position: relative; width: 1.579em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1000.77em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-538"><span class="mi" id="MathJax-Span-539" style="font-family: MathJax_Math-italic;">R</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; top: -3.844em; left: 0.771em;"><span class="mrow" id="MathJax-Span-540"><span class="mi" id="MathJax-Span-541" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-542" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-543" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-544" style="font-family: MathJax_Main; padding-left: 0.233em;">−</span><span class="msubsup" id="MathJax-Span-545" style="padding-left: 0.233em;"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1001.04em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-546"><span class="mi" id="MathJax-Span-547" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.421em; left: 1.117em;"><span class="mrow" id="MathJax-Span-548"><span class="mi" id="MathJax-Span-549" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.963em;"><span class="mrow" id="MathJax-Span-550"><span class="mi" id="MathJax-Span-551" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span><span class="mo" id="MathJax-Span-552" style="vertical-align: 0em;"><span style="font-family: MathJax_Size4;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.617em, 1009.04em, 3.887em, -999.998em); top: -5.729em; left: 1.002em;"><span style="display: inline-block; position: relative; width: 9.04em; height: 0px;"><span style="position: absolute; font-family: MathJax_Main; top: -3.998em; left: -0.075em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Main; top: -3.998em; left: 8.348em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 0.425em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 0.963em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 1.502em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 2.04em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 2.579em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 3.079em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 3.617em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 4.156em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 4.694em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 5.233em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 5.771em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 6.31em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 6.848em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 7.348em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Main; position: absolute; top: -3.998em; left: 7.887em;">−<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(4.502em, 1001.08em, 8.348em, -999.998em); top: -6.652em; left: 0em;"><span style="display: inline-block; position: relative; width: 1.04em; height: 0px;"><span style="position: absolute; font-family: MathJax_Size4; top: -3.383em; left: 0em;"><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; font-family: MathJax_Size4; top: -1.267em; left: 0em;">⎷<span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -2.806em; left: 0em;"><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="font-family: MathJax_Size4; position: absolute; top: -2.19em; left: 0em;"><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.617em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.233em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -2.098em; border-left: 0px solid; width: 0px; height: 4.803em;"></span></span></nobr></span></div><script type="math/mml" id="MathJax-Element-15"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" display="block" id="M30"><msubsup><mrow><mi>W</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>i</mi></mrow></msubsup><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>T</mi></mrow></mfrac><munderover accent="false" accentunder="false"><mrow><mi>∑</mi></mrow><mrow><mi>j</mi><mo>=</mo><mi>i</mi></mrow><mrow><mi>T</mi><mo>+</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mrow><mi>R</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>,</mo><mspace width="1em"></mspace><msubsup><mrow><mi>W</mi></mrow><mrow><mi>σ</mi></mrow><mrow><mi>i</mi></mrow></msubsup><mo>=</mo><msqrt><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mi>T</mi></mrow></mfrac><munderover accent="false" accentunder="false"><mrow><mi>∑</mi></mrow><mrow><mi>j</mi><mo>=</mo><mi>i</mi></mrow><mrow><mi>T</mi><mo>+</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></munderover><mo>(</mo><msub><mrow><mi>R</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>−</mo><msubsup><mrow><mi>W</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>i</mi></mrow></msubsup><mo>)</mo></mrow></msqrt></math></script></div><div class="l">6</div></div><p></p><p id="Par39">A large value of <span id="IEq10"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M32" style="width: 1.925em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.46em, 2.656em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-554"><span class="msubsup" id="MathJax-Span-555"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1001.04em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-556"><span class="mi" id="MathJax-Span-557" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.421em; left: 1.117em;"><span class="mrow" id="MathJax-Span-558"><span class="mi" id="MathJax-Span-559" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.5em, 4.271em, -999.998em); top: -3.767em; left: 0.963em;"><span class="mrow" id="MathJax-Span-560"><span class="mi" id="MathJax-Span-561" style="font-size: 70.7%; font-family: MathJax_Math-italic;">μ</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.547em; border-left: 0px solid; width: 0px; height: 1.752em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-16"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M32"><msubsup><mrow><mi>W</mi></mrow><mrow><mi>μ</mi></mrow><mrow><mi>i</mi></mrow></msubsup></math></script></span> means that the average reconstruction error of the <em>T</em> frames within the window is high. Similarly, a large value of <span id="IEq11"><span class="MathJax_Preview" style=""></span><span class="MathJax" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 78%;"><nobr><span class="math" id="M34" style="width: 1.925em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px; font-size: 130%;"><span style="position: absolute; clip: rect(1.156em, 1001.46em, 2.54em, -999.998em); top: -2.152em; left: 0em;"><span class="mrow" id="MathJax-Span-563"><span class="msubsup" id="MathJax-Span-564"><span style="display: inline-block; position: relative; width: 1.463em; height: 0px;"><span style="position: absolute; clip: rect(3.194em, 1001.04em, 4.156em, -999.998em); top: -3.998em; left: 0em;"><span class="mrow" id="MathJax-Span-565"><span class="mi" id="MathJax-Span-566" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.117em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.425em, 1000.31em, 4.117em, -999.998em); top: -4.421em; left: 1.117em;"><span class="mrow" id="MathJax-Span-567"><span class="mi" id="MathJax-Span-568" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span><span style="position: absolute; clip: rect(3.579em, 1000.46em, 4.117em, -999.998em); top: -3.767em; left: 0.963em;"><span class="mrow" id="MathJax-Span-569"><span class="mi" id="MathJax-Span-570" style="font-size: 70.7%; font-family: MathJax_Math-italic;">σ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span><span style="display: inline-block; width: 0px; height: 4.002em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.156em;"></span></span></span><span style="display: inline-block; overflow: hidden; vertical-align: -0.398em; border-left: 0px solid; width: 0px; height: 1.552em;"></span></span></nobr></span><script type="math/mml" id="MathJax-Element-17"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M34"><msubsup><mrow><mi>W</mi></mrow><mrow><mi>σ</mi></mrow><mrow><mi>i</mi></mrow></msubsup></math></script></span> means that the variation of reconstruction error among the <em>T</em> frames of a window is high. Both situations indicate that high reconstruction error may be happening due to one or more frames present within a window. Therefore, these situations represent the case when DSTCAE reconstructs the <em>T</em> frames in the window with high/variable reconstruction error, which may represent an anomalous behavior such as a fall.</p><p id="Par40" class="p p-last">In order to designate a whole window of frames as a fall or non fall, we set a threshold on the number of fall frames in the window. That is, if the sequence contains more fall frames than the threshold, the sequence is labeled as a fall. Otherwise, it is labeled as a non-fall window. If this threshold is too low then <em>DeepFall</em> may be very sensitive and may generate many false positives. Whereas, if this threshold is too high (for example all frames in the sequence are required to be fall frames), then our system may miss some falls. Therefore, this threshold, which is the number of fall frames that are required for a window of frames to be designated as a fall, is a hyper-parameter of the <em>DeepFall</em> framework and is discussed in detail in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec17" rid="Sec17" class=" sec">5.4</a>.</p></div></div><div id="Sec10" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Sec10title">Experiments and Results</h2><div id="Sec11" class="sec sec-first"><h3 id="Sec11title">Datasets</h3><p id="Par41" class="p p-first">We test the <em>DeepFall</em> framework on the following three publicly available data sets that collected normal ADL and falls using non-invasive sensing modalities.</p><div id="Sec12" class="sec"><p></p><h4 id="Sec12title" class="inline">Thermal Fall Dataset </h4><p id="Par42" class="p p-first">This dataset consists of videos captured by a FLIR ONE thermal camera mounted on an Android phone in a room setting with a single view [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR33" rid="CR33" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">33</a>]. The videos have a frame rate of either 25 fps or 15 fps, which was obtained by observing the properties of each video. A total of 44 videos are collected; out of which, 35 videos contain a fall along with normal ADL and 9 videos contain only ADL. The spatial resolution of the thermal images is 640 × 480. The thermal dataset contains many empty frames; that is, scenes where no person is present. It also contains frames of people entering the scene from the left and from the right. Examples of thermal ADL and fall frames are given in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig3/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig3" rid-ob="ob-Fig3" co-legend-rid="lgnd_Fig3"><span>3</span></a>.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig3" co-legend-rid="lgnd_Fig3"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig3/" target="figure" rid-figpopup="Fig3" rid-ob="ob-Fig3"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326261491584"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig3/" target="figure" rid-figpopup="Fig3" rid-ob="ob-Fig3"></a><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=8982799_41666_2019_61_Fig3_HTML.jpg" target="tileshopwindow" rel="noopener"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig3_HTML.jpg" title="Click on image to zoom" class="tileshop" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig3_HTML.jpg"></a></div><div class="largeobj-link align_right" id="largeobj_idm140326261491584" style="display: none;"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig3/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig3"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig3/" target="figure" rid-figpopup="Fig3" rid-ob="ob-Fig3">Fig. 3</a></div><!--caption a7--><div class="caption"><p>Thermal dataset: ADL frames. <strong>a</strong> Empty scene. <strong>b</strong> Person entering the scene. <strong>c</strong> Person in the scene. <strong>d</strong>, <strong>e</strong>, and <strong>f</strong> Fall frames</p></div></div></div><p id="Par43" class="p p-last">The thermal dataset contains 22,116 ADL frames from 9 videos. After windowing the ADL videos individually, we generate 22,053 windows of contiguous frames (using (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Equ1" rid="Equ1" class=" ">1</a>)), which are used for training spatio-temporal autoencoders.
</p></div><div id="Sec13" class="sec"><p></p><h4 id="Sec13title" class="inline">UR Fall Detection Dataset </h4><p id="Par44" class="p p-first-last">The UR dataset (UR) [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR3" rid="CR3" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">3</a>] contains 70 depth videos collected using a Microsoft Kinect camera at 30 fps that was mounted parallel to the floor. Of these, 30 videos contain a fall and 40 videos contain various ADL, such as walking, sitting down, crouching down, and lying down in bed. Five persons performed two types of falls—from standing position and from sitting on the chair. The pixels in the depth frames indicate the calibrated depth in the scene. The depth map is provided in a 640 × 480 resolution. The UR dataset contains empty frames. It also contains frames of people entering the scene towards the camera. Samples of the original ADL and fall depth frame of the UR dataset are shown in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig4/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig4" rid-ob="ob-Fig4" co-legend-rid="lgnd_Fig4"><span>4</span></a>. After applying the sliding window, we obtain 8661 windows of contiguous frames used for training different spatio-temporal autoencoders (Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig5/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig5" rid-ob="ob-Fig5" co-legend-rid="lgnd_Fig5"><span>5</span></a>).
</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig4" co-legend-rid="lgnd_Fig4"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig4/" target="figure" rid-figpopup="Fig4" rid-ob="ob-Fig4"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326263788864"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig4/" target="figure" rid-figpopup="Fig4" rid-ob="ob-Fig4"></a><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=8982799_41666_2019_61_Fig4_HTML.jpg" target="tileshopwindow" rel="noopener"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig4_HTML.jpg" title="Click on image to zoom" class="tileshop" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig4_HTML.jpg"></a></div><div class="largeobj-link align_right" id="largeobj_idm140326263788864" style="display: none;"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig4/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig4"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig4/" target="figure" rid-figpopup="Fig4" rid-ob="ob-Fig4">Fig. 4</a></div><!--caption a7--><div class="caption"><p>UR dataset: original depth frames with holes. <strong>a</strong> Empty scene. <strong>b</strong> Person entering the scene. <strong>c</strong> Person in the scene. <strong>d</strong> Fall</p></div></div></div><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig5" co-legend-rid="lgnd_Fig5"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig5/" target="figure" rid-figpopup="Fig5" rid-ob="ob-Fig5"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326268689536"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig5/" target="figure" rid-figpopup="Fig5" rid-ob="ob-Fig5"></a><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=8982799_41666_2019_61_Fig5_HTML.jpg" target="tileshopwindow" rel="noopener"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig5_HTML.jpg" title="Click on image to zoom" class="tileshop" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig5_HTML.jpg"></a></div><div class="largeobj-link align_right" id="largeobj_idm140326268689536" style="display: none;"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig5/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig5"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig5/" target="figure" rid-figpopup="Fig5" rid-ob="ob-Fig5">Fig. 5</a></div><!--caption a7--><div class="caption"><p>UR dataset: depth frames after holes filling. <strong>a</strong> Empty scene. <strong>b</strong> Person entering the scene. <strong>c</strong> Person in the scene. <strong>d</strong> Fall</p></div></div></div></div><div id="Sec14" class="sec sec-last"><p></p><h4 id="Sec14title" class="inline">SDU Dataset </h4><p id="Par45" class="p p-first-last">The SDU dataset [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR20" rid="CR20" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">20</a>] contains depth videos collected by a Microsoft Kinect camera. The data that was shared with us contains 1197 depth videos. Of these videos, 997 contain the following ADL: bending, squatting, sitting, lying, and walking. The remaining 200 videos contain a fall, as well as other various ADL. The activities are performed by 20 young men and women. Each person performs 10 trials, which consist of simulating a fall, as well as performing each of the above ADL. The videos are recorded at 30 fps, with a spatial resolution of 320 × 240, and an average length of 5 seconds. After applying the sliding window, we obtain 163,573 windows of contiguous frames used for training spatio-temporal autoencoders. The SDU dataset contains empty frames. It also contains frames of people entering the scene from the left and right. Samples of original ADL and fall depth frame from the SDU dataset are shown in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig6/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig6" rid-ob="ob-Fig6" co-legend-rid="lgnd_Fig6"><span>6</span></a>.
</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig6" co-legend-rid="lgnd_Fig6"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig6/" target="figure" rid-figpopup="Fig6" rid-ob="ob-Fig6"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326273430096"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig6/" target="figure" rid-figpopup="Fig6" rid-ob="ob-Fig6"></a><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=8982799_41666_2019_61_Fig6_HTML.jpg" target="tileshopwindow" rel="noopener"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig6_HTML.jpg" title="Click on image to zoom" class="tileshop" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig6_HTML.jpg"></a></div><div class="largeobj-link align_right" id="largeobj_idm140326273430096" style="display: none;"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig6/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig6"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig6/" target="figure" rid-figpopup="Fig6" rid-ob="ob-Fig6">Fig. 6</a></div><!--caption a7--><div class="caption"><p>SDU dataset: original depth frames with holes. <strong>a</strong> Empty scene. <strong>b</strong> Person entering the scene. <strong>c</strong> Person in the scene.<strong>d</strong> Fall</p></div></div></div></div></div><div id="Sec15" class="sec"><h3 id="Sec15title">Data Preprocessing</h3><p id="Par46" class="p p-first">The thermal dataset frames were extracted from mp4 video files. The UR dataset’s frames were already available in png format. The SDU dataset frames were extracted from AVI video files. All the frames in all the datasets are normalized by dividing the pixel values by 255 to keep them in the range [0,1] and subtracting the per-frame mean from each frame, resulting in pixel values in the range [− 1,1]. As discussed in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec4" rid="Sec4" class=" sec">3.1</a>, all the frames are also re-sized to 64 × 64.</p><p id="Par47">In order to create windows of contiguous video frames to give as input to the DSTCAE for training and testing, we perform a sliding window on all video frames, as described in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec4" rid="Sec4" class=" sec">3.1</a>. We choose <em>T</em> = 8 because we do not want our window length to exceed the length of the shortest fall sequence, which is found to be 13 frames. We thus chose the largest power of 2 smaller than 13, which is 8. We use the same window length for all datasets for simplicity. Smaller window length may lead to higher false positives as the decision regarding a fall would have to be made on fewer reconstructed video frames. On the other hand, a greater window length may include non-fall frames because fall is a short term event. Therefore, some falls may be missed to be detected.</p><p id="Par48">In both the UR dataset and the SDU dataset, there were many regions of missing pixels, termed as “holes.” Both of these datasets use the Microsoft Kinect depth sensor, which is a structured 3D scanner and light measurements from it can contain errors due to multiple reflections, transparent objects, occlusion, or scattering [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR34" rid="CR34" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">34</a>]. These holes can be seen as black regions in Figs.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig4/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig4" rid-ob="ob-Fig4" co-legend-rid="lgnd_Fig4"><span>4</span></a> and&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig6/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig6" rid-ob="ob-Fig6" co-legend-rid="lgnd_Fig6"><span>6</span></a>. These holes can be detrimental to learning useful spatio-temporal features using the <em>DeepFall</em> framework. Therefore, we employed hole-filling methods to fill in these regions. For the UR dataset, we used a method based on depth colorization [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR24" rid="CR24" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>]. Figure&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig5/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig5" rid-ob="ob-Fig5" co-legend-rid="lgnd_Fig5"><span>5</span></a> shows the corresponding depth frame after filling holes in the frames shown in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig4/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig4" rid-ob="ob-Fig4" co-legend-rid="lgnd_Fig4"><span>4</span></a>. For the SDU dataset, we did not have information of distance in the depth frames, since they were extracted from AVI formatted videos. That is, the depth images contain values in the range [0,255], where darker pixels correspond to a lesser distance from the camera; true distance is not known for these values. Distance information is required for using the depth colorization algorithm [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR24" rid="CR24" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">24</a>]. Thus, we used a simple inpainting technique, based on an OpenCV [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR14" rid="CR14" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">14</a>] implementation of the inpainting algorithm presented in [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR2" rid="CR2" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">2</a>]. Figure&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig7/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig7" rid-ob="ob-Fig7" co-legend-rid="lgnd_Fig7"><span>7</span></a> shows the results of applying this inpainting technique on the frame shown in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig6/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig6" rid-ob="ob-Fig6" co-legend-rid="lgnd_Fig6"><span>6</span></a>.
</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig7" co-legend-rid="lgnd_Fig7"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig7/" target="figure" rid-figpopup="Fig7" rid-ob="ob-Fig7"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326272384944"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig7/" target="figure" rid-figpopup="Fig7" rid-ob="ob-Fig7"></a><a class="inline_block ts_canvas" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=8982799_41666_2019_61_Fig7_HTML.jpg" target="tileshopwindow" rel="noopener"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig7_HTML.jpg" title="Click on image to zoom" class="tileshop" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig7_HTML.jpg"></a></div><div class="largeobj-link align_right" id="largeobj_idm140326272384944" style="display: none;"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig7/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig7"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig7/" target="figure" rid-figpopup="Fig7" rid-ob="ob-Fig7">Fig. 7</a></div><!--caption a7--><div class="caption"><p>SDU dataset: depth frames after hole filling. <strong>a</strong> Empty scene. <strong>b</strong> Person entering the scene. <strong>c</strong> Person in the scene. <strong>d</strong> Fall</p></div></div></div><p id="Par49" class="p p-last">To evaluate the effectiveness of hole filling in detecting falls using different autoencoder methods, we created another version of the UR and SDU dataset in which the holes are filled for all the frames, we call them as UR-Filled and SDU-Filled.</p></div><div id="Sec16" class="sec"><h3 id="Sec16title">Experimental Setup</h3><p id="Par50" class="p p-first">Different types of autoencoders are trained on only the ADL videos, which only contain normal ADL / non-fall frames. The testing was carried out on fall videos, which contain fall activity as well as normal ADL. The video frames used for training the models were not annotated because they were all considered normal ADL. In order to test the models, fall videos are used that contained both fall and non-fall frames. The fall frames were manually annotated in these videos.</p><p id="Par51">For comparing the performance of different variants of spatial-temporal autoencoder, DAE, CAE, all autoencoders are trained for 500 epochs. Adadelta optimizer was used in training these models. The training batch size is set to 32 for DAE and CAE models, and 16 for DSTCAE variants, where each batch consists of a stack of 8 frames. To train DAE and CAE variants, we augment the data by performing horizontal flipping. No data augmentation was performed when training DSTCAE variants, as it did not improve results. As noted in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec6" rid="Sec6" class=" sec">3.3</a>, dropout is applied to layer 1 for DAE and to layer 2 for all DSTCAE variants. In all cases, the dropout probability is set to 0.25.<sup><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Fn1" rid="Fn1" class=" fn">1</a></sup></p><p id="Par53" class="p p-last">The within-context anomaly score can only be calculated for the DSTCAE variants, because it calculates a score for each window of <em>T</em> frames rather than individual frames. In this method, if there are <em>α</em> amount of fall frames, then the ground truth of the entire sequence of frames is labeled as a fall. The value of <em>α</em> is varied from <em>α</em> = 1 to <em>α</em> = <em>T</em> = 8. These anomaly scores are then used to compute the area under the curve (AUC) of the ROC with fall as the class of interest. The cross-context anomaly score gives a score per frame (for a given video); therefore, it can be directly compared with DAE and CAE variants. The anomaly scores obtained for every frame are used to calculate AUC of the ROC, with fall as the class of interest. For DAE and CAE variants, the reconstruction error of frames of a test video is considered as anomaly score. The reported AUC is the average of AUC across all test videos. As discussed in Section&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec6" rid="Sec6" class=" sec">3.3</a>, we test three variants of DSTCAE: DSTCAE-UpSampling, DSTCAE-Deconv, DSTCAE-C3D.</p></div><div id="Sec17" class="sec sec-last"><h3 id="Sec17title">Results</h3><div id="Sec18" class="sec sec-first"><p></p><h4 id="Sec18title" class="inline">Cross-Context Anomaly Score </h4><p id="Par54" class="p p-first">The results for all frame-based models, i.e., DAE, CAE variants, and DSTCAE variants using the cross-context score, are presented in Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab4/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab4" rid-ob="ob-Tab4" co-legend-rid=""><span>4</span></a>. We also present the AUC values computed using an ensemble of one-class JK nearest neighbor method [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR16" rid="CR16" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">16</a>] trained over the features learned from DAE; features from the fourth fully connected layer were used. The nearest neighbors are set to 1 (JKNN-11) and 10 (JKNN-JK), and the ensemble sizes are fixed to 25. The results for UR and SDU using the one-class JK nearest neighbor method could not be obtained in a reasonable time because it calculates the euclidean distance for all pairs of input; thus, making the method very slow and impractical to work with large datasets. We also compare the results from our previous work of using CLSTMAE [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR25" rid="CR25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>] over all the datasets with cross-context scores <em>C</em><sub><em>σ</em></sub> and <em>C</em><sub><em>μ</em></sub>. The first column of Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab4/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab4" rid-ob="ob-Tab4" co-legend-rid=""><span>4</span></a> indicates the model tested, and the other columns show the dataset. Each numerical value in the Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab4/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab4" rid-ob="ob-Tab4" co-legend-rid=""><span>4</span></a> represents the average ROC AUC across all videos for the model indicated by the row. The respective standard deviation of ROC AUC across all videos of the dataset is shown in small brackets. The results can be summarized as follows:
</p><ul class="unordered" style="list-style-type:disc"><li><div id="Par55">All the variants of spatio-temporal autoencoders outperforms spatial feature extraction methods (i.e., JKNN, DAE, and two CAE variants). This confirms the fact that extracting both spatial and temporal features are important in video-based fall detection approach.</div></li><li><div id="Par56">All the variants of DSTCAE outperforms the CLSTM-based methods. This marks an improvement on our previous work [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR25" rid="CR25" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">25</a>]. This may be the case since LSTM-based models are tailored to long-term sequential modelling, but falls occur on short time scales. It further confirms that DSTCAE is better suited for such problems of short length sequences.</div></li><li><div id="Par57">The autoencoders trained on holes filled versions of UR and SDU datasets performed better for all the classifiers (except for one CLSTMAE:<em>C</em><sub><em>σ</em></sub> for the SDU dataset, which is worse than the best AUC obtained for this dataset with holes-filled). This result shows that if the depth data contains holes or missing pixels, it must be filled with some technique for the autoencoder to detect falls appropriately.</div></li><li><div id="Par58">The difference between DSTACE-Deconv and DSTCAE-UpSampling appears to be very small, but DSTCAE-C3D performs the best on two out of three datasets (excluding depth datasets without holes filled, which are degenerative cases).</div></li><li><div id="Par59">We see that <em>C</em><sub><em>σ</em></sub> outperforms on <em>C</em><sub><em>μ</em></sub> on thermal and UR-Filled data. That is, DSTCAE-C3D:<em>C</em><sub><em>σ</em></sub>, and DSTCAE-UpSampling:<em>C</em><sub><em>σ</em></sub> perform the best on thermal and UR-Filled data respectively.</div></li></ul><p>We also perform a significance test to compare the ROC AUC of these different algorithms on all the 5 datasets (i.e., thermal, UR, UR-Filled, SDU and SDU-Filled). In particular, we use Friedman’s post-hoc test with Bergmann and Hommel’s correction [4]. For simplicity, we choose to compare one variant from each type of algorithms (i.e., DAE and one each from JKNN, DAE, CAE, CLSTM, and DSTCAE variants). That is, we compare JKNN-JK, DAE, CAE-Deconv, CLSTMAE:<em>C</em><sub><em>μ</em></sub>, and DSTCAE-C3D:<em>C</em><sub><em>σ</em></sub>. The results of this significance test can be found in Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab3/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab3" rid-ob="ob-Tab3" co-legend-rid=""><span>3</span></a>. The <em>i</em> th row and <em>j</em> th column compare the algorithm specified in the <em>i</em> th row of the table, to the algorithm specified in the <em>j</em> th column of the table. Significant differences are shown in bold. We see that the only algorithm with a significant difference from the others is DSTCAE-C3D:<em>C</em><sub><em>σ</em></sub>. This supports the above findings that spatio-temporal autoencoder (DSTCAE and variants) outperforms spatial feature extraction methods (Table&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab4/" target="table" class="fig-table-link figpopup" rid-figpopup="Tab4" rid-ob="ob-Tab4" co-legend-rid=""><span>4</span></a>).
</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="Tab3"><h3>Table 3</h3><!--caption a7--><div class="caption"><p>Friedman post-hoc test with Bergmann and Hommel’s correction</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="left" rowspan="1" colspan="1"></th><th align="left" rowspan="1" colspan="1">JKNN-JK</th><th align="left" rowspan="1" colspan="1">DAE</th><th align="left" rowspan="1" colspan="1">CAE-Deconv</th><th align="left" rowspan="1" colspan="1">CLSTMAE:<em>C</em><sub><em>μ</em></sub>.</th><th align="left" rowspan="1" colspan="1">DSTCAE-C3D:<em>C</em><sub><em>μ</em></sub></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">JKNN-JK</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="left" rowspan="1" colspan="1">0.143</td><td align="left" rowspan="1" colspan="1">0.287</td><td align="left" rowspan="1" colspan="1">0.075</td><td align="left" rowspan="1" colspan="1"><strong>0.003</strong></td></tr><tr><td align="left" rowspan="1" colspan="1">DAE</td><td align="left" rowspan="1" colspan="1">0.143</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="left" rowspan="1" colspan="1">1.000</td><td align="left" rowspan="1" colspan="1">1.000</td><td align="left" rowspan="1" colspan="1">0.431</td></tr><tr><td align="left" rowspan="1" colspan="1">CAE-Deconv</td><td align="left" rowspan="1" colspan="1">0.287</td><td align="left" rowspan="1" colspan="1">1.000</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="left" rowspan="1" colspan="1">1.000</td><td align="left" rowspan="1" colspan="1">0.431</td></tr><tr><td align="left" rowspan="1" colspan="1">CLSTMAE:<em>C</em><sub><em>μ</em></sub>.</td><td align="left" rowspan="1" colspan="1">0.075</td><td align="left" rowspan="1" colspan="1">1.000</td><td align="left" rowspan="1" colspan="1">1.000</td><td align="left" rowspan="1" colspan="1">n/a</td><td align="left" rowspan="1" colspan="1">0.543</td></tr><tr><td align="left" rowspan="1" colspan="1">DSTCAE-C3D:<em>C</em><sub><em>μ</em></sub></td><td align="left" rowspan="1" colspan="1"><strong>0.003</strong></td><td align="left" rowspan="1" colspan="1">0.431</td><td align="left" rowspan="1" colspan="1">0.431</td><td align="left" rowspan="1" colspan="1">0.543</td><td align="left" rowspan="1" colspan="1">n/a</td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140326274073440"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab3/?report=objectonly">Open in a separate window</a></div></div><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="Tab4"><h3>Table 4</h3><!--caption a7--><div class="caption"><p>ROC AUC values for different methods, for each dataset, based on cross-context anomaly score</p></div><div class="xtable"><table frame="hsides" rules="groups" class="rendered small default_table"><thead><tr><th align="left" rowspan="1" colspan="1">Models</th><th align="left" rowspan="1" colspan="1">Thermal</th><th align="left" rowspan="1" colspan="1">UR</th><th align="left" rowspan="1" colspan="1">UR-Filled</th><th align="left" rowspan="1" colspan="1">SDU</th><th align="left" rowspan="1" colspan="1">SDU-Filled</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">JKNN-11</td><td align="left" rowspan="1" colspan="1">0.53</td><td align="left" rowspan="1" colspan="1">–</td><td align="left" rowspan="1" colspan="1">0.5</td><td align="left" rowspan="1" colspan="1">–</td><td align="left" rowspan="1" colspan="1">0.72</td></tr><tr><td align="left" rowspan="1" colspan="1">JKNN-JK</td><td align="left" rowspan="1" colspan="1">0.53</td><td align="left" rowspan="1" colspan="1">–</td><td align="left" rowspan="1" colspan="1">0.5</td><td align="left" rowspan="1" colspan="1">–</td><td align="left" rowspan="1" colspan="1">0.86</td></tr><tr><td align="left" rowspan="1" colspan="1">DAE</td><td align="left" rowspan="1" colspan="1">0.65(0.14)</td><td align="left" rowspan="1" colspan="1">0.38(0.14)</td><td align="left" rowspan="1" colspan="1">0.75(0.15)</td><td align="left" rowspan="1" colspan="1">0.72(0.16)</td><td align="left" rowspan="1" colspan="1">0.94(0.05)</td></tr><tr><td align="left" rowspan="1" colspan="1">CAE-UpSampling</td><td align="left" rowspan="1" colspan="1">0.73(0.12)</td><td align="left" rowspan="1" colspan="1">0.38(0.14)</td><td align="left" rowspan="1" colspan="1">0.67(0.19)</td><td align="left" rowspan="1" colspan="1">0.64(0.16)</td><td align="left" rowspan="1" colspan="1">0.89(0.06)</td></tr><tr><td align="left" rowspan="1" colspan="1">CAE-Deconv</td><td align="left" rowspan="1" colspan="1">0.75(0.17)</td><td align="left" rowspan="1" colspan="1">0.38(0.11)</td><td align="left" rowspan="1" colspan="1">0.76(0.21)</td><td align="left" rowspan="1" colspan="1">0.66(0.16)</td><td align="left" rowspan="1" colspan="1">0.92(0.07)</td></tr><tr><td align="left" rowspan="1" colspan="1">CLSTMAE: <em>C</em><sub><em>σ</em></sub></td><td align="left" rowspan="1" colspan="1">0.64(0.16)</td><td align="left" rowspan="1" colspan="1">0.49(0.09)</td><td align="left" rowspan="1" colspan="1">0.67(0.20)</td><td align="left" rowspan="1" colspan="1">0.66(0.10)</td><td align="left" rowspan="1" colspan="1">0.56(0.11)</td></tr><tr><td align="left" rowspan="1" colspan="1">CLSTMAE: <em>C</em><sub><em>μ</em></sub></td><td align="left" rowspan="1" colspan="1">0.58(0.20)</td><td align="left" rowspan="1" colspan="1">0.43(0.11)</td><td align="left" rowspan="1" colspan="1">0.82(0.16)</td><td align="left" rowspan="1" colspan="1"><strong>0.77(0.11)</strong></td><td align="left" rowspan="1" colspan="1">0.92(0.06)</td></tr><tr><td align="left" rowspan="1" colspan="1">DSTCAE-UpSampling:<em>C</em><sub><em>σ</em></sub></td><td align="left" rowspan="1" colspan="1">0.96(0.03)</td><td align="left" rowspan="1" colspan="1">0.69(0.18)</td><td align="left" rowspan="1" colspan="1"><strong>0.89(0.09)</strong></td><td align="left" rowspan="1" colspan="1">0.74(0.12)</td><td align="left" rowspan="1" colspan="1">0.90(0.06)</td></tr><tr><td align="left" rowspan="1" colspan="1">DSTCAE-UpSampling:<em>C</em><sub><em>μ</em></sub></td><td align="left" rowspan="1" colspan="1">0.95(0.04)</td><td align="left" rowspan="1" colspan="1">0.50(0.14)</td><td align="left" rowspan="1" colspan="1">0.88(0.12)</td><td align="left" rowspan="1" colspan="1">0.70(0.18)</td><td align="left" rowspan="1" colspan="1">0.92(0.05)</td></tr><tr><td align="left" rowspan="1" colspan="1">DSTCAE-Deconv:<em>C</em><sub><em>σ</em></sub></td><td align="left" rowspan="1" colspan="1">0.96(0.02)</td><td align="left" rowspan="1" colspan="1"><strong>0.72(0.17)</strong></td><td align="left" rowspan="1" colspan="1">0.88(0.10)</td><td align="left" rowspan="1" colspan="1">0.70(0.13)</td><td align="left" rowspan="1" colspan="1">0.92(0.05)</td></tr><tr><td align="left" rowspan="1" colspan="1">DSTCAE-Deconv:<em>C</em><sub><em>μ</em></sub></td><td align="left" rowspan="1" colspan="1">0.94(0.04)</td><td align="left" rowspan="1" colspan="1">0.48(0.14)</td><td align="left" rowspan="1" colspan="1">0.85(0.11)</td><td align="left" rowspan="1" colspan="1">0.69(0.18)</td><td align="left" rowspan="1" colspan="1">0.92(0.05)</td></tr><tr><td align="left" rowspan="1" colspan="1">DSTCAE-C3D:<em>C</em><sub><em>σ</em></sub></td><td align="left" rowspan="1" colspan="1"><strong>0.97(0.02)</strong></td><td align="left" rowspan="1" colspan="1">0.54(0.13)</td><td align="left" rowspan="1" colspan="1">0.80(0.13)</td><td align="left" rowspan="1" colspan="1">0.76(0.11)</td><td align="left" rowspan="1" colspan="1">0.92(0.06)</td></tr><tr><td align="left" rowspan="1" colspan="1">DSTCAE-C3D:<em>C</em><sub><em>μ</em></sub></td><td align="left" rowspan="1" colspan="1">0.93(0.07)</td><td align="left" rowspan="1" colspan="1">0.45(0.12)</td><td align="left" rowspan="1" colspan="1">0.86(0.17</td><td align="left" rowspan="1" colspan="1">0.71(0.18)</td><td align="left" rowspan="1" colspan="1"><strong>0.95(0.04)</strong></td></tr></tbody></table></div><div class="largeobj-link align_right" id="largeobj_idm140326270554928"><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/table/Tab4/?report=objectonly">Open in a separate window</a></div></div><p id="Par60" class="p p-last">It should be noted that these results may be misleading, firstly because we have a small sample size for conducting a significance test (only five datasets). We note that for the SDU and SDU-Filled dataset, the best performing model (DSTCAE-C3D:<em>C</em><sub><em>μ</em></sub>, 0.95(0.04) AUC) does not perform much better than the much simpler DAE model (0.94(0.05) AUC). The SDU dataset videos contain simple and organic activities; falls always happened from standing, besides having no furniture or background objects in the scene. We hypothesize that due to these reasons the DAE model may be able to learn global features to detect falls comparably to the spatio-temporal network. However, the activities in the thermal and UR datasets were complex; falls happened in various poses (e.g., falling from chair, falling from sitting, and falling from standing), and the scene involved different objects in the background (e.g., bed, chair). Besides that, in the thermal dataset, due to a person entering the scene, the pixel intensity would change values due to change in the heat in the environment. The proposed DSTCAE methods worked well under these diverse conditions to detect unseen falls.
</p></div><div id="Sec19" class="sec sec-last"><p></p><h4 id="Sec19title" class="inline">Within-Context Anomaly Score </h4><p id="Par61" class="p p-first">The results achieved using the within-context anomaly scores, <em>W</em><sub><em>μ</em></sub> and <em>W</em><sub><em>σ</em></sub>, for all the datasets are shown in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig8/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig8" rid-ob="ob-Fig8" co-legend-rid="lgnd_Fig8"><span>8</span></a>. We do not show scores for SDU and UR with holes, because results were significantly worse than those with holes filled. We observe that increasing <em>α</em> increases the ROC AUC for thermal and SDU-Filled datasets, and to a lesser extent, UR-Filled dataset. This indicates that reducing false positives is effective in increasing the ROC AUC score, and thus the ability to detect falls.
</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="Fig8" co-legend-rid="lgnd_Fig8"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig8/" target="figure" rid-figpopup="Fig8" rid-ob="ob-Fig8"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div class="figure" data-largeobj="" data-largeobj-link-rid="largeobj_idm140326272295200"><img loading="lazy" class="fig-image" alt="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig8_HTML.jpg" title="An external file that holds a picture, illustration, etc.
Object name is 41666_2019_61_Fig8_HTML.jpg" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/41666_2019_61_Fig8_HTML.jpg"></div></a><div class="largeobj-link align_right" id="largeobj_idm140326272295200" style="display: none;"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig8/" target="figure" rid-figpopup="Fig8" rid-ob="ob-Fig8"></a><a target="object" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig8/?report=objectonly">Open in a separate window</a></div><div class="icnblk_cntnt" id="lgnd_Fig8"><div><a class="figpopup" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig8/" target="figure" rid-figpopup="Fig8" rid-ob="ob-Fig8">Fig. 8</a></div><!--caption a7--><div class="caption"><p>Effect of changing fall frames in a stack of frames (<em>α</em>) on the ROC AUC</p></div></div></div><p id="Par62" class="p p-last">We also observe that the ROC AUC attained using <em>W</em><sub><em>μ</em></sub> and <em>W</em><sub><em>σ</em></sub> (with sufficiently high <em>α</em>) is at least as high, and in some cases higher than using frame-based scores <em>C</em><sub><em>σ</em></sub> and <em>C</em><sub><em>μ</em></sub>. That is, for thermal dataset, the highest ROC AUC remained consistent from within-context to cross-context scores. For UR-Filled, the ROC AUC improved from 0.89 (<em>C</em><sub><em>σ</em></sub>) to 0.91 (<em>W</em><sub><em>μ</em></sub>), and for SDU-Filled dataset, ROC AUC improved from 0.95 (<em>C</em><sub><em>σ</em></sub>) to 0.98 (<em>W</em><sub><em>μ</em></sub>). Scores for JKNN-11 and JKNN-JK are not shown in Fig.&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/figure/Fig8/" target="figure" class="fig-table-link figpopup" rid-figpopup="Fig8" rid-ob="ob-Fig8" co-legend-rid="lgnd_Fig8"><span>8</span></a>, because these methods do not give scores on a per-frame basis and do not give window-based scores.</p></div></div></div><div id="Sec20" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Sec20title">Conclusions, Discussion, and Future Work</h2><p id="Par63" class="p p-first">Detecting falls in a non-invasive manner is a challenging problem, especially, as falls occur rarely. In this paper, we formulated detecting falls as an anomaly detection problem and presented the <em>DeepFall</em> framework, which shows the development and comparison of three variants of DSTCAE. We tested the <em>DeepFall</em> framework on three datasets that captured ADL and falls in a non-invasive manner using thermal and depth camera. We presented a new anomaly scoring method—referred to as the within-context anomaly score. The results showed that the <em>DeepFall</em> framework outperforms the standard CAE, as well as traditional DAE. We also found that DSTCAE variants outperformed the convolutional LSTM autoencoder approach of detecting falls. It was also observed that the within-context anomaly score outperformed the per-frame-based anomaly scoring method (or cross-context anomaly score) on two out of three datasets (excluding depth data sets without hole filling).</p><p id="Par64">The performance of the <em>DeepFall</em> method may be affected by the presence of multiple persons in a scene, occurrence of other anomalous behavior, or lighting conditions. We are planning to collect a new dataset on fall detection that will address some of these issues to build a robust fall detection system.</p><p id="Par65">The main application of 3D convolutional spatio-temporal autoencoders investigated in this paper is fall detection. Higher performance is achieved because the concept of normal activities of daily living was clearly defined. This idea can be further extended to other possible applications, such as anomalous behavior in crowded scenes, violence detection in public places, and detecting security threats in open areas. In all of these applications, individual facial or body movements are not required, rather generic spatio-temporal features can be learned from normal behavior and anomalies may be flagged.</p><p id="Par66" class="p p-last">Explainability of deep learning- based methods is a challenge [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR30" rid="CR30" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">30</a>]. The advantage of spatio-temporal convolutional methods is that the filters learned during the training process can be visualized. This will improve our understanding of the mechanism of fall detection. In the future, we will explore the application of Generative Adversarial Networks [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR11" rid="CR11" class=" bibr popnode" role="button" aria-expanded="false" aria-haspopup="true">11</a>] to the task of fall detection in an unsupervised setting.</p></div><div id="notes-a.v.b" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="notes-a.v.btitle">Compliance with Ethical Standards</h2><div><strong>Conflict of interests</strong><p id="Par67">The authors declare that they have no conflict of interest.</p></div></div><div id="fn-group-a.v.a" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="fn-group-a.v.atitle">Footnotes</h2><!--back/fn-group--><div class="fm-sec half_rhythm small"><p class="fn sec" id="Fn1"><sup>1</sup>The code for DSTCAE is available at <a href="https://github.com/JJN123/Fall-Detection" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CBody&amp;TO=External%7CLink%7CURI" target="_blank">https://github.com/JJN123/Fall-Detection</a>.</p><p class="fn sec" id="fn-a.v.a.b"></p><p class="p p-first"><strong>Publisher’s Note</strong></p><p class="p p-last">Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p><p></p></div></div><div id="article-aaff-info" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="article-aaff-infotitle">Contributor Information</h2><p><span class="fm-affl">Jacob Nogas, </span><span class="fm-affl"><span class="email-label">Email: </span><a href="mailto:dev@null" data-email="ac.otnorotu.liam@sagon.bocaj" class="oemail">ac.otnorotu.liam@sagon.bocaj</a></span>.</p><p><span class="fm-affl">Shehroz S. Khan, </span><span class="fm-affl"><span class="email-label">Email: </span><a href="mailto:dev@null" data-email="ac.otnorotu@sidiliahim.xela" class="oemail">ac.otnorotu@sidiliahim.xela</a></span>.</p><p><span class="fm-affl">Alex Mihailidis, </span><span class="fm-affl"><span class="email-label">Email: </span><a href="mailto:dev@null" data-email="ac.nhu@nahk.zorhehs" class="oemail">ac.nhu@nahk.zorhehs</a></span>.</p></div><div id="Bib1" class="tsec sec"><div class="goto jig-ncbiinpagenav-goto-container"><a class="tgt_dark page-toc-label jig-ncbiinpagenav-goto-heading" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" title="Go to other sections in this page" role="button" aria-expanded="false" aria-haspopup="true">Go to:</a></div><h2 class="head no_bottom_margin ui-helper-clearfix" id="Bib1title">References</h2><div class="ref-list-sec sec" id="reference-list"><div class="ref-cit-blk half_rhythm" id="CR1">1. <span class="mixed-citation">Baccouche M, Mamalet F, Wolf C, Garcia C, Baskurt A (2012) Spatio-temporal convolutional sparse autoencoder for sequence classification. In: BMVC. Citeseer</span></div><div class="ref-cit-blk half_rhythm" id="CR2">2. <span class="mixed-citation">Bertalmio M, Bertozzi AL, Sapiro G (2001) Navier-stokes, fluid dynamics, and image and video inpainting. In: Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001, vol 1, pp I–355–I–362, DOI 10.1109/CVPR.2001.990497</span></div><div class="ref-cit-blk half_rhythm" id="CR3">3. <span class="element-citation">Bogdan Kwolek MK. Human fall detection on embedded platform using depth maps and wireless accelerometer. <span><span class="ref-journal">Comput Methods Programs Biomed. </span>2014;<span class="ref-vol">117</span>:489–501. doi:&nbsp;10.1016/j.cmpb.2014.09.005.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/25308505" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.cmpb.2014.09.005" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Comput+Methods+Programs+Biomed&amp;title=Human+fall+detection+on+embedded+platform+using+depth+maps+and+wireless+accelerometer&amp;author=MK+Bogdan+Kwolek&amp;volume=117&amp;publication_year=2014&amp;pages=489-501&amp;pmid=25308505&amp;doi=10.1016/j.cmpb.2014.09.005&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR4">4. <span class="mixed-citation">CDC (2017) Enter of disease control and prevention – important facts about falls. <a href="https://www.cdc.gov/homeandrecreationalsafety/falls/adultfalls.html" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.cdc.gov/homeandrecreationalsafety/falls/adultfalls.html</a>. [Online accessed 22-December-2017]</span></div><div class="ref-cit-blk half_rhythm" id="CR5">5. <span class="mixed-citation">Chalapathy R, Menon AK, Chawla S (2017) Robust, deep and inductive anomaly detection. In: European conference on machine learning. Skopje</span></div><div class="ref-cit-blk half_rhythm" id="CR6">6. <span class="element-citation">Chandola V, Banerjee A, Kumar V. Anomaly detection: a survey. <span><span class="ref-journal">ACM Comput Surv. </span>2009;<span class="ref-vol">41</span>(3):15:1–15:58. doi:&nbsp;10.1145/1541880.1541882.</span> [<a href="https://doi.org/10.1145%2F1541880.1541882" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=ACM+Comput+Surv&amp;title=Anomaly+detection:+a+survey&amp;author=V+Chandola&amp;author=A+Banerjee&amp;author=V+Kumar&amp;volume=41&amp;issue=3&amp;publication_year=2009&amp;pages=15:1-15:58&amp;doi=10.1145/1541880.1541882&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR7">7. <span class="mixed-citation">Chollet F., et al. (2015) Keras: the python deep learning library <a href="https://github.com/fchollet/keras" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://github.com/fchollet/keras</a>. Online accessed 20-January-2018</span></div><div class="ref-cit-blk half_rhythm" id="CR8">8. <span class="mixed-citation">Chong YS, Tay YH (2017) Abnormal event detection in videos using spatiotemporal autoencoder. In: International symposium on neural networks. Springer, pp 189–196</span></div><div class="ref-cit-blk half_rhythm" id="CR9">9. <span class="mixed-citation">Du Tran Lubomir Bourdev RFLTMP (2015) Learning spatiotemporal features with 3d convolutional networks. In: IEEE International conference on computer vision (ICCV). IEEE, DOI 10.1109/ICCV.2015.510</span></div><div class="ref-cit-blk half_rhythm" id="CR10">10. <span class="element-citation">Goldstein M, Uchida S. A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data. <span><span class="ref-journal">PloS one 11. </span>2016;<span class="ref-vol">4</span>:e0152173. doi:&nbsp;10.1371/journal.pone.0152173.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4836738/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/27093601" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1371%2Fjournal.pone.0152173" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=PloS+one+11&amp;title=A+comparative+evaluation+of+unsupervised+anomaly+detection+algorithms+for+multivariate+data&amp;author=M+Goldstein&amp;author=S+Uchida&amp;volume=4&amp;publication_year=2016&amp;pages=e0152173&amp;doi=10.1371/journal.pone.0152173&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR11">11. <span class="mixed-citation">Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y (2014) Generative adversarial nets. In: Advances in neural information processing systems, pp 2672–2680</span></div><div class="ref-cit-blk half_rhythm" id="CR12">12. <span class="mixed-citation">Gutoski M, Aquino NMR, Ribeiro M, Lazzaretti AE, Lopes HS (2017) Detection of video anomalies using convolutional autoencoders and one-class support vector machines. In: Proc. XIII Brazilian congress on computational intelligence</span></div><div class="ref-cit-blk half_rhythm" id="CR13">13. <span class="mixed-citation">Hasan M, Choi J, Neumann J, Roy-Chowdhury AK, Davis LS (2016) Learning temporal regularity in video sequences. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 733–742</span></div><div class="ref-cit-blk half_rhythm" id="CR14">14. <span class="mixed-citation">Itseez (2015) Open source computer vision library. <a href="https://github.com/itseez/opencv" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://github.com/itseez/opencv</a></span></div><div class="ref-cit-blk half_rhythm" id="CR15">15. <span class="element-citation">Ji S, Xu W, Yang M, Yu K. 3d convolutional neural networks for human action recognition. <span><span class="ref-journal">IEEE Trans Pattern Anal Mach Intell. </span>2013;<span class="ref-vol">35</span>(1):221–231. doi:&nbsp;10.1109/TPAMI.2012.59.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/22392705" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTPAMI.2012.59" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans+Pattern+Anal+Mach+Intell&amp;title=3d+convolutional+neural+networks+for+human+action+recognition&amp;author=S+Ji&amp;author=W+Xu&amp;author=M+Yang&amp;author=K+Yu&amp;volume=35&amp;issue=1&amp;publication_year=2013&amp;pages=221-231&amp;pmid=22392705&amp;doi=10.1109/TPAMI.2012.59&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR16">16. <span class="element-citation">Khan SS, Ahmad A. Relationship between variants of one-class nearest neighbors and creating their accurate ensembles. <span><span class="ref-journal">IEEE Trans Knowl Data Eng. </span>2018;<span class="ref-vol">30</span>(9):1796–1809. doi:&nbsp;10.1109/TKDE.2018.2806975.</span> [<a href="https://doi.org/10.1109%2FTKDE.2018.2806975" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans+Knowl+Data+Eng&amp;title=Relationship+between+variants+of+one-class+nearest+neighbors+and+creating+their+accurate+ensembles&amp;author=SS+Khan&amp;author=A+Ahmad&amp;volume=30&amp;issue=9&amp;publication_year=2018&amp;pages=1796-1809&amp;doi=10.1109/TKDE.2018.2806975&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR17">17. <span class="element-citation">Khan SS, Karg ME, Kulić D, Hoey J. Detecting falls with x-factor hidden Markov models. <span><span class="ref-journal">Appl Soft Comput. </span>2017;<span class="ref-vol">55</span>:168–177. doi:&nbsp;10.1016/j.asoc.2017.01.034.</span> [<a href="https://doi.org/10.1016%2Fj.asoc.2017.01.034" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Appl+Soft+Comput&amp;title=Detecting+falls+with+x-factor+hidden+Markov+models&amp;author=SS+Khan&amp;author=ME+Karg&amp;author=D+Kuli%C4%87&amp;author=J+Hoey&amp;volume=55&amp;publication_year=2017&amp;pages=168-177&amp;doi=10.1016/j.asoc.2017.01.034&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR18">18. <span class="element-citation">Khan SS, Madden MG. One-class classification: taxonomy of study and review of techniques. <span><span class="ref-journal">Knowl Eng Rev. </span>2014;<span class="ref-vol">29</span>(3):345–374. doi:&nbsp;10.1017/S026988891300043X.</span> [<a href="https://doi.org/10.1017%2FS026988891300043X" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Knowl+Eng+Rev&amp;title=One-class+classification:+taxonomy+of+study+and+review+of+techniques&amp;author=SS+Khan&amp;author=MG+Madden&amp;volume=29&amp;issue=3&amp;publication_year=2014&amp;pages=345-374&amp;doi=10.1017/S026988891300043X&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR19">19. <span class="mixed-citation">Khan SS, Taati B (2017) Detecting unseen falls from wearable devices using channel-wise ensemble of autoencoders. Expert Systems with Applications</span></div><div class="ref-cit-blk half_rhythm" id="CR20">20. <span class="element-citation">Ma X, Wang H, Xue B, Zhou M, Ji B, Li Y. Depth-based human fall detection via shape features and improved extreme learning machine. <span><span class="ref-journal">IEEE J Biomed Health Inform. </span>2014;<span class="ref-vol">18</span>(6):1915–1922. doi:&nbsp;10.1109/JBHI.2014.2304357.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/25375688" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FJBHI.2014.2304357" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+J+Biomed+Health+Inform&amp;title=Depth-based+human+fall+detection+via+shape+features+and+improved+extreme+learning+machine&amp;author=X+Ma&amp;author=H+Wang&amp;author=B+Xue&amp;author=M+Zhou&amp;author=B+Ji&amp;volume=18&amp;issue=6&amp;publication_year=2014&amp;pages=1915-1922&amp;pmid=25375688&amp;doi=10.1109/JBHI.2014.2304357&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR21">21. <span class="mixed-citation">Masci J, Meier U, Cireşan D, Schmidhuber J (2011) Stacked convolutional auto-encoders for hierarchical feature extraction. In: International conference on artificial neural networks. Springer, pp 52–59</span></div><div class="ref-cit-blk half_rhythm" id="CR22">22. <span class="mixed-citation">Mercuri M, Garripoli C, Karsmakers P, Soh PJ, Vandenbosch GA, Pace C, Leroux P, Schreurs D (2016) Healthcare system for non-invasive fall detection in indoor environment. In: Applications in electronics pervading industry, environment and society. Springer, pp 145–152</span></div><div class="ref-cit-blk half_rhythm" id="CR23">23. <span class="mixed-citation">Munawar A, Vinayavekhin P, De Magistris G (2017) Spatio-temporal anomaly detection for industrial robots through prediction in unsupervised feature space. In: 2017 IEEE Winter conference on applications of computer vision (WACV). IEEE, pp 1017–1025</span></div><div class="ref-cit-blk half_rhythm" id="CR24">24. <span class="mixed-citation">Nathan Silberman Derek Hoiem PK, Fergus R (2012) Indoor segmentation and support inference from rgbd images. In: ECCV</span></div><div class="ref-cit-blk half_rhythm" id="CR25">25. <span class="mixed-citation">Nogas J, Khan SS, Mihailidis A (2018) Fall detection from thermal camera using convolutional lstm autoencoder. In: Proceedings of the 2nd workshop on aging, rehabilitation and independent assisted living. IJCAI Workshop</span></div><div class="ref-cit-blk half_rhythm" id="CR26">26. <span class="element-citation">Penttilä J.  <span class="ref-journal">A method for anomaly detection in hyperspectral images, using deep convolutional autoencoders. Master’s thesis.</span> Finland: University of Jyväskylä; 2017.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=A+method+for+anomaly+detection+in+hyperspectral+images,+using+deep+convolutional+autoencoders.+Master%E2%80%99s+thesis&amp;author=J+Penttil%C3%A4&amp;publication_year=2017&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR27">27. <span class="mixed-citation">Ribeiro M, Lazzaretti AE, Lopes HS (2017) A study of deep convolutional auto-encoders for anomaly detection in videos. Pattern Recognition Letters</span></div><div class="ref-cit-blk half_rhythm" id="CR28">28. <span class="element-citation">Rubenstein LZ, Robbins AS, Josephson KR, Schulman BL, Osterweil D. The value of assessing falls in an elderly population: a randomized clinical trial. <span><span class="ref-journal">Ann Intern Med. </span>1990;<span class="ref-vol">113</span>(4):308–316. doi:&nbsp;10.7326/0003-4819-113-4-308.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/2115755" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.7326%2F0003-4819-113-4-308" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Ann+Intern+Med&amp;title=The+value+of+assessing+falls+in+an+elderly+population:+a+randomized+clinical+trial&amp;author=LZ+Rubenstein&amp;author=AS+Robbins&amp;author=KR+Josephson&amp;author=BL+Schulman&amp;author=D+Osterweil&amp;volume=113&amp;issue=4&amp;publication_year=1990&amp;pages=308-316&amp;pmid=2115755&amp;doi=10.7326/0003-4819-113-4-308&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR29">29. <span class="element-citation">Sabokrou M, Fayyaz M, Fathy M, Klette R. Deep-cascade: cascading 3d deep neural networks for fast anomaly detection and localization in crowded scenes. <span><span class="ref-journal">IEEE Trans Image Process. </span>2017;<span class="ref-vol">26</span>(4):1992–2004. doi:&nbsp;10.1109/TIP.2017.2670780.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28221995" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTIP.2017.2670780" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans+Image+Process&amp;title=Deep-cascade:+cascading+3d+deep+neural+networks+for+fast+anomaly+detection+and+localization+in+crowded+scenes&amp;author=M+Sabokrou&amp;author=M+Fayyaz&amp;author=M+Fathy&amp;author=R+Klette&amp;volume=26&amp;issue=4&amp;publication_year=2017&amp;pages=1992-2004&amp;pmid=28221995&amp;doi=10.1109/TIP.2017.2670780&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR30">30. <span class="mixed-citation">Samek W, Wiegand T, Müller KR (2017) Explainable artificial intelligence: understanding, visualizing and interpreting deep learning models. arXiv:<a href="https://arxiv.org/abs/1708.08296" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://arxiv.org/abs/1708.08296</a></span></div><div class="ref-cit-blk half_rhythm" id="CR31">31. <span class="mixed-citation">Skubic M, Harris BH, Stone E, Ho K, Su BY, Rantz M (2016) Testing non-wearable fall detection methods in the homes of older adults. In: 2016 IEEE 38th annual international conference of the engineering in medicine and biology society (EMBC). IEEE, pp 557–560 [<a href="https://pubmed.ncbi.nlm.nih.gov/28268392" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>]</span></div><div class="ref-cit-blk half_rhythm" id="CR32">32. <span class="mixed-citation">Tran HT, Hogg D (2017) Anomaly detection using a convolutional winner-take-all autoencoder. In: Proceedings of the British machine vision conference 2017. Leeds</span></div><div class="ref-cit-blk half_rhythm" id="CR33">33. <span class="mixed-citation">Vadivelu S, Ganesan S, Murthy OR, Dhall A (2016) Thermal imaging based elderly fall detection. In: ACCV workshop. Springer, pp 541–553</span></div><div class="ref-cit-blk half_rhythm" id="CR34">34. <span class="mixed-citation">Viacheslav V, Alexander F, Vladimir M, Svetlana T, Oksana L (2014) Kinect depth map restoration using modified exemplar-based inpainting. In: 2014 12th International conference on signal processing (ICSP). IEEE, pp 1175–1179</span></div><div class="ref-cit-blk half_rhythm" id="CR35">35. <span class="element-citation">Xu D, Yan Y, Ricci E, Sebe N. Detecting anomalous events in videos by learning deep representations of appearance and motion. <span><span class="ref-journal">Comput Vis Image Underst. </span>2017;<span class="ref-vol">156</span>:117–127. doi:&nbsp;10.1016/j.cviu.2016.10.010.</span> [<a href="https://doi.org/10.1016%2Fj.cviu.2016.10.010" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Comput+Vis+Image+Underst&amp;title=Detecting+anomalous+events+in+videos+by+learning+deep+representations+of+appearance+and+motion&amp;author=D+Xu&amp;author=Y+Yan&amp;author=E+Ricci&amp;author=N+Sebe&amp;volume=156&amp;publication_year=2017&amp;pages=117-127&amp;doi=10.1016/j.cviu.2016.10.010&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR36">36. <span class="element-citation">Yusif S, Soar J, Hafeez-Baig A. Older people, assistive technologies, and the barriers to adoption: a systematic review. <span><span class="ref-journal">Int J Med Inform. </span>2016;<span class="ref-vol">94</span>:112–116. doi:&nbsp;10.1016/j.ijmedinf.2016.07.004.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/27573318" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.ijmedinf.2016.07.004" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int+J+Med+Inform&amp;title=Older+people,+assistive+technologies,+and+the+barriers+to+adoption:+a+systematic+review&amp;author=S+Yusif&amp;author=J+Soar&amp;author=A+Hafeez-Baig&amp;volume=94&amp;publication_year=2016&amp;pages=112-116&amp;pmid=27573318&amp;doi=10.1016/j.ijmedinf.2016.07.004&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="CR37">37. <span class="mixed-citation">Zhao Y, Deng B, Shen C, Liu Y, Lu H, Hua XS (2017) Spatio-temporal autoencoder for video anomaly detection. In: Proceedings of the 2017 ACM on multimedia conference, MM ’17. ACM, New York</span></div></div></div><div style="display: none; width: 200px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true" class="ui-helper-reset ui-ncbipopper-wrapper ui-ncbilinksmenu"><ul id="ui-ncbiinpagenav-2"><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Abs1title">Abstract</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec1title">Introduction</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec2title">Related Work</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec3title">Deep Spatio-Temporal Convolutional Autoencoders</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec7title">Anomaly Scores to Detect Unseen Falls</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec10title">Experiments and Results</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Sec20title">Conclusions, Discussion, and Future Work</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#notes-a.v.btitle">Compliance with Ethical Standards</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#fn-group-a.v.atitle">Footnotes</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#article-aaff-infotitle">Contributor Information</a></li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#Bib1title">References</a></li></ul></div></div><!--post-content--><div class="courtesy-note whole_rhythm small"><hr><div class="half_rhythm">Articles from <span class="acknowledgment-journal-title">Journal of Healthcare Informatics Research</span> are provided here courtesy of <strong>Springer</strong></div><hr></div><div id="body-link-poppers"><span></span><div id="body-link-popper-CR4" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">4. <span class="mixed-citation">CDC (2017) Enter of disease control and prevention – important facts about falls. <a href="https://www.cdc.gov/homeandrecreationalsafety/falls/adultfalls.html" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://www.cdc.gov/homeandrecreationalsafety/falls/adultfalls.html</a>. [Online accessed 22-December-2017]</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR4">Ref list</a>]</div><div id="body-link-popper-CR28" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">28. <span class="element-citation">Rubenstein LZ, Robbins AS, Josephson KR, Schulman BL, Osterweil D. The value of assessing falls in an elderly population: a randomized clinical trial. <span><span class="ref-journal">Ann Intern Med. </span>1990;<span class="ref-vol">113</span>(4):308–316. doi:&nbsp;10.7326/0003-4819-113-4-308.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/2115755" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.7326%2F0003-4819-113-4-308" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Ann+Intern+Med&amp;title=The+value+of+assessing+falls+in+an+elderly+population:+a+randomized+clinical+trial&amp;author=LZ+Rubenstein&amp;author=AS+Robbins&amp;author=KR+Josephson&amp;author=BL+Schulman&amp;author=D+Osterweil&amp;volume=113&amp;issue=4&amp;publication_year=1990&amp;pages=308-316&amp;pmid=2115755&amp;doi=10.7326/0003-4819-113-4-308&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR28">Ref list</a>]</div><div id="body-link-popper-CR17" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">17. <span class="element-citation">Khan SS, Karg ME, Kulić D, Hoey J. Detecting falls with x-factor hidden Markov models. <span><span class="ref-journal">Appl Soft Comput. </span>2017;<span class="ref-vol">55</span>:168–177. doi:&nbsp;10.1016/j.asoc.2017.01.034.</span> [<a href="https://doi.org/10.1016%2Fj.asoc.2017.01.034" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Appl+Soft+Comput&amp;title=Detecting+falls+with+x-factor+hidden+Markov+models&amp;author=SS+Khan&amp;author=ME+Karg&amp;author=D+Kuli%C4%87&amp;author=J+Hoey&amp;volume=55&amp;publication_year=2017&amp;pages=168-177&amp;doi=10.1016/j.asoc.2017.01.034&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR17">Ref list</a>]</div><div id="body-link-popper-CR22" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">22. <span class="mixed-citation">Mercuri M, Garripoli C, Karsmakers P, Soh PJ, Vandenbosch GA, Pace C, Leroux P, Schreurs D (2016) Healthcare system for non-invasive fall detection in indoor environment. In: Applications in electronics pervading industry, environment and society. Springer, pp 145–152</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR22">Ref list</a>]</div><div id="body-link-popper-CR36" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">36. <span class="element-citation">Yusif S, Soar J, Hafeez-Baig A. Older people, assistive technologies, and the barriers to adoption: a systematic review. <span><span class="ref-journal">Int J Med Inform. </span>2016;<span class="ref-vol">94</span>:112–116. doi:&nbsp;10.1016/j.ijmedinf.2016.07.004.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/27573318" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.ijmedinf.2016.07.004" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Int+J+Med+Inform&amp;title=Older+people,+assistive+technologies,+and+the+barriers+to+adoption:+a+systematic+review&amp;author=S+Yusif&amp;author=J+Soar&amp;author=A+Hafeez-Baig&amp;volume=94&amp;publication_year=2016&amp;pages=112-116&amp;pmid=27573318&amp;doi=10.1016/j.ijmedinf.2016.07.004&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR36">Ref list</a>]</div><div id="body-link-popper-CR31" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">31. <span class="mixed-citation">Skubic M, Harris BH, Stone E, Ho K, Su BY, Rantz M (2016) Testing non-wearable fall detection methods in the homes of older adults. In: 2016 IEEE 38th annual international conference of the engineering in medicine and biology society (EMBC). IEEE, pp 557–560 [<a href="https://pubmed.ncbi.nlm.nih.gov/28268392" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>]</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR31">Ref list</a>]</div><div id="body-link-popper-CR21" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">21. <span class="mixed-citation">Masci J, Meier U, Cireşan D, Schmidhuber J (2011) Stacked convolutional auto-encoders for hierarchical feature extraction. In: International conference on artificial neural networks. Springer, pp 52–59</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR21">Ref list</a>]</div><div id="body-link-popper-CR1" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">1. <span class="mixed-citation">Baccouche M, Mamalet F, Wolf C, Garcia C, Baskurt A (2012) Spatio-temporal convolutional sparse autoencoder for sequence classification. In: BMVC. Citeseer</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR1">Ref list</a>]</div><div id="body-link-popper-CR25" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">25. <span class="mixed-citation">Nogas J, Khan SS, Mihailidis A (2018) Fall detection from thermal camera using convolutional lstm autoencoder. In: Proceedings of the 2nd workshop on aging, rehabilitation and independent assisted living. IJCAI Workshop</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR25">Ref list</a>]</div><div id="body-link-popper-CR27" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">27. <span class="mixed-citation">Ribeiro M, Lazzaretti AE, Lopes HS (2017) A study of deep convolutional auto-encoders for anomaly detection in videos. Pattern Recognition Letters</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR27">Ref list</a>]</div><div id="body-link-popper-CR12" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">12. <span class="mixed-citation">Gutoski M, Aquino NMR, Ribeiro M, Lazzaretti AE, Lopes HS (2017) Detection of video anomalies using convolutional autoencoders and one-class support vector machines. In: Proc. XIII Brazilian congress on computational intelligence</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR12">Ref list</a>]</div><div id="body-link-popper-CR32" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">32. <span class="mixed-citation">Tran HT, Hogg D (2017) Anomaly detection using a convolutional winner-take-all autoencoder. In: Proceedings of the British machine vision conference 2017. Leeds</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR32">Ref list</a>]</div><div id="body-link-popper-CR5" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">5. <span class="mixed-citation">Chalapathy R, Menon AK, Chawla S (2017) Robust, deep and inductive anomaly detection. In: European conference on machine learning. Skopje</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR5">Ref list</a>]</div><div id="body-link-popper-CR13" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">13. <span class="mixed-citation">Hasan M, Choi J, Neumann J, Roy-Chowdhury AK, Davis LS (2016) Learning temporal regularity in video sequences. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 733–742</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR13">Ref list</a>]</div><div id="body-link-popper-CR23" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">23. <span class="mixed-citation">Munawar A, Vinayavekhin P, De Magistris G (2017) Spatio-temporal anomaly detection for industrial robots through prediction in unsupervised feature space. In: 2017 IEEE Winter conference on applications of computer vision (WACV). IEEE, pp 1017–1025</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR23">Ref list</a>]</div><div id="body-link-popper-CR35" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">35. <span class="element-citation">Xu D, Yan Y, Ricci E, Sebe N. Detecting anomalous events in videos by learning deep representations of appearance and motion. <span><span class="ref-journal">Comput Vis Image Underst. </span>2017;<span class="ref-vol">156</span>:117–127. doi:&nbsp;10.1016/j.cviu.2016.10.010.</span> [<a href="https://doi.org/10.1016%2Fj.cviu.2016.10.010" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Comput+Vis+Image+Underst&amp;title=Detecting+anomalous+events+in+videos+by+learning+deep+representations+of+appearance+and+motion&amp;author=D+Xu&amp;author=Y+Yan&amp;author=E+Ricci&amp;author=N+Sebe&amp;volume=156&amp;publication_year=2017&amp;pages=117-127&amp;doi=10.1016/j.cviu.2016.10.010&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR35">Ref list</a>]</div><div id="body-link-popper-CR37" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">37. <span class="mixed-citation">Zhao Y, Deng B, Shen C, Liu Y, Lu H, Hua XS (2017) Spatio-temporal autoencoder for video anomaly detection. In: Proceedings of the 2017 ACM on multimedia conference, MM ’17. ACM, New York</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR37">Ref list</a>]</div><div id="body-link-popper-CR26" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">26. <span class="element-citation">Penttilä J.  <span class="ref-journal">A method for anomaly detection in hyperspectral images, using deep convolutional autoencoders. Master’s thesis.</span> Finland: University of Jyväskylä; 2017.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=A+method+for+anomaly+detection+in+hyperspectral+images,+using+deep+convolutional+autoencoders.+Master%E2%80%99s+thesis&amp;author=J+Penttil%C3%A4&amp;publication_year=2017&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR26">Ref list</a>]</div><div id="body-link-popper-CR29" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">29. <span class="element-citation">Sabokrou M, Fayyaz M, Fathy M, Klette R. Deep-cascade: cascading 3d deep neural networks for fast anomaly detection and localization in crowded scenes. <span><span class="ref-journal">IEEE Trans Image Process. </span>2017;<span class="ref-vol">26</span>(4):1992–2004. doi:&nbsp;10.1109/TIP.2017.2670780.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28221995" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTIP.2017.2670780" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans+Image+Process&amp;title=Deep-cascade:+cascading+3d+deep+neural+networks+for+fast+anomaly+detection+and+localization+in+crowded+scenes&amp;author=M+Sabokrou&amp;author=M+Fayyaz&amp;author=M+Fathy&amp;author=R+Klette&amp;volume=26&amp;issue=4&amp;publication_year=2017&amp;pages=1992-2004&amp;pmid=28221995&amp;doi=10.1109/TIP.2017.2670780&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR29">Ref list</a>]</div><div id="body-link-popper-CR8" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">8. <span class="mixed-citation">Chong YS, Tay YH (2017) Abnormal event detection in videos using spatiotemporal autoencoder. In: International symposium on neural networks. Springer, pp 189–196</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR8">Ref list</a>]</div><div id="body-link-popper-CR6" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">6. <span class="element-citation">Chandola V, Banerjee A, Kumar V. Anomaly detection: a survey. <span><span class="ref-journal">ACM Comput Surv. </span>2009;<span class="ref-vol">41</span>(3):15:1–15:58. doi:&nbsp;10.1145/1541880.1541882.</span> [<a href="https://doi.org/10.1145%2F1541880.1541882" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=ACM+Comput+Surv&amp;title=Anomaly+detection:+a+survey&amp;author=V+Chandola&amp;author=A+Banerjee&amp;author=V+Kumar&amp;volume=41&amp;issue=3&amp;publication_year=2009&amp;pages=15:1-15:58&amp;doi=10.1145/1541880.1541882&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR6">Ref list</a>]</div><div id="body-link-popper-CR10" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">10. <span class="element-citation">Goldstein M, Uchida S. A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data. <span><span class="ref-journal">PloS one 11. </span>2016;<span class="ref-vol">4</span>:e0152173. doi:&nbsp;10.1371/journal.pone.0152173.</span> <span class="nowrap">[<a class="int-reflink" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4836738/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/27093601" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1371%2Fjournal.pone.0152173" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=PloS+one+11&amp;title=A+comparative+evaluation+of+unsupervised+anomaly+detection+algorithms+for+multivariate+data&amp;author=M+Goldstein&amp;author=S+Uchida&amp;volume=4&amp;publication_year=2016&amp;pages=e0152173&amp;doi=10.1371/journal.pone.0152173&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR10">Ref list</a>]</div><div id="body-link-popper-CR18" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">18. <span class="element-citation">Khan SS, Madden MG. One-class classification: taxonomy of study and review of techniques. <span><span class="ref-journal">Knowl Eng Rev. </span>2014;<span class="ref-vol">29</span>(3):345–374. doi:&nbsp;10.1017/S026988891300043X.</span> [<a href="https://doi.org/10.1017%2FS026988891300043X" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Knowl+Eng+Rev&amp;title=One-class+classification:+taxonomy+of+study+and+review+of+techniques&amp;author=SS+Khan&amp;author=MG+Madden&amp;volume=29&amp;issue=3&amp;publication_year=2014&amp;pages=345-374&amp;doi=10.1017/S026988891300043X&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR18">Ref list</a>]</div><div id="body-link-popper-CR19" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">19. <span class="mixed-citation">Khan SS, Taati B (2017) Detecting unseen falls from wearable devices using channel-wise ensemble of autoencoders. Expert Systems with Applications</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR19">Ref list</a>]</div><div id="body-link-popper-CR15" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">15. <span class="element-citation">Ji S, Xu W, Yang M, Yu K. 3d convolutional neural networks for human action recognition. <span><span class="ref-journal">IEEE Trans Pattern Anal Mach Intell. </span>2013;<span class="ref-vol">35</span>(1):221–231. doi:&nbsp;10.1109/TPAMI.2012.59.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/22392705" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FTPAMI.2012.59" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans+Pattern+Anal+Mach+Intell&amp;title=3d+convolutional+neural+networks+for+human+action+recognition&amp;author=S+Ji&amp;author=W+Xu&amp;author=M+Yang&amp;author=K+Yu&amp;volume=35&amp;issue=1&amp;publication_year=2013&amp;pages=221-231&amp;pmid=22392705&amp;doi=10.1109/TPAMI.2012.59&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR15">Ref list</a>]</div><div id="body-link-popper-CR7" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">7. <span class="mixed-citation">Chollet F., et al. (2015) Keras: the python deep learning library <a href="https://github.com/fchollet/keras" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://github.com/fchollet/keras</a>. Online accessed 20-January-2018</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR7">Ref list</a>]</div><div id="body-link-popper-CR9" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">9. <span class="mixed-citation">Du Tran Lubomir Bourdev RFLTMP (2015) Learning spatiotemporal features with 3d convolutional networks. In: IEEE International conference on computer vision (ICCV). IEEE, DOI 10.1109/ICCV.2015.510</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR9">Ref list</a>]</div><div id="body-link-popper-CR33" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">33. <span class="mixed-citation">Vadivelu S, Ganesan S, Murthy OR, Dhall A (2016) Thermal imaging based elderly fall detection. In: ACCV workshop. Springer, pp 541–553</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR33">Ref list</a>]</div><div id="body-link-popper-CR3" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">3. <span class="element-citation">Bogdan Kwolek MK. Human fall detection on embedded platform using depth maps and wireless accelerometer. <span><span class="ref-journal">Comput Methods Programs Biomed. </span>2014;<span class="ref-vol">117</span>:489–501. doi:&nbsp;10.1016/j.cmpb.2014.09.005.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/25308505" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.cmpb.2014.09.005" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Comput+Methods+Programs+Biomed&amp;title=Human+fall+detection+on+embedded+platform+using+depth+maps+and+wireless+accelerometer&amp;author=MK+Bogdan+Kwolek&amp;volume=117&amp;publication_year=2014&amp;pages=489-501&amp;pmid=25308505&amp;doi=10.1016/j.cmpb.2014.09.005&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR3">Ref list</a>]</div><div id="body-link-popper-CR20" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">20. <span class="element-citation">Ma X, Wang H, Xue B, Zhou M, Ji B, Li Y. Depth-based human fall detection via shape features and improved extreme learning machine. <span><span class="ref-journal">IEEE J Biomed Health Inform. </span>2014;<span class="ref-vol">18</span>(6):1915–1922. doi:&nbsp;10.1109/JBHI.2014.2304357.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/25375688" ref="reftype=pubmed&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1109%2FJBHI.2014.2304357" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+J+Biomed+Health+Inform&amp;title=Depth-based+human+fall+detection+via+shape+features+and+improved+extreme+learning+machine&amp;author=X+Ma&amp;author=H+Wang&amp;author=B+Xue&amp;author=M+Zhou&amp;author=B+Ji&amp;volume=18&amp;issue=6&amp;publication_year=2014&amp;pages=1915-1922&amp;pmid=25375688&amp;doi=10.1109/JBHI.2014.2304357&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR20">Ref list</a>]</div><div id="body-link-popper-CR34" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">34. <span class="mixed-citation">Viacheslav V, Alexander F, Vladimir M, Svetlana T, Oksana L (2014) Kinect depth map restoration using modified exemplar-based inpainting. In: 2014 12th International conference on signal processing (ICSP). IEEE, pp 1175–1179</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR34">Ref list</a>]</div><div id="body-link-popper-CR24" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">24. <span class="mixed-citation">Nathan Silberman Derek Hoiem PK, Fergus R (2012) Indoor segmentation and support inference from rgbd images. In: ECCV</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR24">Ref list</a>]</div><div id="body-link-popper-CR14" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">14. <span class="mixed-citation">Itseez (2015) Open source computer vision library. <a href="https://github.com/itseez/opencv" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://github.com/itseez/opencv</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR14">Ref list</a>]</div><div id="body-link-popper-CR2" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">2. <span class="mixed-citation">Bertalmio M, Bertozzi AL, Sapiro G (2001) Navier-stokes, fluid dynamics, and image and video inpainting. In: Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001, vol 1, pp I–355–I–362, DOI 10.1109/CVPR.2001.990497</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR2">Ref list</a>]</div><div id="body-link-popper-CR16" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">16. <span class="element-citation">Khan SS, Ahmad A. Relationship between variants of one-class nearest neighbors and creating their accurate ensembles. <span><span class="ref-journal">IEEE Trans Knowl Data Eng. </span>2018;<span class="ref-vol">30</span>(9):1796–1809. doi:&nbsp;10.1109/TKDE.2018.2806975.</span> [<a href="https://doi.org/10.1109%2FTKDE.2018.2806975" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans+Knowl+Data+Eng&amp;title=Relationship+between+variants+of+one-class+nearest+neighbors+and+creating+their+accurate+ensembles&amp;author=SS+Khan&amp;author=A+Ahmad&amp;volume=30&amp;issue=9&amp;publication_year=2018&amp;pages=1796-1809&amp;doi=10.1109/TKDE.2018.2806975&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar" role="button" aria-expanded="false" aria-haspopup="true">Google Scholar</a>]</span></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR16">Ref list</a>]</div><div id="body-link-popper-CR30" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">30. <span class="mixed-citation">Samek W, Wiegand T, Müller KR (2017) Explainable artificial intelligence: understanding, visualizing and interpreting deep learning models. arXiv:<a href="https://arxiv.org/abs/1708.08296" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=8982799&amp;issue-id=404748&amp;journal-id=4174&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">https://arxiv.org/abs/1708.08296</a></span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR30">Ref list</a>]</div><div id="body-link-popper-CR11" class="body-link-popper ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic" style="display: none; width: 400px; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true">11. <span class="mixed-citation">Goodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, Courville A, Bengio Y (2014) Generative adversarial nets. In: Advances in neural information processing systems, pp 2672–2680</span> [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#CR11">Ref list</a>]</div></div></div>
            
        </section>
    </article>
    <aside class="usa-width-one-fourth usa-layout-docs-sidenav pmc-sidebar">
         
  

<div class="scroller">

    
        <section>
                <h6>Other Formats</h6>
                <ul class="pmc-sidebar__formats">
                  <li class="pubreader-link other_item"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/?report=reader" class="sidefm-pmclink">PubReader</a></li>
<li class="pdf-link other_item"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/pdf/41666_2019_Article_61.pdf" class="int-view">PDF (1.5M)</a></li>
                </ul>
        </section>
    
    <section>
        <h6>Actions</h6>
        <ul class="pmc-sidebar__actions">
            <li>
                <button role="button" class="citation-button citation-dialog-trigger ctxp" aria-label="Open dialog with citation text in different styles" data-ga-category="save_share" data-ga-action="cite" data-ga-label="open" data-all-citations-url="/pmc/resources/citations/8982799/" data-citation-style="nlm" data-download-format-link="/pmc/resources/citations/8982799/export/">
                    <span class="button-label">Cite</span>
                </button>
            </li>
            <li>
                
                    

<div class="collections-button-container" data-article-id="8982799" data-article-db="pmc">
  <button class="collections-button collections-dialog-trigger collections-button-empty" aria-label="Save article in MyNCBI collections." data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_button" data-collections-open-dialog-enabled="false" data-collections-open-dialog-url="https://www.ncbi.nlm.nih.gov/account?back_url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F%23open-collections-dialog" data-in-collections="false">
      <span class="button-label">Collections</span>
  </button>
  <div class="overlay collections-dialog-overlay" role="dialog">
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true" role="document">
    <div class="title">Add to Collections</div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form" class="collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors" data-existing-collections-url="/pmc/list-existing-collections/" data-add-to-existing-collection-url="/pmc/add-to-existing-collection/" data-create-and-add-to-new-collection-url="/pmc/create-and-add-to-new-collection/" data-myncbi-max-collection-name-length="100" data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

  <input type="hidden" name="csrfmiddlewaretoken" value="Z1wlUS2IdMoRH6er7wVEUXiJxGaWCn1Q6W71YasyERnavgTnHGolLdY3kfv1MEhC">

  

  <div class="choice-group" role="radiogroup">
    <ul class="radio-group-items">
      <li>
        <input type="radio" id="collections-action-dialog-new-aside " class="collections-new" name="collections" value="new" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_new">
        <label for="collections-action-dialog-new-aside ">Create a new collection</label>
      </li>
      <li>
        <input type="radio" id="collections-action-dialog-existing-aside " class="collections-existing" name="collections" value="existing" checked="true" data-ga-category="collections_button" data-ga-action="click" data-ga-label="collections_radio_existing">
        <label for="collections-action-dialog-existing-aside ">Add to an existing collection</label>
      </li>
    </ul>
  </div>

  <div class="controls-wrapper">
    <div class="action-panel-control-wrap new-collections-controls">
      <label for="collections-action-dialog-add-to-new" class="action-panel-label required-field-asterisk">
        Name your collection:
      </label>
      <input type="text" name="add-to-new-collection" id="collections-action-dialog-add-to-new" class="collections-action-add-to-new" pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/" maxlength="" data-ga-category="collections_button" data-ga-action="create_collection" data-ga-label="non_favorties_collection">
      <div class="collections-new-name-too-long usa-input-error-message selection-validation-message">
        Name must be less than  characters
      </div>
    </div>
    <div class="action-panel-control-wrap existing-collections-controls">
      <label for="collections-action-dialog-add-to-existing" class="action-panel-label">
        Choose a collection:
      </label>
      <select id="collections-action-dialog-add-to-existing" class="action-panel-selector collections-action-add-to-existing" data-ga-category="collections_button" data-ga-action="select_collection" data-ga-label="($(&#39;.collections-action-add-to-existing&#39;).val() === &#39;Favorites&#39;) ? &#39;Favorites&#39; : &#39;non_favorites_collection&#39;">
      </select>
      <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
        Unable to load your collection due to an error<br>
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#">Please try again</a>
      </div>
    </div>
  </div>

  <div class="action-panel-actions">
    <button class="action-panel-submit" type="submit" data-loading-label="Adding..." data-pinger-ignore="" data-ga-category="collections_button" data-ga-action="click" data-ga-label="add">
      Add
    </button>
    <button class="action-panel-cancel" aria-label="Close &#39;Add to Collections&#39; panel" ref="linksrc=close_collections_panel" aria-controls="collections-action-panel" aria-expanded="false" data-ga-category="collections_button" data-ga-action="click" data-ga-label="cancel">
      Cancel
    </button>
  </div>
</form>
    </div>
  </div>
</div>
</div>
                
            </li>

        </ul>
    </section>
    
        <section class="social-sharing">
            <h6>Share</h6>
            <ul class="pmc-sidebar__share">
                <li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F&amp;text=DeepFall%3A%20Non-Invasive%20Fall%20Detection%20with%20Deep%20Spatio-Temporal%20Convolutional%20Autoencoders" alt="Share on Twitter" aria-expanded="false" aria-haspopup="true"><i class="fa fa-twitter fa-stack-1x">&nbsp;</i></a></li> 
<li><a class="fa-stack fa-lg" target="_blank" rel="noopener noreferrer" role="button" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8982799%2F" alt="Share on Facebook" aria-expanded="false" aria-haspopup="true"><i class="fa fa-facebook fa-stack-1x">&nbsp;</i></a></li>
                <li>
                    <div class="share-permalink dropdown-block">
                        <button class="trigger" alt="Show article permalink" aria-expanded="false" aria-haspopup="true">
                            <i class="fa-stack fa-lg">
                                <i class="fa fa-link fa-stack-1x">&nbsp;</i>
                            </i>
                        </button>
                        <div class="dropdown dropdown-container" aria-hidden="true">
                              <div class="title">
                                Permalink
                              </div>
                              <div class="content">
                                  <input type="text" class="permalink-text" value="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/" aria-label="Article permalink"><button class="permalink-copy-button usa-button-primary" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                                      <span class="button-title">Copy</span>
                                  </button>
                              </div>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
    
    <section>
        <h6>RESOURCES</h6>
        <ul class="pmc-sidebar__resources">
        
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_similar_articles" data-ga-label="/pmc/articles/PMC8982799/" class="usa-accordion-button" aria-controls="similar-articles-accordion-aside" aria-expanded="false" data-action-open="open_similar_articles" data-action-close="close_similar_articles">
                        Similar articles
                    </button>
                    <div data-source-url="/pmc/resources/similar-article-links/35415435/" class="usa-accordion-content pmc-sidebar__resources--citations" id="similar-articles-accordion-aside" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_cited_by" data-ga-label="/pmc/articles/PMC8982799/" class="usa-accordion-button" aria-controls="cited-by-accordion-aside" aria-expanded="false" data-action-open="open_cited_by" data-action-close="close_cited_by">
                        Cited by other articles
                    </button>
                    <div data-source-url="/pmc/resources/cited-by-links/35415435/" class="usa-accordion-content pmc-sidebar__resources--citations" id="cited-by-accordion-aside" aria-hidden="true">
                        
                    </div>
                </div>
            </li>
            <li>
                <div class="usa-accordion">
                    <button data-ga-category="resources_accordion" data-ga-action="open_NCBI_links" data-ga-label="/pmc/articles/PMC8982799/" class="usa-accordion-button" aria-controls="links-accordion-aside" aria-expanded="false" data-action-open="open_NCBI_links" data-action-close="close_NCBI_link">
                        Links to NCBI Databases
                    </button>
                    <div data-source-url="/pmc/resources/db-links/8982799/" class="usa-accordion-content" id="links-accordion-aside" aria-hidden="true"></div>
                </div>
            </li>

            
        
        </ul>
    </section>

 </div>

    </aside>
</main>

    <div class="overlay citation-dialog-overlay" role="dialog" aria-label="Citation Dialog">
  <div class="dialog citation-dialog" role="document">
    <button class="close-overlay" tabindex="1" data-pinger-ignore="true">[x]</button>
    <div class="title">Cite</div>
    <div class="citation-text-block">
  <div class="citation-text"></div>
  <div class="citation-actions">
    <button class="copy-button dialog-focus" data-ga-category="save_share" data-ga-action="cite" data-ga-label="copy" tabindex="2">
      Copy
    </button>

      <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8982799/#" class="export-button" data-ga-category="save_share" data-ga-action="cite" data-ga-label="download" title="Download a file for external citation management software" tabindex="3">
          <span class="title">Download .nbib</span>
          <span class="title-mobile">.nbib</span>
      </a>


    

<div class="citation-style-selector-wrapper">
  <label class="selector-label">Format:</label>
  <select aria-label="Format" class="citation-style-selector" tabindex="4">
    
      <option data-style-url-name="ama" value="AMA">
        AMA
      </option>
    
      <option data-style-url-name="apa" value="APA">
        APA
      </option>
    
      <option data-style-url-name="mla" value="MLA">
        MLA
      </option>
    
      <option data-style-url-name="nlm" value="NLM" selected="selected">
        NLM
      </option>
    
  </select>
</div>
  </div>
<div class="dots-loading-indicator citation-loading-indicator">
        <div class="dot dot-1"></div>
        <div class="dot dot-2"></div>
        <div class="dot dot-3"></div>
      </div></div>
  </div>
</div>

     <!-- ========== BEGIN FOOTER ========== -->
 <footer>
      <section class="icon-section">
        <div id="icon-section-header" class="icon-section_header">Follow NCBI</div>
        <div class="grid-container container">
          <div class="icon-section_container">
            <a class="footer-icon" id="footer_twitter" href="https://twitter.com/ncbi" aria-label="Twitter" role="button" aria-expanded="false" aria-haspopup="true" target="_blank"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <defs>
                  <style>
                    .cls-11 {
                      fill: #737373;
                    }
                  </style>
                </defs>
                <title>Twitter</title>
                <path class="cls-11" d="M250.11,105.48c-7,3.14-13,3.25-19.27.14,8.12-4.86,8.49-8.27,11.43-17.46a78.8,78.8,0,0,1-25,9.55,39.35,39.35,0,0,0-67,35.85,111.6,111.6,0,0,1-81-41.08A39.37,39.37,0,0,0,81.47,145a39.08,39.08,0,0,1-17.8-4.92c0,.17,0,.33,0,.5a39.32,39.32,0,0,0,31.53,38.54,39.26,39.26,0,0,1-17.75.68,39.37,39.37,0,0,0,36.72,27.3A79.07,79.07,0,0,1,56,223.34,111.31,111.31,0,0,0,116.22,241c72.3,0,111.83-59.9,111.83-111.84,0-1.71,0-3.4-.1-5.09C235.62,118.54,244.84,113.37,250.11,105.48Z">
                </path>
              </svg></a>
            <a class="footer-icon" id="footer_facebook" href="https://www.facebook.com/ncbi.nlm" aria-label="Facebook" role="button" aria-expanded="false" aria-haspopup="true" target="_blank"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <title>Facebook</title>
                <path class="cls-11" d="M210.5,115.12H171.74V97.82c0-8.14,5.39-10,9.19-10h27.14V52l-39.32-.12c-35.66,0-42.42,26.68-42.42,43.77v19.48H99.09v36.32h27.24v109h45.41v-109h35Z">
                </path>
              </svg></a>
            <a class="footer-icon" id="footer_linkedin" href="https://www.linkedin.com/company/ncbinlm" aria-label="LinkedIn"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <title>LinkedIn</title>
                <path class="cls-11" d="M101.64,243.37H57.79v-114h43.85Zm-22-131.54h-.26c-13.25,0-21.82-10.36-21.82-21.76,0-11.65,8.84-21.15,22.33-21.15S101.7,78.72,102,90.38C102,101.77,93.4,111.83,79.63,111.83Zm100.93,52.61A17.54,17.54,0,0,0,163,182v61.39H119.18s.51-105.23,0-114H163v13a54.33,54.33,0,0,1,34.54-12.66c26,0,44.39,18.8,44.39,55.29v58.35H198.1V182A17.54,17.54,0,0,0,180.56,164.44Z">
                </path>
              </svg></a>
            <a class="footer-icon" id="footer_github" href="https://github.com/ncbi" aria-label="GitHub"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                <defs>
                  <style>
                    .cls-11,
                    .cls-12 {
                      fill: #737373;
                    }

                    .cls-11 {
                      fill-rule: evenodd;
                    }
                  </style>
                </defs>
                <title>GitHub</title>
                <path class="cls-11" d="M151.36,47.28a105.76,105.76,0,0,0-33.43,206.1c5.28,1,7.22-2.3,7.22-5.09,0-2.52-.09-10.85-.14-19.69-29.42,6.4-35.63-12.48-35.63-12.48-4.81-12.22-11.74-15.47-11.74-15.47-9.59-6.56.73-6.43.73-6.43,10.61.75,16.21,10.9,16.21,10.9,9.43,16.17,24.73,11.49,30.77,8.79,1-6.83,3.69-11.5,6.71-14.14C108.57,197.1,83.88,188,83.88,147.51a40.92,40.92,0,0,1,10.9-28.39c-1.1-2.66-4.72-13.42,1-28,0,0,8.88-2.84,29.09,10.84a100.26,100.26,0,0,1,53,0C198,88.3,206.9,91.14,206.9,91.14c5.76,14.56,2.14,25.32,1,28a40.87,40.87,0,0,1,10.89,28.39c0,40.62-24.74,49.56-48.29,52.18,3.79,3.28,7.17,9.71,7.17,19.58,0,14.15-.12,25.54-.12,29,0,2.82,1.9,6.11,7.26,5.07A105.76,105.76,0,0,0,151.36,47.28Z">
                </path>
                <path class="cls-12" d="M85.66,199.12c-.23.52-1.06.68-1.81.32s-1.2-1.06-.95-1.59,1.06-.69,1.82-.33,1.21,1.07.94,1.6Zm-1.3-1">
                </path>
                <path class="cls-12" d="M90,203.89c-.51.47-1.49.25-2.16-.49a1.61,1.61,0,0,1-.31-2.19c.52-.47,1.47-.25,2.17.49s.82,1.72.3,2.19Zm-1-1.08">
                </path>
                <path class="cls-12" d="M94.12,210c-.65.46-1.71,0-2.37-.91s-.64-2.07,0-2.52,1.7,0,2.36.89.65,2.08,0,2.54Zm0,0"></path>
                <path class="cls-12" d="M99.83,215.87c-.58.64-1.82.47-2.72-.41s-1.18-2.06-.6-2.7,1.83-.46,2.74.41,1.2,2.07.58,2.7Zm0,0">
                </path>
                <path class="cls-12" d="M107.71,219.29c-.26.82-1.45,1.2-2.64.85s-2-1.34-1.74-2.17,1.44-1.23,2.65-.85,2,1.32,1.73,2.17Zm0,0">
                </path>
                <path class="cls-12" d="M116.36,219.92c0,.87-1,1.59-2.24,1.61s-2.29-.68-2.3-1.54,1-1.59,2.26-1.61,2.28.67,2.28,1.54Zm0,0">
                </path>
                <path class="cls-12" d="M124.42,218.55c.15.85-.73,1.72-2,1.95s-2.37-.3-2.52-1.14.73-1.75,2-2,2.37.29,2.53,1.16Zm0,0"></path>
              </svg></a>
            <a class="footer-icon" id="footer_blog" href="https://ncbiinsights.ncbi.nlm.nih.gov/" aria-label="Blog">
              <svg id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><style>.cls-1{fill:#737373;}</style></defs><path class="cls-1" d="M14,30a4,4,0,1,1-4-4,4,4,0,0,1,4,4Zm11,3A19,19,0,0,0,7.05,15a1,1,0,0,0-1,1v3a1,1,0,0,0,.93,1A14,14,0,0,1,20,33.07,1,1,0,0,0,21,34h3a1,1,0,0,0,1-1Zm9,0A28,28,0,0,0,7,6,1,1,0,0,0,6,7v3a1,1,0,0,0,1,1A23,23,0,0,1,29,33a1,1,0,0,0,1,1h3A1,1,0,0,0,34,33Z"></path></svg>
            </a>
          </div>
        </div>
      </section>

      <section class="container-fluid bg-primary">
        <div class="container pt-5">
          <div class="row mt-3">
            <div class="col-lg-3 col-12">
              <p><a class="text-white" href="https://www.nlm.nih.gov/socialmedia/index.html">Connect with NLM</a></p>
              <ul class="list-inline social_media">
                <li class="list-inline-item"><a href="https://twitter.com/NLM_NIH" aria-label="Twitter" target="_blank" rel="noopener noreferrer" role="button" aria-expanded="false" aria-haspopup="true"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 249 249" style="enable-background:new 0 0 249 249;" xml:space="preserve">
                      <style type="text/css">
                        .st20 {
                          fill: #FFFFFF;
                        }

                        .st30 {
                          fill: none;
                          stroke: #FFFFFF;
                          stroke-width: 8;
                          stroke-miterlimit: 10;
                        }
                      </style>
                      <title>SM-Twitter</title>
                      <g>
                        <g>
                          <g>
                            <path class="st20" d="M192.9,88.1c-5,2.2-9.2,2.3-13.6,0.1c5.7-3.4,6-5.8,8.1-12.3c-5.4,3.2-11.4,5.5-17.6,6.7
                                                c-10.5-11.2-28.1-11.7-39.2-1.2c-7.2,6.8-10.2,16.9-8,26.5c-22.3-1.1-43.1-11.7-57.2-29C58,91.6,61.8,107.9,74,116
                                                c-4.4-0.1-8.7-1.3-12.6-3.4c0,0.1,0,0.2,0,0.4c0,13.2,9.3,24.6,22.3,27.2c-4.1,1.1-8.4,1.3-12.5,0.5c3.6,11.3,14,19,25.9,19.3
                                                c-11.6,9.1-26.4,13.2-41.1,11.5c12.7,8.1,27.4,12.5,42.5,12.5c51,0,78.9-42.2,78.9-78.9c0-1.2,0-2.4-0.1-3.6
                                                C182.7,97.4,189.2,93.7,192.9,88.1z"></path>
                          </g>
                        </g>
                        <circle class="st30" cx="124.4" cy="128.8" r="108.2"></circle>
                      </g>
                    </svg></a></li>
                <li class="list-inline-item"><a href="https://www.facebook.com/nationallibraryofmedicine" aria-label="Facebook" rel="noopener noreferrer" target="_blank" role="button" aria-expanded="false" aria-haspopup="true">
                    <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 249 249" style="enable-background:new 0 0 249 249;" xml:space="preserve">
                      <style type="text/css">
                        .st10 {
                          fill: #FFFFFF;
                        }

                        .st110 {
                          fill: none;
                          stroke: #FFFFFF;
                          stroke-width: 8;
                          stroke-miterlimit: 10;
                        }
                      </style>
                      <title>SM-Facebook</title>
                      <g>
                        <g>
                          <path class="st10" d="M159,99.1h-24V88.4c0-5,3.3-6.2,5.7-6.2h16.8V60l-24.4-0.1c-22.1,0-26.2,16.5-26.2,27.1v12.1H90v22.5h16.9
                                                      v67.5H135v-67.5h21.7L159,99.1z"></path>
                        </g>
                      </g>
                      <circle class="st110" cx="123.6" cy="123.2" r="108.2"></circle>
                    </svg>
                  </a></li>
                <li class="list-inline-item"><a href="https://www.youtube.com/user/NLMNIH" aria-label="Youtube" target="_blank" rel="noopener noreferrer" role="button" aria-expanded="false" aria-haspopup="true"><svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 249 249" style="enable-background:new 0 0 249 249;" xml:space="preserve">
                      <title>SM-Youtube</title>
                      <style type="text/css">
                        .st4 {
                          fill: none;
                          stroke: #FFFFFF;
                          stroke-width: 8;
                          stroke-miterlimit: 10;
                        }

                        .st5 {
                          fill: #FFFFFF;
                        }
                      </style>
                      <circle class="st4" cx="124.2" cy="123.4" r="108.2"></circle>
                      <g transform="translate(0,-952.36218)">
                        <path class="st5" d="M88.4,1037.4c-10.4,0-18.7,8.3-18.7,18.7v40.1c0,10.4,8.3,18.7,18.7,18.7h72.1c10.4,0,18.7-8.3,18.7-18.7
                                            v-40.1c0-10.4-8.3-18.7-18.7-18.7H88.4z M115.2,1058.8l29.4,17.4l-29.4,17.4V1058.8z"></path>
                      </g>
                    </svg></a></li>
              </ul>
            </div>
            <div class="col-lg-3 col-12">
              <p class="address_footer text-white">National Library of Medicine<br>
                <a href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/@38.9959508,-77.101021,17z/data=!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb:0x19156f88b27635b8!8m2!3d38.9959508!4d-77.0988323" class="text-white" target="_blank" rel="noopener noreferrer" role="button" aria-expanded="false" aria-haspopup="true">8600 Rockville Pike<br>
                  Bethesda, MD 20894</a></p>
            </div>
            <div class="col-lg-3 col-12 centered-lg">
              <p><a href="https://www.nlm.nih.gov/web_policies.html" class="text-white">Web Policies</a><br>
                <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="text-white">FOIA</a><br>
                <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="text-white" id="vdp">HHS Vulnerability Disclosure</a></p>
            </div>
            <div class="col-lg-3 col-12 centered-lg">
              <p><a class="supportLink text-white" href="https://support.nlm.nih.gov/?pagename=pmc-frontend%3Apmc%3Aarticle%3A%2Farticles%2FPMC8982799%2F" data-pinger-pagename-param="true">Help</a><br>
                <a href="https://www.nlm.nih.gov/accessibility.html" class="text-white">Accessibility</a><br>
                <a href="https://www.nlm.nih.gov/careers/careers.html" class="text-white">Careers</a></p>
            </div>
          </div>
          <div class="row">
            <div class="col-lg-12 centered-lg">
              <nav class="bottom-links">
                <ul class="mt-3">
                  <li>
                    <a class="text-white" href="https://www.nlm.nih.gov/">NLM</a>
                  </li>
                  <li>
                    <a class="text-white" href="https://www.nih.gov/">NIH</a>
                  </li>
                  <li>
                    <a class="text-white" href="https://www.hhs.gov/">HHS</a>
                  </li>
                  <li>
                    <a class="text-white" href="https://www.usa.gov/">USA.gov</a>
                  </li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </section>
    </footer>
 <!-- ========== END FOOTER ========== -->
  <!-- javascript to inject NWDS meta tags. Note: value of nwds_version is updated by "npm version" command -->
 
  <script type="text/javascript">
    var nwds_version = "1.1.9-2";

    var meta_nwds_ver = document.createElement('meta');
    meta_nwds_ver.name = 'ncbi_nwds_ver';
    meta_nwds_ver.content = nwds_version;
    document.getElementsByTagName('head')[0].appendChild(meta_nwds_ver);

    var meta_nwds = document.createElement('meta');
    meta_nwds.name = 'ncbi_nwds';
    meta_nwds.content = 'yes';
    document.getElementsByTagName('head')[0].appendChild(meta_nwds);

	var alertsUrl = "/core/alerts/alerts.js";
	if (typeof ncbiBaseUrl !== 'undefined') {
		alertsUrl = ncbiBaseUrl + alertsUrl;
	}
  </script>



  
    <!-- JavaScript -->
    <script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.0f72d6a64937.js.download"></script>
  
  
    <script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/jquery-3.5.0.min.js.download" integrity="sha256-xNzN2a4ltkB44Mc/Jz3pT4iU1cmeR0FkXs4pru/JxaQ=" crossorigin="anonymous">
    </script>
    <script>
        var fallbackJquery = "/pmc/static/base/js/jquery-3.5.0.min.js";
        window.jQuery || document.write("<script src=" + fallbackJquery + ">\x3C/script>")
    </script>
  

  <script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.a212a9fcf845.js.download"></script>
<script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.7999321d1aac.js.download"></script>
<script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.7ca436b2ea51.js.download"></script>
<script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.f8422046fbe0.js.download"></script>
<script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.ff40c7d85ff8.js.download"></script>
<script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.a6a84a0ad361.js.download"></script>

<script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/base.54110350c77632754ed7.js.download"></script>

    <script type="text/javascript">
        if(typeof jQuery !=='undefined') {
            jQuery.migrateMute = true;
        }
    </script>
    <script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/jquery-migrate-1.4.1.js.download"></script>
    <script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/jig.nojquery.min.js.download">//</script><script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/common.min.js.download">//</script><script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/NcbiTagServer.min.js.download">//</script><script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/crb.min.js.download">//</script><script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/jactions.min.js.download">//</script><meta name="citationexporter" content="backend:&#39;https://api.ncbi.nlm.nih.gov/lit/ctxp/v1/pmc/&#39;"><script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/jquery.citationexporter.min.js.download">//</script><link rel="stylesheet" href="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/citationexporter.css" type="text/css"><script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/MathJax.js.download"></script><script type="text/javascript">window.name="mainwindow";</script>

    <script type="text/javascript">var exports = {};</script>
    <script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.340a3b9cce7f.js.download"></script><div class="fake-body-scroll"></div>
<script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/output.586993420cfd.js.download"></script><div class="fake-body-scroll"></div>
    <script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/article.bf4d0b9d90eb88f67344.js.download"></script>
    <script type="text/javascript">
        window.ncbi.pmc.articlePage.init({ pageURL: '/pmc/articles/PMC8982799/', citeCookieName: 'pmc-cf'});
    </script>


  
  
  <script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/pinger.js.download"> </script><div id="ZN_dikYWqsjiUWN0Q5"></div>


  
      
  



<div style="display: none; top: -100px; left: -100px;" aria-live="assertive" aria-hidden="true" class="ui-helper-reset ui-ncbipopper-wrapper ui-ncbipopper-basic">External link. Please review our <a href="https://www.nlm.nih.gov/privacy.html">privacy policy</a>.</div><script type="text/javascript" src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/saved_resource"></script><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; min-width: 0px; max-width: none; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: MathJax_Size2, sans-serif;"></div></div><script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/CoreModule.js.download" defer=""></script><script src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/FeedbackButtonModule.js.download" defer=""></script><style type="text/css">.QSIFeedbackButton div,.QSIFeedbackButton dl,.QSIFeedbackButton dt,.QSIFeedbackButton dd,.QSIFeedbackButton ul,.QSIFeedbackButton ol,.QSIFeedbackButton li,.QSIFeedbackButton h1,.QSIFeedbackButton h2,.QSIFeedbackButton h3,.QSIFeedbackButton h4,.QSIFeedbackButton h5,.QSIFeedbackButton h6,.QSIFeedbackButton span,.QSIFeedbackButton pre,.QSIFeedbackButton form,.QSIFeedbackButton fieldset,.QSIFeedbackButton textarea,.QSIFeedbackButton p,.QSIFeedbackButton blockquote,.QSIFeedbackButton tr,.QSIFeedbackButton th,.QSIFeedbackButton td{ margin: 0; padding: 0;background-color: transparent; border: 0; font-size: 12px; line-height: normal; vertical-align:baseline; box-shadow: none; }.QSIFeedbackButton img{ height: auto; width: auto; margin: 0; padding: 0 }.QSIFeedbackButton ul,.QSIFeedbackButton ol{ margin: 12px 0; padding-left: 40px; }.QSIFeedbackButton ul li{ list-style-type: disc; }.QSIFeedbackButton ol li{ list-style-type: decimal; }.QSIFeedbackButton .scrollable{ -webkit-overflow-scrolling: touch; }.QSIFeedbackButton table{ border-collapse: collapse; border-spacing: 0; }.QSIFeedbackButton table td{ padding: 2px; }.QSIFeedbackButton iframe{ max-height: none; }.QSIFeedbackButton *{ box-sizing: content-box; }</style><div class="QSIFeedbackButton" style="position: fixed; visibility: hidden; inset: 0px; display: flex; flex-direction: column; justify-content: flex-end; align-items: flex-start; margin: 0px; padding: 0px; z-index: 2000000000;"><button role="button" aria-label="Tell us what you think!" id="QSIFeedbackButton-btn" aria-expanded="false" aria-controls="QSIFeedbackButton-target-container" style="position: fixed; visibility: visible; cursor: pointer; border: none; background-color: transparent; padding: 0px; margin: 0px; bottom: 105px; right: -1px; width: 52px; transition: all 0.5s ease 0s;"><img src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/Feedback+Button_vt.png" alt="Tell us what you think!" style="max-width: 110px; max-height: 110px; display: block;"></button></div><div id="QSIFeedbackButton-target-container" class="QSIFeedbackButton" role="dialog" aria-hidden="true" aria-labelledby="QSIFeedbackButton-btn" style="position: fixed; overflow: hidden; color: rgb(0, 0, 0); background-color: rgb(237, 237, 237); border-top: 2px solid rgb(166, 166, 166); border-right: none; border-bottom: 2px solid rgb(166, 166, 166); border-left: 2px solid rgb(166, 166, 166); border-image: initial; box-sizing: border-box; transition: all 0.5s ease 0s; margin: 0px; padding: 0px; z-index: 2000000001; height: 50%; border-radius: 2px 0px 0px 2px; max-width: 400px; width: 100vw; left: 100%; bottom: 0px;"><div id="QSIFeedbackButton-close-btn-container" style="background-color: transparent; padding-bottom: 10px; right: 10px; top: 10px; position: absolute; display: flex; justify-content: flex-end;"><button role="button" id="QSIFeedbackButton-close-btn" tabindex="-1" style="cursor: pointer; border: 0px; padding: 0px; background-color: transparent; z-index: 2000000001; margin: 0px;"><img src="./DeepFall_ Non-Invasive Fall Detection with Deep Spatio-Temporal Convolutional Autoencoders - PMC_files/wr-dialog-close-btn-black.png" alt="Close" style="height: 17px; width: 17px;"></button><div id="QSIFeedbackButton-close-btn-background" style="position: absolute; width: 28px; height: 28px; border-radius: 14px; top: -5px; right: -5px; background-color: rgb(255, 255, 255); opacity: 0.5;"></div></div></div></body></html>